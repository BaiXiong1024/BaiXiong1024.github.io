<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习 machine learning | HELLO WORLD</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="MachineLearning" />
  
  
  
  
  <meta name="description" content="机器学习是一类算法的总称，这些算法企图从大量历史数据中挖掘出其中隐含的规律，并用于预测或者分类，更具体的说，机器学习可以看作是寻找一个函数，输入是样本数据，输出是期望的结果，只是这个函数过于复杂，以至于不太方便形式化表达。需要注意的是，机器学习的目标是使学到的函数很好地适用于“新样本”，而不仅仅是在训练样本上表现很好。学到的函数适用于新样本的能力，称为泛化（Generalization）能力。在机">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习 Machine Learning">
<meta property="og:url" content="http://example.com/2021/10/01/ML/index.html">
<meta property="og:site_name" content="HELLO WORLD">
<meta property="og:description" content="机器学习是一类算法的总称，这些算法企图从大量历史数据中挖掘出其中隐含的规律，并用于预测或者分类，更具体的说，机器学习可以看作是寻找一个函数，输入是样本数据，输出是期望的结果，只是这个函数过于复杂，以至于不太方便形式化表达。需要注意的是，机器学习的目标是使学到的函数很好地适用于“新样本”，而不仅仅是在训练样本上表现很好。学到的函数适用于新样本的能力，称为泛化（Generalization）能力。在机">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200625102204710.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200625112011624.png#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200625112111267.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200625112147276.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200625112222314.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200625112341667.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200625112520192.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200625112620238.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200625112655511.png#pic_center">
<meta property="article:published_time" content="2021-10-01T07:09:12.000Z">
<meta property="article:modified_time" content="2023-02-16T14:43:24.473Z">
<meta property="article:author" content="Bai Xiong">
<meta property="article:tag" content="MachineLearning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20200625102204710.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center">
  
    <link rel="alternate" href="/atom.xml" title="HELLO WORLD" type="application/atom+xml">
  

  

  <link rel="icon" href="/css/images/mylogo.jpg">
  <link rel="apple-touch-icon" href="/css/images/mylogo.jpg">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt; src:url("/css/fonts/FuturaPTBold.otf") format("woff");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt-light; src:url("/css/fonts/FuturaPTBook.otf") format("woff");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt-italic; src:url("/css/fonts/FuturaPTBookOblique.otf") format("woff");font-weight:400;font-style:italic;}
}

  </style>
  
<link rel="stylesheet" href="/css/style.css">


  
<script src="/js/jquery-3.1.1.min.js"></script>

  
<script src="/js/bootstrap.js"></script>


  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css" >

  
    
<link rel="stylesheet" href="/css/dialog.css">

  

  

  
    <link rel="stylesheet" href="/css/header-post.css" >
  

  
  
  
    <link rel="stylesheet" href="/css/vdonate.css" >
  

<meta name="generator" content="Hexo 5.4.2"></head>



  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="
                 margin-top: 0px;"  
                href="#" data-toggle="modal" data-target="#myModal" >
                  <img width="124px" height="124px" alt="Hike News" src="/css/images/mylogo.jpg">
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/">Home</a> </li>
                
                  <li> <a class="main-nav-link" href="/archives">Archives</a> </li>
                
                  <li> <a class="main-nav-link" href="/categories">Categories</a> </li>
                
                  <li> <a class="main-nav-link" href="/tags">Tags</a> </li>
                
                  <li> <a class="main-nav-link" href="/about">About</a> </li>
                
                  <li> <a class="main-nav-link" href="/collection">collection</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div></li>
            </div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-ML" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      机器学习 Machine Learning
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2021/10/01/ML/" class="article-date">
	  <time datetime="2021-10-01T07:09:12.000Z" itemprop="datePublished">2021-10-01</time>
	</a>

      
    <a class="article-category-link" href="/categories/Introduction/">Introduction</a>

      
	<a class="article-views">
	<span id="busuanzi_container_page_pv">
		PV:<span id="busuanzi_value_page_pv"></span>
	</span>
	</a>

      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>机器学习是一类算法的总称，这些算法企图从大量历史数据中挖掘出其中隐含的规律，并用于预测或者分类，更具体的说，机器学习可以看作是寻找一个函数，输入是样本数据，输出是期望的结果，只是这个函数过于复杂，以至于不太方便形式化表达。需要注意的是，机器学习的目标是使学到的函数很好地适用于“新样本”，而不仅仅是在训练样本上表现很好。学到的函数适用于新样本的能力，称为泛化（Generalization）能力。<br>在机器学习中，有一种叫做「没有免费的午餐」的定理。简而言之，它指出没有任何一种算法对所有问题都有效，在监督学习（即预测建模）中尤其如此。<br>机器学习算法被描述为学习一个目标函数 f，该函数将输入变量 X 最好地映射到输出变量 Y：Y = f(X)<br>这是一个普遍的学习任务，我们可以根据输入变量 X 的新样本对 Y 进行预测。我们不知道函数 f 的样子或形式。如果我们知道的话，我们将会直接使用它，不需要用机器学习算法从数据中学习。<br>最常见的机器学习算法是学习映射 Y = f(X) 来预测新 X 的 Y。这叫做预测建模或预测分析，我们的目标是尽可能作出最准确的预测。</p>
<span id="more"></span>

<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><p>机器学习核心思想：梯度下降<br>梯度下降分类：批量梯度下降(BGD)   随机梯度下降(SGD) 小批量梯度下降(MBGD)</p>
<h2 id="机器学习常用算法总结"><a href="#机器学习常用算法总结" class="headerlink" title="机器学习常用算法总结"></a>机器学习常用算法总结</h2><p><img src="https://img-blog.csdnimg.cn/20200625102204710.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center" alt="机器学习常用算法总结"></p>
<h2 id="常用算法原理"><a href="#常用算法原理" class="headerlink" title="常用算法原理"></a>常用算法原理</h2><h4 id="LinearRegression-线性回归"><a href="#LinearRegression-线性回归" class="headerlink" title="LinearRegression 线性回归"></a>LinearRegression 线性回归</h4><ul>
<li>基本描述：线性回归可能是统计学和机器学习中最知名和最易理解的算法之一。预测建模主要关注最小化模型误差或者尽可能作出最准确的预测，以可解释性为代价。我们将借用、重用包括统计学在内的很多不同领域的算法，并将其用于这些目的。<br>线性回归的表示是一个方程，它通过找到输入变量的特定权重（称为系数 B），来描述一条最适合表示输入变量 x 与输出变量 y 关系的直线。<br>例如：y = B0 + B1 * x<br>我们将根据输入 x 预测 y，线性回归学习算法的目标是找到系数 B0 和 B1 的值。<br>可以使用不同的技术从数据中学习线性回归模型，例如用于普通最小二乘法和梯度下降优化的线性代数解。</li>
<li>算法思想：历史数据–&gt; 拟合平面计算式-&gt;损失函数（误差）分析-&gt;目标函数最小值参数seita-&gt;回归模型-&gt;预测值</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20200625112011624.png#pic_center" alt="Linear-Regression"></p>
<h4 id="Loglstic-罗辑回归"><a href="#Loglstic-罗辑回归" class="headerlink" title="Loglstic 罗辑回归"></a>Loglstic 罗辑回归</h4><ul>
<li><p>算法思想：特征数据–&gt;线性回归方程–&gt;进行sigmoid激活–&gt;输出的得分值–&gt;比较不同预测结果的得分值</p>
</li>
<li><p>基本描述：回归是机器学习从统计学中借鉴的另一种技术。它是解决二分类问题的首选方法。<br>Logistic 回归与线性回归相似，目标都是找到每个输入变量的权重，即系数值。与线性回归不同的是，Logistic 回归对输出的预测使用被称为 logistic 函数的非线性函数进行变换。<br>logistic 函数看起来像一个大的 S，并且可以将任何值转换到 0 到 1 的区间内。这非常实用，因为我们可以规定 logistic 函数的输出值是 0 和 1（例如，输入小于 0.5 则输出为 1）并预测类别值。<br>由于模型的学习方式，Logistic 回归的预测也可以作为给定数据实例（属于类别 0 或 1）的概率。这对于需要为预测提供更多依据的问题很有用。<br>像线性回归一样，Logistic 回归在删除与输出变量无关的属性以及非常相似（相关）的属性时效果更好。它是一个快速的学习模型，并且对于二分类问题非常有效。<br><img src="https://img-blog.csdnimg.cn/20200625112111267.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center" alt="Logistic"></p>
</li>
</ul>
<h4 id="LDA-线性判别分析"><a href="#LDA-线性判别分析" class="headerlink" title="LDA 线性判别分析"></a>LDA 线性判别分析</h4><ul>
<li>基本描述：Logistic 回归是一种分类算法，传统上，它仅限于只有两类的分类问题。如果你有两个以上的类别，那么线性判别分析是首选的线性分类技术。<br>LDA 的表示非常简单直接。它由数据的统计属性构成，对每个类别进行计算。单个输入变量的 LDA 包括：每个类别的平均值；所有类别的方差。<br>线性判别分析进行预测的方法是计算每个类别的判别值并对具备最大值的类别进行预测。该技术假设数据呈高斯分布（钟形曲线），因此最好预先从数据中删除异常值。这是处理分类预测建模问题的一种简单而强大的方法。</li>
</ul>
<h4 id="SVM-支持向量机"><a href="#SVM-支持向量机" class="headerlink" title="SVM 支持向量机"></a>SVM 支持向量机</h4><ul>
<li><p>基本描述：支持向量机可能是最受欢迎和最广泛讨论的机器学习算法之一。<br>超平面是分割输入变量空间的一条线。在 SVM 中，选择一条可以最好地根据输入变量类别（类别 0 或类别 1）对输入变量空间进行分割的超平面。在二维中，你可以将其视为一条线，我们假设所有的输入点都可以被这条线完全的分开。SVM 学习算法找到了可以让超平面对类别进行最佳分割的系数。<br>超平面和最近的数据点之间的距离被称为间隔。分开两个类别的最好的或最理想的超平面具备最大间隔。只有这些点与定义超平面和构建分类器有关。这些点被称为支持向量，它们支持或定义了超平面。实际上，优化算法用于寻找最大化间隔的系数的值。<br>SVM 可能是最强大的立即可用的分类器之一，值得一试。</p>
</li>
<li><p>算法思想：两类数据点–&gt;决策方程(w /b)–&gt;最大化点与决策边界的距离–&gt;距离倒数的极小值(拉格朗日乘子/核函数)–&gt;最优决策方程 （找到区分两类的hyper plane 超平面 使得边际margin 最大）</p>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20200625112147276.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center" alt="SVM"></p>
<h4 id="DecideTree-决策树"><a href="#DecideTree-决策树" class="headerlink" title="DecideTree 决策树"></a>DecideTree 决策树</h4><ul>
<li><p>基本描述：决策树是预测建模机器学习的一种重要算法。<br>决策树模型的表示是一个二叉树。这是算法和数据结构中的二叉树，没什么特别的。每个节点代表一个单独的输入变量 x 和该变量上的一个分割点（假设变量是数字）。<br>决策树的叶节点包含一个用于预测的输出变量 y。通过遍历该树的分割点，直到到达一个叶节点并输出该节点的类别值就可以作出预测。<br>决策树学习速度和预测速度都很快。它们还可以解决大量问题，并且不需要对数据做特别准备。</p>
</li>
<li><p>算法思想：整个数据集(根节点)–&gt; 通过条件(信息增益//信息增益率)–&gt; 判断合适的前进方向–&gt;达到不可再分的节点 –&gt;  最终的决策结果</p>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20200625112222314.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center" alt="Decide-Tree"></p>
<h5 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h5><h5 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h5><h4 id="RandomForest-随机森林"><a href="#RandomForest-随机森林" class="headerlink" title="RandomForest 随机森林"></a>RandomForest 随机森林</h4><ul>
<li><p>基本描述：随机森林是最流行和最强大的机器学习算法之一。它是 Bootstrap Aggregation（又称 bagging）集成机器学习算法的一种。<br>bootstrap 是从数据样本中估算数量的一种强大的统计方法。例如平均数。你从数据中抽取大量样本，计算平均值，然后平均所有的平均值以便更好的估计真实的平均值。<br>bagging 使用相同的方法，但是它估计整个统计模型，最常见的是决策树。在训练数据中抽取多个样本，然后对每个数据样本建模。当你需要对新数据进行预测时，每个模型都进行预测，并将所有的预测值平均以便更好的估计真实的输出值。<br>随机森林是对这种方法的一种调整，在随机森林的方法中决策树被创建以便于通过引入随机性来进行次优分割，而不是选择最佳分割点。<br>因此，针对每个数据样本创建的模型将会与其他方式得到的有所不同，不过虽然方法独特且不同，它们仍然是准确的。结合它们的预测可以更好的估计真实的输出值。<br>如果用方差较高的算法（如决策树）得到了很好的结果，那么通常可以通过 bagging 该算法来获得更好的结果。</p>
</li>
<li><p>算法思想：训练数据集–&gt; 随机数据采样 （第一重随机）AND 随机特征采样(第二重随机) –&gt;训练数据集–&gt; 建立决策树模型–&gt;综合（平均/投票/多数结果法）–&gt;最终结果</p>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20200625112341667.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center" alt="Random-Forest"></p>
<h4 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h4><p><img src="https://img-blog.csdnimg.cn/20200625112520192.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center" alt="Adboost"></p>
<h5 id="Adboost"><a href="#Adboost" class="headerlink" title="Adboost"></a>Adboost</h5><ul>
<li>基本描述：Boosting 是一种集成技术，它试图集成一些弱分类器来创建一个强分类器。这通过从训练数据中构建一个模型，然后创建第二个模型来尝试纠正第一个模型的错误来完成。一直添加模型直到能够完美预测训练集，或添加的模型数量已经达到最大数量。<br>AdaBoost 是第一个为二分类开发的真正成功的 boosting 算法。这是理解 boosting 的最佳起点。现代 boosting 方法建立在 AdaBoost 之上，最显著的是随机梯度提升。<br>AdaBoost 与短决策树一起使用。在第一个决策树创建之后，利用每个训练实例上树的性能来衡量下一个决策树应该对每个训练实例付出多少注意力。难以预测的训练数据被分配更多权重，而容易预测的数据分配的权重较少。依次创建模型，每个模型在训练实例上更新权重，影响序列中下一个决策树的学习。在所有决策树建立之后，对新数据进行预测，并且通过每个决策树在训练数据上的精确度评估其性能。<br>因为在纠正算法错误上投入了太多注意力，所以具备已删除异常值的干净数据非常重要。</li>
<li>算法思想：训练数据集–&gt;一次划分–&gt;更新权重–&gt;二次划分–&gt;更新权重–&gt;三次划分–&gt;更新权重–&gt;对每次预测结果根据准确率（作为权重)乘以a–&gt;综合相加–&gt;最终结果</li>
</ul>
<h5 id="Xgboost"><a href="#Xgboost" class="headerlink" title="Xgboost"></a>Xgboost</h5><ul>
<li>算法思想：内部决策树用的回归树–&gt;构造出第一棵树–&gt;选择策略–&gt;第二棵树–&gt;选择策略–&gt;第三棵树</li>
</ul>
<h4 id="K-Means-K均值"><a href="#K-Means-K均值" class="headerlink" title="K-Means K均值"></a>K-Means K均值</h4><ul>
<li>算法思想：一堆数据–&gt;初始化 k 个质心点– &gt;按质心算距离 聚类 –&gt; 迭代更新质心–&gt; 依次继续更新</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20200625112620238.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk4ODEzMQ==,size_16,color_FFFFFF,t_70#pic_center" alt="KMeans"></p>
<h4 id="KNN-K近邻"><a href="#KNN-K近邻" class="headerlink" title="KNN K近邻"></a>KNN K近邻</h4><ul>
<li><p>基本描述：KNN 算法非常简单且有效。KNN 的模型表示是整个训练数据集。<br>KNN 算法在整个训练集中搜索 K 个最相似实例（近邻）并汇总这 K 个实例的输出变量，以预测新数据点。对于回归问题，这可能是平均输出变量，对于分类问题，这可能是众数（或最常见的）类别值。<br>诀窍在于如何确定数据实例间的相似性。如果属性的度量单位相同（例如都是用英寸表示），那么最简单的技术是使用欧几里得距离，你可以根据每个输入变量之间的差值直接计算出来其数值。<br>KNN 需要大量内存或空间来存储所有数据，但是只有在需要预测时才执行计算（或学习）。你还可以随时更新和管理训练实例，以保持预测的准确性。<br>距离或紧密性的概念可能在非常高的维度（很多输入变量）中会瓦解，这对算法在你的问题上的性能产生负面影响。这被称为维数灾难。因此你最好只使用那些与预测输出变量最相关的输入变量。</p>
</li>
<li><p>算法思想：带标签的训练数据集和待分类测试数据–&gt;测试对象到训练集中每个对象的距离–&gt;按距离大小排序–&gt;选取K个与测试对象最近的标签数据–&gt;多数表决预测</p>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20200625112655511.png#pic_center" alt="KNN"></p>
<h4 id="LVQ-学习向量量化"><a href="#LVQ-学习向量量化" class="headerlink" title="LVQ 学习向量量化"></a>LVQ 学习向量量化</h4><ul>
<li>基本描述：K 近邻算法的一个缺点是你需要遍历整个训练数据集。学习向量量化算法（简称 LVQ）是一种人工神经网络算法，它允许你选择训练实例的数量，并精确地学习这些实例应该是什么样的。<br>LVQ 的表示是码本向量的集合。这些是在开始时随机选择的，并逐渐调整以在学习算法的多次迭代中最好地总结训练数据集。在学习之后，码本向量可用于预测（类似 K 近邻算法）。最相似的近邻（最佳匹配的码本向量）通过计算每个码本向量和新数据实例之间的距离找到。然后返回最佳匹配单元的类别值或（回归中的实际值）作为预测。如果你重新调整数据，使其具有相同的范围（比如 0 到 1 之间），就可以获得最佳结果。<br>如果 KNN 在数据集上达到很好的结果，请尝试用 LVQ 减少存储整个训练数据集的内存要求</li>
</ul>
<h4 id="NaiveBayes"><a href="#NaiveBayes" class="headerlink" title="NaiveBayes"></a>NaiveBayes</h4><ul>
<li>基本描述：朴素贝叶斯是一个简单但是很强大的预测建模算法。<br>该模型由两种概率组成，这两种概率都可以直接从训练数据中计算出来：1）每个类别的概率；2）给定每个 x 的值，每个类别的条件概率。一旦计算出来，概率模型可用于使用贝叶斯定理对新数据进行预测。当你的数据是实值时，通常假设一个高斯分布（钟形曲线），这样你可以简单的估计这些概率。<br>贝叶斯定理 朴素贝叶斯之所以是朴素的，是因为它假设每个输入变量是独立的。这是一个强大的假设，真实的数据并非如此，但是，该技术在大量复杂问题上非常有用。</li>
</ul>
<h4 id="EM"><a href="#EM" class="headerlink" title="EM"></a>EM</h4>
      
    </div>
    <footer class="article-footer">
      
        <div id="donation_div"></div>


<script src="/js/vdonate.js"></script>

<script>
var a = new Donate({
  title: '如果觉得我的文章对您有用，请随意打赏。您的支持将鼓励我继续创作!', // 可选参数，打赏标题
  btnText: 'Donate', // 可选参数，打赏按钮文字
  el: document.getElementById('donation_div'),
  wechatImage: 'css/images/zhifubao.jpg',
  alipayImage: 'css/images/weixin.jpg'
});
</script>
      
      
      <div>
        <ul class="post-copyright">
          <li class="post-copyright-author">
          <strong>Post author:  </strong>Bai Xiong</a>
          </li>
          <li class="post-copyright-link">
          <strong>Post link:  </strong>
          <a href="/2021/10/01/ML/" target="_blank" title="机器学习 Machine Learning">http://example.com/2021/10/01/ML/</a>
          </li>
          <li class="post-copyright-license">
            <strong>Copyright Notice:   </strong>
            All articles in this blog are licensed under <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a>
            unless stating additionally.
          </li>
         
        </ul>
<div>

      
      
        
	<div id="comment">
		<!-- 来必力City版安装代码 -->
		<div id="lv-container" data-id="city" data-uid="MTAyMC8yOTQ4MS82MDQ5">
		<script type="text/javascript">
		   (function(d, s) {
		       var j, e = d.getElementsByTagName(s)[0];

		       if (typeof LivereTower === 'function') { return; }

		       j = d.createElement(s);
		       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
		       j.async = true;

		       e.parentNode.insertBefore(j, e);
		   })(document, 'script');
		</script>
		<noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
		</div>
		<!-- City版安装代码已完成 -->
	</div>



      
      
        
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MachineLearning/" rel="tag">MachineLearning</a></li></ul>

      

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2022/09/28/CV-SelfiSegmentation/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          计算机视觉人像抠图 SemanticSegmentation
        
      </div>
    </a>
  
  
    <a href="/2021/10/01/ML-KMeans/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">机器学习-K均值 KMeans</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">Contents</strong>
    
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.</span> <span class="nav-text">机器学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93"><span class="nav-number">1.1.</span> <span class="nav-text">机器学习常用算法总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="nav-number">1.2.</span> <span class="nav-text">常用算法原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#LinearRegression-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">1.2.0.1.</span> <span class="nav-text">LinearRegression 线性回归</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Loglstic-%E7%BD%97%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="nav-number">1.2.0.2.</span> <span class="nav-text">Loglstic 罗辑回归</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LDA-%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90"><span class="nav-number">1.2.0.3.</span> <span class="nav-text">LDA 线性判别分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SVM-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-number">1.2.0.4.</span> <span class="nav-text">SVM 支持向量机</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DecideTree-%E5%86%B3%E7%AD%96%E6%A0%91"><span class="nav-number">1.2.0.5.</span> <span class="nav-text">DecideTree 决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#C4-5"><span class="nav-number">1.2.0.5.1.</span> <span class="nav-text">C4.5</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#CART"><span class="nav-number">1.2.0.5.2.</span> <span class="nav-text">CART</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RandomForest-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="nav-number">1.2.0.6.</span> <span class="nav-text">RandomForest 随机森林</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.2.0.7.</span> <span class="nav-text">集成学习</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Adboost"><span class="nav-number">1.2.0.7.1.</span> <span class="nav-text">Adboost</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Xgboost"><span class="nav-number">1.2.0.7.2.</span> <span class="nav-text">Xgboost</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#K-Means-K%E5%9D%87%E5%80%BC"><span class="nav-number">1.2.0.8.</span> <span class="nav-text">K-Means K均值</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#KNN-K%E8%BF%91%E9%82%BB"><span class="nav-number">1.2.0.9.</span> <span class="nav-text">KNN K近邻</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LVQ-%E5%AD%A6%E4%B9%A0%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96"><span class="nav-number">1.2.0.10.</span> <span class="nav-text">LVQ 学习向量量化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#NaiveBayes"><span class="nav-number">1.2.0.11.</span> <span class="nav-text">NaiveBayes</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#EM"><span class="nav-number">1.2.0.12.</span> <span class="nav-text">EM</span></a></li></ol></li></ol></li></ol></li></ol>
    
    </div>
  </aside>

</section>
        
      </div>
      
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2013 - 2023 HELLO WORLD All Rights Reserved.</p>
	      
	      
    		<p class="busuanzi_uv">
				UV : <span id="busuanzi_value_site_uv"></span> |  
				PV : <span id="busuanzi_value_site_pv"></span>
		    </p>
  		   
		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
    <a href="/collection" class="mobile-nav-link">Collection</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/scripts.js"></script>





  
<script src="/js/dialog.js"></script>









	<div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>



	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>






  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            HELLO WORLD
          </div>
          <div class="panel-body">
            Copyright © 2023 Bai Xiong All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a>
  
</body>
</html>