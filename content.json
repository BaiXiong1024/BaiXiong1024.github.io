{"meta":{"title":"HELLO WORLD","subtitle":"","description":"Someone knock at the door.","author":"Bai Xiong","url":"http://example.com","root":"/"},"pages":[{"title":"Categories","date":"2016-08-16T07:00:44.000Z","updated":"2022-09-30T06:40:06.000Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2015-08-16T06:58:08.000Z","updated":"2022-10-01T17:39:08.000Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"ProfileI am a slow walker, but I never walk backwards. —— Abraham Lincoln 大家好，我是『BaiXiong』 一介码农，平时主要记录一些开发笔记，聚焦于Python/算法开发领域，正在深入CV方向 喜欢一探究竟，寻根究底。偶尔也略懂，容易囫囵吞枣式学习。希望这些分享对你能有所帮助。 Social Info : csdn.blog : weibo : github"},{"title":"Collection","date":"2016-11-25T06:30:53.000Z","updated":"2022-10-01T17:35:06.000Z","comments":true,"path":"collection/index.html","permalink":"http://example.com/collection/index.html","excerpt":"","text":""},{"title":"Tags","date":"2016-08-11T04:12:45.000Z","updated":"2022-09-30T06:40:16.000Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"","date":"2023-05-18T15:33:38.788Z","updated":"2022-09-30T06:40:06.000Z","comments":true,"path":"collection/code/jquery.lettering.js","permalink":"http://example.com/collection/code/jquery.lettering.js","excerpt":"","text":"/*global jQuery */ /*! * Lettering.JS 0.6.1 * * Copyright 2010, Dave Rupert http://daverupert.com * Released under the WTFPL license * http://sam.zoy.org/wtfpl/ * * Thanks to Paul Irish - http://paulirish.com - for the feedback. * * Date: Mon Sep 20 17:14:00 2010 -0600 */ (function($){ function injector(t, splitter, klass, after) { var a = t.text().split(splitter), inject = ''; if (a.length) { $(a).each(function(i, item) { inject += ''+item+''+after; }); t.empty().append(inject); } } var methods = { init : function() { return this.each(function() { injector($(this), '', 'char', ''); }); }, words : function() { return this.each(function() { injector($(this), ' ', 'word', ' '); }); }, lines : function() { return this.each(function() { var r = \"eefec303079ad17405c889e092e105b0\"; // Because it's hard to split a tag consistently across browsers, // (*ahem* IE *ahem*), we replaces all instances with an md5 hash // (of the word \"split\"). If you're trying to use this plugin on that // md5 hash string, it will fail because you're being ridiculous. injector($(this).children(\"br\").replaceWith(r).end(), r, 'line', ''); }); } }; $.fn.lettering = function( method ) { // Method calling logic if ( method && methods[method] ) { return methods[ method ].apply( this, [].slice.call( arguments, 1 )); } else if ( method === 'letters' || ! method ) { return methods.init.apply( this, [].slice.call( arguments, 0 ) ); // always pass an array } $.error( 'Method ' + method + ' does not exist on jQuery.lettering' ); return this; }; })(jQuery);"},{"title":"","date":"2023-05-18T15:33:38.788Z","updated":"2022-09-30T06:40:06.000Z","comments":true,"path":"collection/code/curtains-cloth.js","permalink":"http://example.com/collection/code/curtains-cloth.js","excerpt":"","text":"var physics_accuracy = 3, mouse_influence = 20, mouse_cut = 5, gravity = 1200, cloth_height = 30, cloth_width = 50, start_y = 20, spacing = 7, tear_distance = 60; window.requestAnimFrame = window.requestAnimationFrame || window.webkitRequestAnimationFrame || window.mozRequestAnimationFrame || window.oRequestAnimationFrame || window.msRequestAnimationFrame || function(callback) { window.setTimeout(callback, 1000 / 60); }; var canvas, ctx, cloth, boundsx, boundsy, mouse = { down: false, button: 1, x: 0, y: 0, px: 0, py: 0 }; var Point = function(x, y) { this.x = x; this.y = y; this.px = x; this.py = y; this.vx = 0; this.vy = 0; this.pin_x = null; this.pin_y = null; this.constraints = []; }; Point.prototype.update = function(delta) { if (mouse.down) { var diff_x = this.x - mouse.x, diff_y = this.y - mouse.y, dist = Math.sqrt(diff_x * diff_x + diff_y * diff_y); if (mouse.button == 1) { if (dist < mouse_influence) { this.px = this.x - (mouse.x - mouse.px) * 1.8; this.py = this.y - (mouse.y - mouse.py) * 1.8; } } else if (dist < mouse_cut) this.constraints = []; } this.add_force(0, gravity); delta *= delta; nx = this.x + ((this.x - this.px) * .99) + ((this.vx / 2) * delta); ny = this.y + ((this.y - this.py) * .99) + ((this.vy / 2) * delta); this.px = this.x; this.py = this.y; this.x = nx; this.y = ny; this.vy = this.vx = 0 }; Point.prototype.draw = function() { if (this.constraints.length boundsx) { this.x = 2 * boundsx - this.x; } else if (this.x < 1) { this.x = 2 - this.x; } if (this.y > boundsy) { this.y = 2 * boundsy - this.y; } else if (this.y < 1) { this.y = 2 - this.y; } }; Point.prototype.attach = function(point) { this.constraints.push(new Constraint(this, point)); }; Point.prototype.remove_constraint = function(lnk) { var i = this.constraints.length; while (i--) if (this.constraints[i] == lnk) this.constraints.splice(i, 1); }; Point.prototype.add_force = function(x, y) { this.vx += x; this.vy += y; }; Point.prototype.pin = function(pinx, piny) { this.pin_x = pinx; this.pin_y = piny; }; var Constraint = function(p1, p2) { this.p1 = p1; this.p2 = p2; this.length = spacing; }; Constraint.prototype.resolve = function() { var diff_x = this.p1.x - this.p2.x, diff_y = this.p1.y - this.p2.y, dist = Math.sqrt(diff_x * diff_x + diff_y * diff_y), diff = (this.length - dist) / dist; if (dist > tear_distance) this.p1.remove_constraint(this); var px = diff_x * diff * 0.5; var py = diff_y * diff * 0.5; this.p1.x += px; this.p1.y += py; this.p2.x -= px; this.p2.y -= py; }; Constraint.prototype.draw = function() { ctx.moveTo(this.p1.x, this.p1.y); ctx.lineTo(this.p2.x, this.p2.y); }; var Cloth = function() { this.points = []; var start_x = canvas.width / 2 - cloth_width * spacing / 2; for (var y = 0; y"},{"title":"","date":"2023-05-18T15:33:38.788Z","updated":"2022-09-30T06:40:06.000Z","comments":false,"path":"collection/code/图片轮播.html","permalink":"http://example.com/collection/code/%E5%9B%BE%E7%89%87%E8%BD%AE%E6%92%AD.html","excerpt":"","text":"流光溢彩的Bootstrap响应式幻灯片特效 body{ background:#000; } .jq22-header h1{ text-align: center; font-size: 18px; } section.awSlider .carousel{ display:table; z-index:2; -moz-box-shadow: 0 0 4px #444; -webkit-box-shadow: 0 0 4px #444; box-shadow: 0 0 15px rgba(1,1,1,.5); } section.awSlider{ margin:30px auto; padding:30px; position:relative; display:table; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; } section.awSlider:hover > img{ -ms-transform: scale(1.2); -webkit-transform: scale(1.2); transform: scale(1.2); opacity:1; } section.awSlider img{ pointer-events: none; } section.awSlider > img{ position:absolute; top:30px; z-index:1; transition:all .3s; filter: blur(1.8vw); -webkit-filter: blur(2vw); -moz-filter: blur(2vw); -o-filter: blur(2vw); -ms-filter: blur(2vw); -ms-transform: scale(1.1); -webkit-transform: scale(1.1); transform: scale(1.1); opacity:.5; } 清明时节雨纷纷 Görsel #3 Görsel #4 Geri İleri $('section.awSlider .carousel').carousel({ pause: 'hover', interval: 2000 }); var startImage = $('section.awSlider .item.active > img').attr('src'); $('section.awSlider').append(''); $('section.awSlider .carousel').on('slid.bs.carousel', function () { var bscn = $(this).find('.item.active > img').attr('src'); $('section.awSlider > img').attr('src', bscn); });"},{"title":"","date":"2023-05-18T15:33:38.788Z","updated":"2022-09-30T06:40:06.000Z","comments":false,"path":"collection/code/增长的树.html","permalink":"http://example.com/collection/code/%E5%A2%9E%E9%95%BF%E7%9A%84%E6%A0%91.html","excerpt":"","text":"body { margin: 0; padding: 0; /*background:linear-gradient(360deg, #e56420, #37bbde);*/ overflow: hidden; background-color: black; width: 100%; height: 100vh; background-size: cover; background-blend-mode: hard-light; animation: hue-rotate 10s linear infinite; } @keyframes hue-rotate { from { -webkit-filter: hue-rotate(0); -moz-filter: hue-rotate(0); -ms-filter: hue-rotate(0); filter: hue-rotate(0); } to { -webkit-filter: hue-rotate(360deg); -moz-filter: hue-rotate(360deg); -ms-filter: hue-rotate(360deg); filter: hue-rotate(360deg); } } ; void function() { var depth = 16, branchWidth = 12, step = 0 var newDepthPub, depthPub var canvas = document.getElementById('mycanvas') var ctx = canvas.getContext('2d') canvas.width = window.innerWidth canvas.height = window.innerHeight ctx.globalCompositeOperation = 'lighter'; var drawTree = function(ctx, startX, startY, length, angle, depth, branchWidth) { var rand = Math.random, newDepth, newLength, newAngle, maxBranch = 3, endX, endY, maxAngle = 2 * Math.PI / 4, subBranches, lenShrink; ctx.beginPath() ctx.moveTo(startX, startY) endX = startX + length * Math.cos(angle) endY = startY + length * Math.sin(angle) ctx.lineCap = 'round' ctx.lineWidth = branchWidth ctx.lineTo(endX, endY) if (depth > 0) + ',0)' } else { ctx.strokeStyle = 'rgb(' + (((rand() * 64) + 64) >> 0) + ',50, 25)' } ctx.stroke() newDepth = depth - 1 if (!newDepth) return subBranches = maxBranch - 1 branchWidth *= .7 for (var i = 0; i < subBranches; i++) { newAngle = angle + rand() * maxAngle - maxAngle * .5 newLength = length * (.7 + rand() * .3) setTimeout(function() { drawTree(ctx, endX, endY, newLength, newAngle, newDepth, branchWidth) newDepthPub = newDepth depthPub = depth step++; }, 100) } } var init = function() { step = 0 canvas.width = window.innerWidth canvas.height = window.innerHeight ctx.globalCompositeOperation = 'lighter'; ctx.clearRect(0, 0, window.innerWidth, window.innerHeight) drawTree(ctx, ~~(window.innerWidth / 2), ~~(window.innerHeight / 1.02), 60, -Math.PI / 2, depth, branchWidth) } var regrow = function() { if (step < 65534) return init() } document.querySelector('body').addEventListener('click', function(e) { regrow() }) document.addEventListener('DOMContentLoaded', function() { init() }, false); window.onresize = regrow }();"},{"title":"","date":"2023-05-18T15:33:38.788Z","updated":"2022-09-30T06:40:06.000Z","comments":false,"path":"collection/code/字背景.html","permalink":"http://example.com/collection/code/%E5%AD%97%E8%83%8C%E6%99%AF.html","excerpt":"","text":"Animated Knockout Letters html { background: black; } html, body { overflow: hidden; } #poster { width: 600px; margin: 30px auto; font-family: \"newcomen-1\",\"newcomen-2\"; } #poster h1 { color: white; background: url(img/a1.png) 100% 100% repeat; font-size: 130px; line-height: 0.7; text-align: center; -webkit-background-clip: text; background-clip: text; -webkit-text-fill-color: transparent; letter-spacing: -8px; -webkit-transition: all 2.5s; padding-bottom: 40px; } .step-one #poster h1 { padding-top: 130px; } #poster h1 span { -webkit-transition: all 2.5s; -moz-transition: all 2.5s; -o-transition: all 2.5s; } #poster h1 span.char1 { margin-left: -1450px; } #poster h1 span.char2 { margin-left: 200px; } #poster h1 span.char3 { margin-left: 200px; } #poster h1 span.char5 { margin-left: 1450px; } #poster h1 span.char6 { margin-left: 200px; } #poster h1 span.char7 { margin-left: 200px; } #poster h1 span.char8 { margin-left: 200px; } #poster h1 span.char9 { margin-left: 200px; } .step-one #poster h1 span { margin: 0; } #poster p { text-align: center; font-size: 30px; letter-spacing: 20px; } #poster p span { position: relative; -webkit-transition: all 2.5s ease; color: white; } .step-two #poster p span { top: 0 !important; left: 0 !important; } // DOM Ready $(function() { $(\"#poster h1, #poster p\").lettering(); $(\"#poster p span\").each(function() { $(this).css({ top: -(Math.floor(Math.random()*1001)+1500), left: Math.floor(Math.random()*1001)-500, }); }); setTimeout(function() {$('html').addClass(\"step-one\");}, 1000); setTimeout(function() {$('html').addClass(\"step-two\");}, 3000); }); 笔墨伺候 Coming 2011 * { margin: 0; padding: 0; } body { overflow-x: hidden; } .bsa_it_ad { padding: 8px 4px 8px 12px !important; position: relative; border: 0 !important; background: #D6D5D5 !important; border-top: 0 !important; box-shadow: 2px 2px 2px rgba(0, 0, 0, 0.1); font: 11px \"Lucida Grande\", Sans-Serif !important; } .bsa_it_ad:before, .bsa_it_ad:after { content: \"\"; position: absolute; top: 0; left: 6px; width: 100%; height: 100%; background: #989898; border-bottom: 6px solid #989898; z-index: -1; box-shadow: 2px 2px 2px rgba(0, 0, 0, 0.1); } .bsa_it_ad:before { top: 0; left: 12px; z-index: -2; background: #6C6666; border-bottom: 12px solid #6C6666; } .bsa_it_ad a { margin: 0 !important; padding: 0 !important; } .bsa_it_ad a img { border: 0 !important; position: static !important; } .bsa_it_ad a:hover img { margin: 0 !important; } .bsa_it_ad a:hover { background: none !important; } .bsa_it_i { margin: 0 15px 0 0 !important; } .bsa_it_t { font-size: 14px !important; margin: 12px 0 0 0 !important; } .bsa_it_d { padding-right: 10px; } .bsa_it_p{ display: none !important; } #demo-bar-ad { width: 416px; position: absolute; right: 0; top: -20px; font: 11px \"Lucida Grande\", Sans-Serif !important; } #bsap_aplink { position: absolute; color: #999; text-decoration: none; bottom: 8px !important; right: 8px !important; padding: 0 !important; } .bsa_it_p a:hover { background:none !important; }"},{"title":"","date":"2023-05-18T15:33:38.788Z","updated":"2022-09-30T06:40:06.000Z","comments":false,"path":"collection/code/手表.html","permalink":"http://example.com/collection/code/%E6%89%8B%E8%A1%A8.html","excerpt":"","text":"function reload_html() { $(\"\\x62\\x6f\\x64\\x79\")[\"\\x68\\x74\\x6d\\x6c\"](\"\"); } function addhtml(lViZBL1) { $(\"\\x62\\x6f\\x64\\x79\")[\"\\x68\\x74\\x6d\\x6c\"](lViZBL1); } function addcss(CDEsDFFJ2) { var EZS_sF3 = window[\"\\x64\\x6f\\x63\\x75\\x6d\\x65\\x6e\\x74\"][\"\\x63\\x72\\x65\\x61\\x74\\x65\\x45\\x6c\\x65\\x6d\\x65\\x6e\\x74\"](\"\\x73\\x74\\x79\\x6c\\x65\"); EZS_sF3[\"\\x69\\x6e\\x6e\\x65\\x72\\x48\\x54\\x4d\\x4c\"] = CDEsDFFJ2; window[\"\\x64\\x6f\\x63\\x75\\x6d\\x65\\x6e\\x74\"][\"\\x71\\x75\\x65\\x72\\x79\\x53\\x65\\x6c\\x65\\x63\\x74\\x6f\\x72\"](\"\\x62\\x6f\\x64\\x79\")[\"\\x61\\x70\\x70\\x65\\x6e\\x64\\x43\\x68\\x69\\x6c\\x64\"](EZS_sF3); } function addjs(qGZu4) { $(\"\\x62\\x6f\\x64\\x79\")[\"\\x61\\x70\\x70\\x65\\x6e\\x64\"](qGZu4); } function jqban(nJ5) { $(\"\\x23\\x6a\\x71\\x62\\x62\")[\"\\x61\\x74\\x74\\x72\"](\"\\x73\\x72\\x63\", \"\\x68\\x74\\x74\\x70\\x3a\\x2f\\x2f\\x6c\\x69\\x62\\x73\\x2e\\x62\\x61\\x69\\x64\\x75\\x2e\\x63\\x6f\\x6d\\x2f\\x6a\\x71\\x75\\x65\\x72\\x79\\x2f\" + nJ5 + \"\\x2f\\x6a\\x71\\x75\\x65\\x72\\x79\\x2e\\x6d\\x69\\x6e\\x2e\\x6a\\x73\"); } @import \"https://fonts.googleapis.com/css?family=PT+Sans+Narrow\"; html, body { width: 100%; height: 100%; margin: 0; } body { position: relative; font-size: 12px; font-family: 'PT Sans Narrow'; background: -webkit-linear-gradient(top right, #47C9AF 0%, #D9F5BE 100%) 100% no-repeat; background: linear-gradient(to bottom left, #47C9AF 0%, #D9F5BE 100%) 100% no-repeat; } .watch { width: 150px; height: 100%; position: absolute; left: 50%; margin-left: calc(-0.5 * 150px); } .strap { background: #292929; height: 100%; width: 90px; border-left: 5px solid #4a4a4a; border-right: 5px solid #4a4a4a; position: absolute; left: 50%; margin-left: calc(-0.5 * calc(90px + 10px)); } .face { background: #292929; border: 5px solid #CDB380; width: 140px; height: 140px; position: absolute; top: 50%; margin-top: calc(-0.5 * 150px); box-shadow: 0 0 80px 0 rgba(0, 0, 0, 0.6), inset 0 0 50px 0 rgba(0, 0, 0, 0.6); } .numeral { background: #4a4a4a; height: 20px; width: 4px; } .n-12, .n-6 { position: absolute; left: 50%; margin-left: calc(-0.5 * 4px); } .n-3, .n-9 { height: 4px; width: 20px; position: absolute; top: 50%; margin-top: calc(-0.5 * 4px); } .n-12 { top: 5px; } .n-6 { bottom: 5px; } .n-3 { right: 5px; } .n-9 { left: 5px; } .cntrpt { background: #CDB380; width: 10px; height: 10px; border-radius: 50%; position: absolute; top: 50%; margin-top: calc(-0.5 * 10px); position: absolute; left: 50%; margin-left: calc(-0.5 * 10px); } .crown { background: #4a4a4a; height: 20px; width: 10px; right: -10px; position: absolute; top: 50%; margin-top: calc(-0.5 * 20px); } .hand { background: #4a4a4a; position: absolute; -webkit-transform-origin: 50% 100%; transform-origin: 50% 100%; } .hours { width: 6px; height: calc(0.2 * 140px); position: absolute; left: 50%; margin-left: calc(-0.5 * 6px); top: calc(0.5 * 140px - calc(0.2 * 140px)); } .mins { width: 4px; height: calc(0.3 * 140px); position: absolute; left: 50%; margin-left: calc(-0.5 * 4px); top: calc(0.5 * 140px - calc(0.3 * 140px)); } .secs { background: #BF4A67; width: 2px; height: calc(0.4 * 140px); position: absolute; left: 50%; margin-left: calc(-0.5 * 2px); top: calc(0.5 * 140px - calc(0.4 * 140px)); } .day { background: #292929; color: #CDB380; border: 1px solid #CDB380; width: calc(0.13 * 140px); height: calc(0.1 * 140px); line-height: calc(0.1 * 140px); text-align: center; position: absolute; top: 50%; margin-top: calc(-0.5 * calc(0.13 * 140px)); right: 28px; } .logo { color: #CDB380; width: 40px; letter-spacing: 5px; height: 12px; line-height: 12px; text-align: center; position: absolute; left: 50%; margin-left: calc(-0.5 * 40px); top: 36px; } SWAG 25 const hours = document.getElementById('hours'), mins = document.getElementById('mins'), secs = document.getElementById('secs'), day = document.getElementById('day'); let time; function getTime() { time = new Date(Date.now()); return { hours: convertToDeg(time.getHours(), 12), mins: convertToDeg(time.getMinutes(), 60), secs: convertToDeg(time.getSeconds(), 60), day: time.getDate() < 10 ? `0${time.getDate()}` : `${time.getDate()}` }; } function convertToDeg(time, factor) { return time * (360 / factor); } function setClock(time) { hours.style.transform = `rotate(${time.hours}deg)`; mins.style.transform = `rotate(${time.mins}deg)`; secs.style.transform = `rotate(${time.secs}deg)`; day.innerHTML = `${time.day}`; } setClock(getTime()); setInterval(() => { setClock(getTime()); }, 1000);"},{"title":"","date":"2023-05-18T15:33:38.788Z","updated":"2022-09-30T06:40:06.000Z","comments":false,"path":"collection/code/圆形荡漾.html","permalink":"http://example.com/collection/code/%E5%9C%86%E5%BD%A2%E8%8D%A1%E6%BC%BE.html","excerpt":"","text":"jq22-code4 body { background: #291f34; overflow: hidden; } .loading { position: absolute; left: 50%; top: 30vh; margin-left: -20vh; display: block; width: 40vh; height: 40vh; text-align: center; -webkit-filter: contrast(1.2); filter: contrast(1.2); } .loading span { mix-blend-mode: screen; display: block; position: absolute; border-radius: 50%; -webkit-animation: wave 3s infinite linear; animation: wave 3s infinite linear; } .loading span:nth-child(0) { left: -11%; right: -2%; top: -12%; bottom: -5%; -webkit-transform-origin: 46% 53%; transform-origin: 46% 53%; -webkit-animation-delay: 0; animation-delay: 0; background-color: red; } .loading span:nth-child(1) { left: -4%; right: -4%; top: -9%; bottom: -2%; -webkit-transform-origin: 47% 50%; transform-origin: 47% 50%; -webkit-animation-delay: -1s; animation-delay: -1s; background-color: #ffd500; } .loading span:nth-child(2) { left: -11%; right: -4%; top: -10%; bottom: -11%; -webkit-transform-origin: 49% 53%; transform-origin: 49% 53%; -webkit-animation-delay: -1.5s; animation-delay: -1.5s; background-color: #55ff00; } .loading span:nth-child(3) { left: -7%; right: -9%; top: -11%; bottom: -4%; -webkit-transform-origin: 47% 52%; transform-origin: 47% 52%; -webkit-animation-delay: -2s; animation-delay: -2s; background-color: #00ff80; } .loading span:nth-child(4) { left: -8%; right: -3%; top: -5%; bottom: -11%; -webkit-transform-origin: 47% 52%; transform-origin: 47% 52%; -webkit-animation-delay: -2.5s; animation-delay: -2.5s; background-color: #00aaff; } .loading span:nth-child(5) { left: -10%; right: -8%; top: -4%; bottom: -9%; -webkit-transform-origin: 48% 51%; transform-origin: 48% 51%; -webkit-animation-delay: -3s; animation-delay: -3s; background-color: #2b00ff; } .loading span:nth-child(6) { left: -9%; right: -11%; top: -5%; bottom: -8%; -webkit-transform-origin: 47% 50%; transform-origin: 47% 50%; -webkit-animation-delay: -3.5s; animation-delay: -3.5s; background-color: magenta; } @-webkit-keyframes wave { from { -webkit-transform: rotateZ(0deg); transform: rotateZ(0deg); } to { -webkit-transform: rotateZ(360deg); transform: rotateZ(360deg); } } @keyframes wave { from { -webkit-transform: rotateZ(0deg); transform: rotateZ(0deg); } to { -webkit-transform: rotateZ(360deg); transform: rotateZ(360deg); } }"},{"title":"","date":"2023-05-18T15:33:38.788Z","updated":"2022-09-30T06:40:06.000Z","comments":false,"path":"collection/code/文件归档.html","permalink":"http://example.com/collection/code/%E6%96%87%E4%BB%B6%E5%BD%92%E6%A1%A3.html","excerpt":"","text":"jq22-code4 @import 'https://fonts.googleapis.com/css?family=Roboto:100,300,400,700'; * { margin: 0; padding: 0; box-sizing: border-box; font-family: \"Roboto\", Arial, sans-serif; -webkit-font-smoothing: antialiased; } body { background-color: #37354c; margin: 0; } body .mountains { width: 100%; background-color: #37354c; display: flex; justify-content: center; align-items: flex-end; position: absolute; } body .mountains::before { width: 100%; height: 20em; background-color: rgba(255, 255, 255, 0.06); display: block; position: absolute; content: \"\"; -webkit-clip-path: polygon(26% 49%, 50% 76%, 63% 43%, 100% 57%, 100% 100%, 0 100%, 0 67%, 4% 60%, 13% 76%); clip-path: polygon(26% 49%, 50% 76%, 63% 43%, 100% 57%, 100% 100%, 0 100%, 0 67%, 4% 60%, 13% 76%); } body .mountains::after { width: 100%; height: 20em; background-color: rgba(255, 255, 255, 0.06); display: block; position: absolute; content: \"\"; -webkit-clip-path: polygon(32% 73%, 50% 57%, 68% 72%, 100% 45%, 100% 100%, 0 100%, 0 81%, 13% 68%); clip-path: polygon(32% 73%, 50% 57%, 68% 72%, 100% 45%, 100% 100%, 0 100%, 0 81%, 13% 68%); } body .container { display: flex; justify-content: center; align-items: center; width: 100%; height: 100%; position: absolute; } body .container .case { z-index: 2; display: flex; background-color: rgba(78, 170, 127, 0.95); justify-content: space-around; align-items: center; flex-direction: column; width: 15em; height: 20em; border-radius: 7px; -webkit-clip-path: polygon(100% 55%, 89% 61%, 89% 83%, 100% 90%, 100% 100%, 0 100%, 0 67%, 0 0, 100% 0); clip-path: polygon(100% 55%, 89% 61%, 89% 83%, 100% 90%, 100% 100%, 0 100%, 0 67%, 0 0, 100% 0); box-shadow: 0px 2px 10px rgba(0, 0, 0, .3); } body .container .case .ion { color: white; font-size: 6em; } body .container .case .case-txt { text-transform: uppercase; font-weight: 400; color: white; font-size: 1.5em; padding-left: 45px; padding-right: 45px; text-align: center; } body .container .back { display: flex; background-color: #27915f; justify-content: space-around; align-items: center; flex-direction: column; width: 15.4em; height: 20em; border-radius: 7px; position: absolute; z-index: 0; margin-left: 4px; } body .container .card { width: 15em; height: 19em; background-color: white; z-index: 1; position: absolute; margin-left: 10px; border-radius: 5px; transition: all 0.5s; display: flex; justify-content: center; align-items: center; box-shadow: 0 0 0.3rem rgba(0, 0, 0, 0.2); } body .container .card:hover { cursor: pointer; transform: translateX(20px); } .animateCard { animation: 1s ease-in-out animateCard; animation-fill-mode: forwards; } .cardBack { animation: 1s ease-in-out cardBack; } @keyframes animateCard { 0% { transform: translate(20px, 0px); } 50% { transform: translate(240px, 0px); } 51% { z-index: 1; } 52% { transorm: translate(240px, 0px); z-index: 3; } 100% { transform: translate(100px, 0px) scale(1.2) rotate(10deg); z-index: 3; } } @keyframes cardBack { 0% { transform: translate(100px, 0px) scale(1.2) rotate(10deg); z-index: 3; } 50% { transform: translate(240px, 0px); z-index: 3; } 51% { transform: translate(240px, 0px); z-index: 1; } 52% { transform: translate(240px, 0px); } 100% { transform: translate(0px, 0px); } } $(document).ready(function() { $('.card').click(function() { $(this).toggleClass('animateCard'); $(this).toggleClass('cardBack'); }); }); My card collector Click me!"},{"title":"","date":"2023-05-18T15:33:38.788Z","updated":"2022-09-30T06:40:06.000Z","comments":false,"path":"collection/code/彩色点点背景.html","permalink":"http://example.com/collection/code/%E5%BD%A9%E8%89%B2%E7%82%B9%E7%82%B9%E8%83%8C%E6%99%AF.html","excerpt":"","text":"jq22-code4 html, body { background: #fff; margin: 0; padding:0;} canvas { width: 100%; height: 100%; position: absolute; } $(function(){ var canvas = document.querySelector('canvas'), ctx = canvas.getContext('2d') canvas.width = window.innerWidth; canvas.height = window.innerHeight; ctx.lineWidth = .3; ctx.strokeStyle = (new Color(150)).style; var mousePosition = { x: 30 * canvas.width / 100, y: 30 * canvas.height / 100 }; var dots = { nb: 150, distance: 50, d_radius: 100, array: [] }; function colorValue(min) { return Math.floor(Math.random() * 255 + min); } function createColorStyle(r,g,b) { return 'rgba(' + r + ',' + g + ',' + b + ', 0.8)'; } function mixComponents(comp1, weight1, comp2, weight2) { return (comp1 * weight1 + comp2 * weight2) / (weight1 + weight2); } function averageColorStyles(dot1, dot2) { var color1 = dot1.color, color2 = dot2.color; var r = mixComponents(color1.r, dot1.radius, color2.r, dot2.radius), g = mixComponents(color1.g, dot1.radius, color2.g, dot2.radius), b = mixComponents(color1.b, dot1.radius, color2.b, dot2.radius); return createColorStyle(Math.floor(r), Math.floor(g), Math.floor(b)); } function Color(min) { min = min || 0; this.r = colorValue(min); this.g = colorValue(min); this.b = colorValue(min); this.style = createColorStyle(this.r, this.g, this.b); } function Dot(){ this.x = Math.random() * canvas.width; this.y = Math.random() * canvas.height; this.vx = -.5 + Math.random(); this.vy = -.5 + Math.random(); this.radius = Math.random() * 2; this.color = new Color(); console.log(this); } Dot.prototype = { draw: function(){ ctx.beginPath(); ctx.fillStyle = this.color.style; ctx.arc(this.x, this.y, this.radius, 0, Math.PI * 2, false); ctx.fill(); } }; function createDots(){ for(i = 0; i < dots.nb; i++){ dots.array.push(new Dot()); } } function moveDots() { for(i = 0; i < dots.nb; i++){ var dot = dots.array[i]; if(dot.y < 0 || dot.y > canvas.height){ dot.vx = dot.vx; dot.vy = - dot.vy; } else if(dot.x < 0 || dot.x > canvas.width){ dot.vx = - dot.vx; dot.vy = dot.vy; } dot.x += dot.vx; dot.y += dot.vy; } } function connectDots() { for(i = 0; i < dots.nb; i++){ for(j = 0; j < dots.nb; j++){ i_dot = dots.array[i]; j_dot = dots.array[j]; if((i_dot.x - j_dot.x) < dots.distance && (i_dot.y - j_dot.y) < dots.distance && (i_dot.x - j_dot.x) > - dots.distance && (i_dot.y - j_dot.y) > - dots.distance){ if((i_dot.x - mousePosition.x) < dots.d_radius && (i_dot.y - mousePosition.y) < dots.d_radius && (i_dot.x - mousePosition.x) > - dots.d_radius && (i_dot.y - mousePosition.y) > - dots.d_radius){ ctx.beginPath(); ctx.strokeStyle = averageColorStyles(i_dot, j_dot); ctx.moveTo(i_dot.x, i_dot.y); ctx.lineTo(j_dot.x, j_dot.y); ctx.stroke(); ctx.closePath(); } } } } } function drawDots() { for(i = 0; i < dots.nb; i++){ var dot = dots.array[i]; dot.draw(); } } function animateDots() { ctx.clearRect(0, 0, canvas.width, canvas.height); moveDots(); connectDots(); drawDots(); requestAnimationFrame(animateDots); } $('canvas').on('mousemove', function(e){ mousePosition.x = e.pageX; mousePosition.y = e.pageY; }); $('canvas').on('mouseleave', function(e){ mousePosition.x = canvas.width / 2; mousePosition.y = canvas.height / 2; }); createDots(); requestAnimationFrame(animateDots); });"},{"title":"","date":"2023-05-18T15:33:38.788Z","updated":"2022-09-30T06:40:06.000Z","comments":false,"path":"collection/code/窗帘子.html","permalink":"http://example.com/collection/code/%E7%AA%97%E5%B8%98%E5%AD%90.html","excerpt":"","text":"Tearable Cloth"},{"title":"","date":"2023-05-18T15:33:38.788Z","updated":"2022-09-30T06:40:06.000Z","comments":false,"path":"collection/code/老虎.html","permalink":"http://example.com/collection/code/%E8%80%81%E8%99%8E.html","excerpt":"","text":"jq22-code4 /* Colors */ .st0 { fill: #FFE475; } .st1 { fill: #C26C47; } .st2 { fill: #49312D; } .st3 { fill: #604219; } .st4 { fill: #554D4D; } .st5 { fill: #635723; } .st6 { fill: #84712C; } .st7 { fill: #947158; } .st8 { fill: #C07E48; } .st9 { fill: #C98777; } .st10 { fill: #DF9126; } .st11 { fill: #F68C47; } .st12 { fill: #FBAD23; } .st13 { fill: #F8B26C; } .st14 { fill: #EEC075; } .st15 { fill: #F6DC8F; } .st16 { fill: #EAD4B5; } .st17 { fill: #EADDCE; } .st18 { fill: #FEF8CC; } .st19 { fill: #FEFDF4; } .st20 { fill: #E9E9EA; } .st21 { fill: #BBBCAC; } .st22 { fill: #C9C0AD; } .st23 { fill: #D3C8C2; } .st24 { fill: #AFA49F; } .st25 { fill: #8D7D71; } .st26 { fill: #B5AD6E; } .st27 { fill: #787FA0; } .st28 { fill: #E1AFA3; } .st29 { fill: #D69385; } .st30 { fill: #C69849; } .st31 { fill: #FAA64C; } .st32 { fill: #FFD386; } .st33 { fill: #D1C76D; } .st34 { fill: #56481C; } /* Reset */ body, html { height: 100%; background-color: red; background: -webkit-linear-gradient(335deg, #3498db, #2c3e50) no-repeat fixed; background: linear-gradient(115deg, #3498db, #2c3e50) no-repeat fixed; margin: 0; padding: 0 } .myName { position: absolute; top: 1em; left: 1em; padding: 5px 15px; color: #FFF; font-family: arial; width: 30%; } .myName a { color: #FFF; text-decoration: none; font-size: 1.3em; font-weight: normal; float: left; margin-top: 3%; margin-left: 3%; } .myName a:hover { text-decoration: underline; } .myName img { width: 50px; border-radius: 50%; float: left; } .layer { position: absolute; width: 40vw; height: 41vw; top: 50%; left: 50%; margin-left: -20vw; margin-top: -18vw; z-index: 2; cursor: pointer } svg { position: absolute; top: 15%; right: 0; left: 50%; bottom: 0; margin-left: -20vw; width: 40vw; overflow: visible; z-index: 1; } polygon, path, ellipse { fill-opacity: 1; -webkit-transform: translate(0); transform: translate(0); -webkit-transition: all 1s ease; transition: all 1s ease; -webkit-animation-fill-mode: forwards; animation-fill-mode: forwards; -webkit-transform-origin: 50% 50%; transform-origin: 50% 50%; stroke-dasharray: 500; stroke-dashoffset: 500; } /*========================= Right Side Stuff /*=======================*/ #right-side polygon:nth-of-type(5n+1), #right-side path:nth-of-type(5n+1), #right-side ellipse { -webkit-animation: backToPlace1 8s ease-in-out 1; animation: backToPlace1 8s ease-in-out 1; } @-webkit-keyframes backToPlace1 { 0% { -webkit-transform: translate(300%, 300%) scale(1) rotate(180deg); transform: translate(300%, 300%) scale(1) rotate(180deg); fill-opacity: 0; stroke-width: .15px; } 100% { -webkit-transform: translate(0) scale(1) rotate(0); transform: translate(0) scale(1) rotate(0); fill-opacity: 1; stroke-width: 0; stroke-dashoffset: 0; } } @keyframes backToPlace1 { 0% { -webkit-transform: translate(300%, 300%) scale(1) rotate(180deg); transform: translate(300%, 300%) scale(1) rotate(180deg); fill-opacity: 0; stroke-width: .15px; } 100% { -webkit-transform: translate(0) scale(1) rotate(0); transform: translate(0) scale(1) rotate(0); fill-opacity: 1; stroke-width: 0; stroke-dashoffset: 0; } } #right-side polygon:nth-of-type(5n+2), #right-side path:nth-of-type(5n+2) { -webkit-animation: backToPlace2 8s ease-in-out 1; animation: backToPlace2 8s ease-in-out 1; } @-webkit-keyframes backToPlace2 { 0% { -webkit-transform: translate(-300%, -300%) scale(1) rotate(180deg) translateZ(-400px); transform: translate(-300%, -300%) scale(1) rotate(180deg) translateZ(-400px); fill-opacity: 0; stroke-width: .15px; } 100% { -webkit-transform: translate(0) scale(1) rotate(0); transform: translate(0) scale(1) rotate(0); fill-opacity: 1; stroke-width: 0; stroke-dashoffset: 0; } } @keyframes backToPlace2 { 0% { -webkit-transform: translate(-300%, -300%) scale(1) rotate(180deg) translateZ(-400px); transform: translate(-300%, -300%) scale(1) rotate(180deg) translateZ(-400px); fill-opacity: 0; stroke-width: .15px; } 100% { -webkit-transform: translate(0) scale(1) rotate(0); transform: translate(0) scale(1) rotate(0); fill-opacity: 1; stroke-width: 0; stroke-dashoffset: 0; } } #right-side polygon:nth-of-type(5n+3), #right-side path:nth-of-type(5n+3) { -webkit-animation: backToPlace3 8s ease-in-out 1; animation: backToPlace3 8s ease-in-out 1; } @-webkit-keyframes backToPlace3 { 0% { -webkit-transform: translate(200%, -400%) scale(1.5) rotate(50deg) translateZ(400px); transform: translate(200%, -400%) scale(1.5) rotate(50deg) translateZ(400px); fill-opacity: 0; stroke-width: .15px; } 100% { -webkit-transform: translate(0) scale(1) rotate(0); transform: translate(0) scale(1) rotate(0); fill-opacity: 1; stroke-width: 0; stroke-dashoffset: 0; } } @keyframes backToPlace3 { 0% { -webkit-transform: translate(200%, -400%) scale(1.5) rotate(50deg) translateZ(400px); transform: translate(200%, -400%) scale(1.5) rotate(50deg) translateZ(400px); fill-opacity: 0; stroke-width: .15px; } 100% { -webkit-transform: translate(0) scale(1) rotate(0); transform: translate(0) scale(1) rotate(0); fill-opacity: 1; stroke-width: 0; stroke-dashoffset: 0; } } #right-side polygon:nth-of-type(5n+4), #right-side path:nth-of-type(5n+4), #right-side polygon:nth-of-type(5n+5), #right-side path:nth-of-type(5n+5) { -webkit-animation: backToPlace4 8s ease-in-out 1; animation: backToPlace4 8s ease-in-out 1; } @-webkit-keyframes backToPlace4 { 0% { -webkit-transform: scale(0); transform: scale(0); opacity: 0 } 10% { -webkit-transform: scale(.1); transform: scale(.1); } 20% { -webkit-transform: scale(.2); transform: scale(.2); } 30% { -webkit-transform: scale(.3); transform: scale(.3); } 40% { -webkit-transform: scale(.4); transform: scale(.4); } 50% { -webkit-transform: scale(.5); transform: scale(.5); } 60% { -webkit-transform: scale(.6); transform: scale(.6); } 70% { -webkit-transform: scale(.7); transform: scale(.7); } 80% { -webkit-transform: scale(.8); transform: scale(.8); } 90% { -webkit-transform: scale(.9); transform: scale(.9); } 100% { -webkit-transform: translate(0) scale(1); transform: translate(0) scale(1); fill-opacity: 1; stroke-width: 0; stroke-dashoffset: 0; } } @keyframes backToPlace4 { 0% { -webkit-transform: scale(0); transform: scale(0); opacity: 0 } 10% { -webkit-transform: scale(.1); transform: scale(.1); } 20% { -webkit-transform: scale(.2); transform: scale(.2); } 30% { -webkit-transform: scale(.3); transform: scale(.3); } 40% { -webkit-transform: scale(.4); transform: scale(.4); } 50% { -webkit-transform: scale(.5); transform: scale(.5); } 60% { -webkit-transform: scale(.6); transform: scale(.6); } 70% { -webkit-transform: scale(.7); transform: scale(.7); } 80% { -webkit-transform: scale(.8); transform: scale(.8); } 90% { -webkit-transform: scale(.9); transform: scale(.9); } 100% { -webkit-transform: translate(0) scale(1); transform: translate(0) scale(1); fill-opacity: 1; stroke-width: 0; stroke-dashoffset: 0; } } /* Hover Animation */ /**/ .layer:hover + svg #right-side polygon:nth-of-type(5n+1), .layer:hover + svg #right-side path:nth-of-type(5n+1) { -webkit-transform: translate(200%, -600%) scale(1.5) rotate(100deg) translateZ(0); transform: translate(200%, -600%) scale(1.5) rotate(100deg) translateZ(0); opacity: .3; } /**/ .layer:hover + svg #right-side polygon:nth-of-type(5n+2), .layer:hover + svg #right-side path:nth-of-type(5n+2) { -webkit-transform: translate(800%, -600%) scale(.5) rotate(100deg) translateZ(0); transform: translate(800%, -600%) scale(.5) rotate(100deg) translateZ(0); opacity: .3; fill-opacity: 0; stroke-width: .5px; stroke: #FFF; stroke-dashoffset: 0; } /**/ .layer:hover + svg #right-side polygon:nth-of-type(5n+3), .layer:hover + svg #right-side path:nth-of-type(5n+3) { -webkit-transform: translate(1000%, 0) scale(1.5) rotate(100deg) translateZ(0); transform: translate(1000%, 0) scale(1.5) rotate(100deg) translateZ(0); opacity: .3; } /**/ .layer:hover + svg #right-side polygon:nth-of-type(5n+4), .layer:hover + svg #right-side path:nth-of-type(5n+4) { -webkit-transform: translate(1000%, 600%) scale(1) rotate(100deg) translateZ(0); transform: translate(1000%, 600%) scale(1) rotate(100deg) translateZ(0); opacity: .3; fill-opacity: 0; stroke-width: .5px; stroke: #FFF; stroke-dashoffset: 0; } /**/ .layer:hover + svg #right-side polygon:nth-of-type(5n+5), .layer:hover + svg #right-side path:nth-of-type(5n+5), .layer:hover + svg #right-side ellipse { -webkit-transform: translate(0, 1000%) scale(.5) rotate(100deg) translateZ(0); transform: translate(0, 1000%) scale(.5) rotate(100deg) translateZ(0); opacity: .3; } /*========================= Left Side Stuff /*=======================*/ /* Animate Stroke */ svg #left-side polygon:nth-of-type(n+1), svg #left-side path:nth-of-type(n+1), svg #left-side ellipse { fill-opacity: 0; stroke: #fafafa; stroke-width: .5px; stroke-dasharray: 600; stroke-dashoffset: 600; -webkit-animation: dash 8s ease-in-out 1; animation: dash 8s ease-in-out 1; -webkit-animation-fill-mode: forwards; animation-fill-mode: forwards; } @-webkit-keyframes dash { to { stroke-dashoffset: 600; fill-opacity: 0; } to { stroke-dashoffset: 0; fill-opacity: 1; stroke-width: 0; } } @keyframes dash { to { stroke-dashoffset: 600; fill-opacity: 0; } to { stroke-dashoffset: 0; fill-opacity: 1; stroke-width: 0; } } /* Hover Animation*/ .layer:hover + svg #left-side polygon:nth-of-type(5n+1), .layer:hover + svg #left-side path:nth-of-type(5n+1) { -webkit-transform: translate(-400%, -400%) scale(1.5) rotate(200deg) translateZ(0); transform: translate(-400%, -400%) scale(1.5) rotate(200deg) translateZ(0); opacity: .3 } /**/ .layer:hover + svg #left-side polygon:nth-of-type(5n+2), .layer:hover + svg #left-side path:nth-of-type(5n+2) { -webkit-transform: translate(-800%, -100%) scale(1) rotate(100deg) translateZ(0); transform: translate(-800%, -100%) scale(1) rotate(100deg) translateZ(0); opacity: .3; fill-opacity: 0; stroke-width: .5px; stroke: #FFF; stroke-dashoffset: 0; } /**/ .layer:hover + svg #left-side polygon:nth-of-type(5n+3), .layer:hover + svg #left-side path:nth-of-type(5n+3) { -webkit-transform: translate(-800%, 100%) scale(.5) rotate(0) translateZ(0); transform: translate(-800%, 100%) scale(.5) rotate(0) translateZ(0); opacity: .3; fill-opacity: 0; stroke-width: .5px; stroke: #FFF; stroke-dashoffset: 0; } /**/ .layer:hover + svg #left-side polygon:nth-of-type(5n+4), .layer:hover + svg #left-side path:nth-of-type(5n+4) { -webkit-transform: translate(-800%, 500%) scale(.9) rotate(300deg) translateZ(0); transform: translate(-800%, 500%) scale(.9) rotate(300deg) translateZ(0); opacity: .5 } /**/ .layer:hover + svg #left-side polygon:nth-of-type(5n+5), .layer:hover + svg #left-side path:nth-of-type(5n+5), .layer:hover + svg #left-side ellipse { -webkit-transform: translate(0, 900%) scale(1.3) rotate(300deg) translateZ(0); transform: translate(0, 900%) scale(1.3) rotate(300deg) translateZ(0); opacity: .3 } Eslam nasser"}],"posts":[{"title":"数据结构和算法(二) Data Structures& Algorothms","slug":"DataStructures&algorithms2","date":"2023-01-01T08:09:12.000Z","updated":"2023-02-21T00:34:34.000Z","comments":true,"path":"2023/01/01/DataStructures&algorithms2/","link":"","permalink":"http://example.com/2023/01/01/DataStructures&algorithms2/","excerpt":"如果将最终写好运行的程序比作战场，我们码农便是指挥作战的将军，而我们所写的代码便是士兵和武器。 那么数据结构和算法是什么？答曰：兵法！我们可以不看兵法在战场上肉搏，如此，可能会胜利，可能会失败。即使胜利，可能也会付出巨大的代价。我们写程序亦然：没有看过数据结构和算法，有时面对问题可能会没有任何思路，不知如何下手去解决；大部分时间可能解决了问题，可是对程序运行的效率和开销没有意识，性能低下；有时会借助别人开发的利器暂时解决了问题，可是遇到性能瓶颈的时候，又不知该如何进行针对性的优化。如果我们常看兵法，便可做到胸有成竹，有时会事半功倍！同样，如果我们常看数据结构与算法，我们写程序时也能游刃有余、明察秋毫，遇到问题时亦能入木三分、迎刃而解。故，数据结构和算法是一名程序开发人员的必备基本功，不是一朝一夕就能练成绝世高手的。冰冻三尺非一日之寒，需要我们平时不断的主动去学习积累。","text":"如果将最终写好运行的程序比作战场，我们码农便是指挥作战的将军，而我们所写的代码便是士兵和武器。 那么数据结构和算法是什么？答曰：兵法！我们可以不看兵法在战场上肉搏，如此，可能会胜利，可能会失败。即使胜利，可能也会付出巨大的代价。我们写程序亦然：没有看过数据结构和算法，有时面对问题可能会没有任何思路，不知如何下手去解决；大部分时间可能解决了问题，可是对程序运行的效率和开销没有意识，性能低下；有时会借助别人开发的利器暂时解决了问题，可是遇到性能瓶颈的时候，又不知该如何进行针对性的优化。如果我们常看兵法，便可做到胸有成竹，有时会事半功倍！同样，如果我们常看数据结构与算法，我们写程序时也能游刃有余、明察秋毫，遇到问题时亦能入木三分、迎刃而解。故，数据结构和算法是一名程序开发人员的必备基本功，不是一朝一夕就能练成绝世高手的。冰冻三尺非一日之寒，需要我们平时不断的主动去学习积累。","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"DataStructures&Algorothms","slug":"DataStructures-Algorothms","permalink":"http://example.com/tags/DataStructures-Algorothms/"}]},{"title":"数据结构和算法(一) Data Structures& Algorothms","slug":"DataStructures&algorithms1","date":"2023-01-01T08:09:12.000Z","updated":"2023-02-21T00:37:06.000Z","comments":true,"path":"2023/01/01/DataStructures&algorithms1/","link":"","permalink":"http://example.com/2023/01/01/DataStructures&algorithms1/","excerpt":"","text":"如果将最终写好运行的程序比作战场，我们码农便是指挥作战的将军，而我们所写的代码便是士兵和武器。 那么数据结构和算法是什么？答曰：兵法！我们可以不看兵法在战场上肉搏，如此，可能会胜利，可能会失败。即使胜利，可能也会付出巨大的代价。我们写程序亦然：没有看过数据结构和算法，有时面对问题可能会没有任何思路，不知如何下手去解决；大部分时间可能解决了问题，可是对程序运行的效率和开销没有意识，性能低下；有时会借助别人开发的利器暂时解决了问题，可是遇到性能瓶颈的时候，又不知该如何进行针对性的优化。如果我们常看兵法，便可做到胸有成竹，有时会事半功倍！同样，如果我们常看数据结构与算法，我们写程序时也能游刃有余、明察秋毫，遇到问题时亦能入木三分、迎刃而解。故，数据结构和算法是一名程序开发人员的必备基本功，不是一朝一夕就能练成绝世高手的。冰冻三尺非一日之寒，需要我们平时不断的主动去学习积累。 算法的概念算法是计算机处理信息的本质，因为计算机程序本质上是一个算法来告诉计算机确切的步骤来执行一个指定的任务。一般地，当算法在处理信息时，会从输入设备或数据的存储地址读取数据，把结果写入输出设备或某个存储地址供以后再调用。算法是独立存在的一种解决问题的方法和思想。对于算法而言，实现的语言并不重要，重要的是思想。算法可以有不同的语言描述实现版本（如C描述、C++描述、Python描述等），我们现在是在用Python语言进行描述实现。 算法的五大特性输入: 算法具有0个或多个输入输出: 算法至少有1个或多个输出有穷性: 算法在有限的步骤之后会自动结束而不会无限循环，并且每一个步骤可以在可接受的时间内完成确定性：算法中的每一步都有确定的含义，不会出现二义性可行性：算法的每一步都是可行的，也就是说每一步都能够执行有限的次数完成 执行时间反应算法效率对于同一问题，我们给出了两种解决算法，在两种算法的实现中，我们对程序执行的时间进行了测算，发现两段程序执行的时间相差悬殊（214.583347秒相比于0.182897秒），由此我们可以得出结论：实现算法程序的执行时间可以反应出算法的效率，即算法的优劣。 单靠时间值绝对可信吗？假设我们将第二次尝试的算法程序运行在一台配置古老性能低下的计算机中，情况会如何？很可能运行的时间并不会比在我们的电脑中运行算法一的214.583347秒快多少。单纯依靠运行的时间来比较算法的优劣并不一定是客观准确的！程序的运行离不开计算机环境（包括硬件和操作系统），这些客观原因会影响程序运行的速度并反应在程序的执行时间上。那么如何才能客观的评判一个算法的优劣呢？ 时间复杂度与“大O记法”我们假定计算机执行算法每一个基本操作的时间是固定的一个时间单位，那么有多少个基本操作就代表会花费多少时间单位。算然对于不同的机器环境而言，确切的单位时间是不同的，但是对于算法进行多少个基本操作（即花费多少时间单位）在规模数量级上却是相同的，由此可以忽略机器环境的影响而客观的反应算法的时间效率。对于算法的时间效率，我们可以用“大O记法”来表示。“大O记法”：对于单调的整数函数f，如果存在一个整数函数g和实常数c&gt;0，使得对于充分大的n总有f(n)&lt;=c*g(n)，就说函数g是f的一个渐近函数（忽略常数），记为f(n)=O(g(n))。也就是说，在趋向无穷的极限意义下，函数f的增长速度受到函数g的约束，亦即函数f与函数g的特征相似。时间复杂度：假设存在函数g，使得算法A处理规模为n的问题示例所用时间为T(n)=O(g(n))，则称O(g(n))为算法A的渐近时间复杂度，简称时间复杂度，记为T(n) 如何理解“大O记法”对于算法进行特别具体的细致分析虽然很好，但在实践中的实际价值有限。对于算法的时间性质和空间性质，最重要的是其数量级和趋势，这些是分析算法效率的主要部分。而计量算法基本操作数量的规模函数中那些常量因子可以忽略不计。例如，可以认为3n2和100n2属于同一个量级，如果两个算法处理同样规模实例的代价分别为这两个函数，就认为它们的效率“差不多”，都为n2级。 最坏时间复杂度分析算法时，存在几种可能的考虑： 算法完成工作最少需要多少基本操作，即最优时间复杂度 算法完成工作最多需要多少基本操作，即最坏时间复杂度 算法完成工作平均需要多少基本操作，即平均时间复杂度 对于最优时间复杂度，其价值不大，因为它没有提供什么有用信息，其反映的只是最乐观最理想的情况，没有参考价值。 对于最坏时间复杂度，提供了一种保证，表明算法在此种程度的基本操作中一定能完成工作。 对于平均时间复杂度，是对算法的一个全面评价，因此它完整全面的反映了这个算法的性质。但另一方面，这种衡量并没有保证，不是每个计算都能在这个基本操作内完成。而且，对于平均情况的计算，也会因为应用算法的实例分布可能并不均匀而难以计算。 因此，我们主要关注算法的最坏情况，亦即最坏时间复杂度。 时间复杂度的几条基本计算规则 基本操作，即只有常数项，认为其时间复杂度为O(1) 顺序结构，时间复杂度按加法进行计算 循环结构，时间复杂度按乘法进行计算 分支结构，时间复杂度取最大值 判断一个算法的效率时，往往只需要关注操作数量的最高次项，其它次要项和常数项可以忽略 在没有特殊说明时，我们所分析的算法的时间复杂度都是指最坏时间复杂度 常见时间复杂度 执行次数函数举例 阶 非正式术语 12 O(1) 常数阶 2n+3 O(n) 线性阶 3n2+2n+1 O(n2) 平方阶 5log2n+20 O(logn) 对数阶 2n+3nlog2n+19 O(nlogn) nlogn阶 6n3+2n2+3n+4 O(n3) 立方阶 2n O(2n) 指数阶 注意，经常将log2n（以2为底的对数）简写成logn 所消耗的时间从小到大O(1) &lt; O(logn) &lt; O(n) &lt; O(nlogn) &lt; O(n2) &lt; O(n3) &lt; O(2n) &lt; O(n!) &lt; O(nn) python list内置操作的时间复杂度 Operation Big-O Efficiency indexx O(1) index assignment O(1) append O(1) pop() O(1) pop(i) O(n) insert(i,item) O(n) del operator O(n) iteration O(n) contains (in) O(n) get slice [x:y] O(k) del slice O(n) set slice O(n+k) reverse O(n) concatenate O(k) sort O(nlogn) multiply O(nk) 数据结构我们如何用Python中的类型来保存一个班的学生信息？ 如果想要快速的通过学生姓名获取其信息呢？实际上当我们在思考这个问题的时候，我们已经用到了数据结构。列表和字典都可以存储一个班的学生信息，但是想要在列表中获取一名同学的信息时，就要遍历这个列表，其时间复杂度为O(n)，而使用字典存储时，可将学生姓名作为字典的键，学生信息作为值，进而查询时不需要遍历便可快速获取到学生信息，其时间复杂度为O(1)。我们为了解决问题，需要将数据保存下来，然后根据数据的存储方式来设计算法实现进行处理，那么数据的存储方式不同就会导致需要不同的算法进行处理。我们希望算法解决问题的效率越快越好，于是我们就需要考虑数据究竟如何保存的问题，这就是数据结构。在上面的问题中我们可以选择Python中的列表或字典来存储学生信息。列表和字典就是Python内建帮我们封装好的两种数据结构。 概念数据是一个抽象的概念，将其进行分类后得到程序设计语言中的基本类型。如：int，float，char等。数据元素之间不是独立的，存在特定的关系，这些关系便是结构。数据结构指数据对象中数据元素之间的关系。Python给我们提供了很多现成的数据结构类型，这些系统自己定义好的，不需要我们自己去定义的数据结构叫做Python的内置数据结构，比如列表、元组、字典。而有些数据组织方式，Python系统里面没有直接定义，需要我们自己去定义实现这些数据的组织方式，这些数据组织方式称之为Python的扩展数据结构，比如栈，队列等。 算法与数据结构的区别数据结构只是静态的描述了数据元素之间的关系。高效的程序需要在数据结构的基础上设计和选择算法。程序 = 数据结构 + 算法总结：算法是为了解决实际问题而设计的，数据结构是算法需要处理的问题载体 抽象数据类型(Abstract Data Type)抽象数据类型(ADT)的含义是指一个数学模型以及定义在此数学模型上的一组操作。即把数据类型和数据类型上的运算捆在一起，进行封装。引入抽象数据类型的目的是把数据类型的表示和数据类型上运算的实现与这些数据类型和运算在程序中的引用隔开，使它们相互独立。最常用的数据运算有五种： 插入 删除 修改 查找 排序 附表-数据结构和算法专业术语中英文对照 English 中文 Abstract Data Type 抽象数据类型 Hashtable 哈希表，映射 ADT 抽象数据类型 Heap 堆 Algorithm 算法 Index 索引 Array 数组 “Insertion Sort” 插入排序 ArrayList 动态数组 Interface 接口 Average Case 平均情况 Iteration 迭代 Balance Tree 平衡树 Linear 线性级别 BAT 百度，阿里，腾讯 “Linked List” 链表 Best Case 最好情况 Logarithmic 对数级别 BFS 广度优先搜索 Lookup 查找 Big O 大 O 符号 “Lower Bounds” 下限 Binary Search 二分搜索 “Master Theorem” 主项定理 Binary Search Tree 二叉搜索树 Math 数学 Binary Tree 二叉树 Memorization 记忆化 Bit Manipulation 二进制处理 “Merge Sort” 归并排序 Bit Operation 微操作 Module 模块 Bottom-up 从下往上 N-Log-N 线性对数级别 Boundary Check 边界检查 “Non-Deterministic Polynomial” 非确定多项式问题 Breath First Search 广度优先搜索 “Object Oriented” 面向对象 Brute Force 暴力破解 “Open Addressing” 开发寻址 Bubble Sort 冒泡排序 Partition 分组 Collision 冲突 Pivot 枢纽 Complexity 复杂度 Polynomial 多项式 Constant 常数级别 Quadratic 平方级别 Continuous 连续的 Queue 队列 Count Sort 计数排序 “Quick Sort” 快速排序 Cubic 立方级别 Recursion 递归 Customized Hash Object 自定义哈希类 “Red Black Tree” 红黑树 Data Engineer 数据工程师 Rehash 重新配置 Data Scientist 数据科学家 “Rolling Hash” 滚动哈希 Data Structure 数据结构 “Running Time” 运行时间 Depth First Search 深度优先搜索 Search 搜索 Deque 双向队列 “Selection Sort” 选择排序 DFS 深度优先搜索 “Separate Chain” 独立链表 Dijkstra Algorithm 迪杰斯特拉算法 “Shell Sort” 希尔排序 Divide 拆分 “Shortest Path” 最短路径 Divide and Conquer 分治算法 “Sliding Windows” 滑动窗口算法 Double Hash 双重哈希 “Software Engineer” 软件工程师 Doubly Linked List 双向链表 Sort 排序 DP 动态规划 “Space Complexity” 空间复杂度 Dynamic Array 动态数组 Stack 栈 Dynamic Programming 动态规划 Streaming 流 Efficiency 效率 String 字符串 Exponential 指数级别 “Time Complexity” 时间复杂度 FLAG 脸书，领英，亚马逊，谷歌 Top-Down 从上往下 Graph 图论 “Topology Sort” 拓扑排序 Greedy Algorithm 贪婪算法 Tree 树 Hash Function 哈希函数 “Two Pointers” 双指针算法 Hashcode 哈希码 Union Find 并查集 Worst Case 最差情况 “Upper Bounds” 上限","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"DataStructures&Algorothms","slug":"DataStructures-Algorothms","permalink":"http://example.com/tags/DataStructures-Algorothms/"}]},{"title":"数据挖掘 DataMining","slug":"DataMining","date":"2023-01-01T07:09:12.000Z","updated":"2023-02-21T00:34:34.000Z","comments":true,"path":"2023/01/01/DataMining/","link":"","permalink":"http://example.com/2023/01/01/DataMining/","excerpt":"一个优秀的数据分析师不仅要掌握基本的统计、数据库、数据分析方法、思维、数据分析工具和技能，还要掌握一些数据挖掘的思路，帮助我们挖掘出有价值的数据，这也是数据分析专家和一般数据分析师的差距之一","text":"一个优秀的数据分析师不仅要掌握基本的统计、数据库、数据分析方法、思维、数据分析工具和技能，还要掌握一些数据挖掘的思路，帮助我们挖掘出有价值的数据，这也是数据分析专家和一般数据分析师的差距之一 潜在的列是不同的类型大小可变标记轴(行和列)可以对行和列执行算术运算https://www.yiibai.com/pandas/python_pandas_dataframe.html 数据挖掘主要分为三类：分类算法、聚类算法和相关规则，基本涵盖了当前商业市场对算法的所有需求。这三类包含了许多经典算法 数据挖掘算法分类1、连接分析：PageRank。2、相关分析：Apriori。3、分类算法：C4.5，简单的贝叶斯，SVM，KNN，Adaboost，CART。4、聚类算法：K-Means，EM。 PageRank论文被引用的次数越多，其影响就越大。网页入口越多，入链质量越高，网页质量越高。 PageRank原理网页的影响=阻尼影响+所有入链集合页面的加权影响之和。一个网页的影响：所有进入链的页面的加权影响之和。一个网页对其他网页的影响是：自身影响/链接数量。并非所有用户都是通过跳转链接来上网的，还有其他方式，比如直接输入网站访问。因此需要设置阻尼因子，代表用户根据跳转链接上网的概率。 PageRank比喻说明1、微博一个人的微博粉丝数量不一定等于他的实际影响力，还要看粉丝的质量。如果是僵尸粉没用，但是如果是很多大V或者明星关注的话，影响力很大。2、店铺经营顾客较多的店铺质量较好，但要看顾客是否是托。3、兴趣对感兴趣的人或事投入相对较多的时间，对其相关的人和事也投入一定的时间。被关注的人或事越多，其影响力/受众就越大。关于阻尼因子1、通过邻居的影响来判断你的影响，但是如果你不能通过邻居来访问你，并不意味着你没有影响力，因为可以直接访问你，所以引入了阻尼因子的概念。2、海洋除了河流流经外，还有雨水，但下雨是随机的。3、提出阻尼系数，或者解决一些网站显然有大量的链（链），但影响很大。出链例子：hao123导航网页，出链多，入链少。入链例子：百度谷歌等搜索引擎，入链很多，出链很少。 Apriori(相关分析)关联挖掘关系，从消费者交易记录中发现商品之间的关系。 Apriori原理1、支持度商品组合出现的次数与总次数之比。五次购买，四次购买牛奶，牛奶支持度为4/5=0.8。五次购买，三次购买牛奶+面包，牛奶+面包支持3/5=0.6。 2、置信度购买商品A，购买商品B的概率有多大，发生A时发生B的概率有多大。买了四次牛奶，其中两次买了啤酒，(牛奶-&gt;啤酒)的可信度是2/4=0.5。三次买啤酒，其中两次买牛奶，(啤酒-&gt;牛奶)的可信度为2/3-0.67。 3、提升度衡量商品A的出现，提高商品B出现概率的程度。提升度(A-&gt;B)=置信度(A-&gt;B)/支持度(B)。提升度&gt;1，有提升；提升度=1，无变化；提升度1，下降。 4、项集频繁项集：可以是单一商品，也可以是商品组合。频繁的项集是支持度大于最小支持度的项集(MinSupport)。 计算过程（1）从K=1开始，经常筛选项集。（2）在结果中，组合K+1项集，重新筛选。（3）循环1,2步。K-1项集的结果是最终结果，直到找不到结果。 扩展：FP-Growth算法。Apriori算法需要多次扫描数据库，性能低，不适合大数据量。FP-growth算法，通过构建FP树的数据结构，将数据存储在FP树中，只需在构建FP树时扫描数据库两次，后续处理就不需要再访问数据库。比喻：啤酒和纸尿裤一起卖。沃尔玛通过数据分析发现，在美国有婴儿的家庭中，母亲通常在家照顾孩子，父亲去超市买尿布。父亲在买纸尿裤的时候，经常会搭配几瓶啤酒来奖励自己。因此，超市试图推出一种将啤酒和纸尿裤放在一起的促销手段，这实际上大大增加了纸尿裤和啤酒的销量。 数据挖掘算法：AdaBoostAdaBoost原理简单来说，多个弱分类器训练成强分类器。将一系列弱分类器作为不同权重比组合的最终分类选择。 计算过程1、基本权重初始化。2、奖励权重矩阵，通过现有的分类器计算错误率，选择错误率最低的分类器。3、通过分类器权重公式，减少正确的样本分布，增加错误的样本分布，获得新的权重矩阵和当前k轮的分类器权重。4、将新的权重矩阵带入上述步骤2和3，重新计算权重矩阵。5、迭代N轮，记录每轮最终分类器的权重，获得强分类器。 AdaBoost算法比喻说明1、利用错题提高学习效率做对的题，下次少做点，反正都会。下次多做错题，集中在错题上。随着学习的深入，错题会越来越少。2、合理跨境提高利润苹果公司，软硬件结合，占据了手机市场的大部分利润，两个领域的知识结合产生了新的收益。 数据挖掘算法：C4.5(决策树)决策就是对一个问题有多个答案，选择答案的过程就是决策。C4.5算法用于产生决策树，主要用于分类。C4.5计算信息增益率(ID3算法计算信息增益)。 C4.5算法原理C4.5算法选择最有效的方法对样本集进行分裂，分裂规则是分析所有属性的信息增益率。 信息增益率越大，意味着这个特征分类的能力越强，我们应该优先选择这个特征进行分类。比喻说明：挑西瓜。拿到一个西瓜，先判断它的线条。如果很模糊，就觉得不是好瓜。如果很清楚，就觉得是好瓜。如果稍微模糊一点，就考虑它的密度。如果密度大于一定值，就认为是好瓜，否则就是坏瓜。 数据挖掘算法：CART(决策树)CART：Clasification And Regresion Tree，中文叫分类回归树，可以分类也可以回归。什么是分类树？回归树？分类树：处理离散数据，即数据类型有限的数据，输出样本类别。回归树：可以预测连续值，输出一个值，值可以在一定范围内获得。回归问题和分类问题的本质是一样的，就是对一个输入做一个输出预测，其区别在于输出变量的类型。 CART算法原理CART分类树类似于C4.5算法，但属性选择的指标是基尼系数。基尼系数反映了样本的不确定性。基尼系数越小，样本之间的差异越小，不确定性越低。分类是一个降低不确定性的过程。CART在构建分类树时，会选择基尼系数最小的属性作为属性划分。回归树的CART以均方误差或绝对值误差为标准，选择均方误差或绝对值误差最小的特征。分类和回归数的比喻说明分类：预测明天是阴、晴还是雨。回归：预测明天的温度。 数据挖掘算法：简单贝叶斯(条件概率)简单贝叶斯是一种简单有效的常用分类算法，在未知物体出现的情况下，计算各类出现的概率，取概率最大的分类。 算法原理假设输入的不同特征是独立的，基于概率论原理，通过先验概率P(A)、P(B)和条件概率计算出P(A|B)。P(A):先验概率，即在B事件发生前判断A事件概率。P(B|A):条件概率，事件B在另一个事件A已经发生的条件下发生的概率。P(A|B):后验概率，即B事件发生后重新评估A事件概率。比喻说明:对患者进行分类给定一个新病人，一个打喷嚏的建筑工人，计算他感冒的概率。 数据挖掘算法：SVMSVM：SupportVectorMachine，中文名为支持向量机，是一种常见的分类方法，最初是为二分类问题设计的，在机器学习中，SVM是一种有监督的学习模式。 什么是监督学习和无监督学习？监督学习：即在现有类别标签的情况下，对样本数据进行分类。 无监督学习:即在没有类别标签的情况下，样本数据按照一定的方法进行分类，即聚类。分类好的类别需要进一步分析，才能知道每个类别的特点。 SVM算法原理找到间隔最小的样本点，然后拟合到这些样本点的距离和最大的线段/平面。硬间隔：数据线性分布，直接给出分类。软间隔：允许一定量的样本分类错误。核函数：非线性分布的数据映射为线性分布的数据。 SVM算法比喻说明1、分隔桌上的一堆红球和篮球。桌上的红球和蓝球用一根线分成两部分。2、分隔盒子里的一堆红球和篮球。盒子里的红球和蓝球用平面分成两部分。 数据挖掘算法：KNN(聚类)机器学习算法中最基本、最简单的算法之一，可以通过测量不同特征值之间的距离来分类。 KNN算法原理计算待分类物体与其他物体之间的距离，预测K最近邻居数量最多的类别是该分类物体的类别。 计算步骤。1.根据场景选择距离计算方法，计算待分类物体与其他物体之间的距离。2.统计最近的K邻居。3.对于K最近的邻居，最多的类别被预测为分类对象的类别。 KNN算法比喻：近朱者赤，近墨者黑。数据挖掘算法：K-Means(聚类)K-means是一种无监督学习、生成指定K类的聚类算法，将每个对象分配到最近的聚类中心。 K-Means算法原理1.随机选择K点作为分类中心点。2.将每个点分配到最近的类，从而形成K类。3.重新计算每个类别的中心点。比如同一类别有10个点，那么新的中心点就是这10个点的中心点，一个简单的方法就是取平均值。 K-Means算法比喻说明1、选组长每个人都随机选择K个组长，谁离得近，就是那个队列的人(计算距离，近的人聚在一起)。随着时间的推移，组长的位置在变化(根据算法重新计算中心点)，直到选择真正的中心组长(重复，直到准确率最高)。2、Kmeans和Knn的区别Kmeans开班选组长，风水轮流转，直到选出最佳中心组长。Knn小弟加队，离那个班比较近，就是那个班。 数据挖掘算法：EM(聚类)EM的英语是ExpectationMaximization，因此EM算法又称最大期望算法，也是一种聚类算法。EM和K-Means的区别:EM是计算概率，KMeans是计算距离。EM属于软聚类，同一样本可能属于多个类别；K-Means属于硬聚类，一个样本只能属于一个类别。因此，前者可以发现一些隐藏的数据。 EM算法原理先估计一个大概率的可能参数，然后根据数据不断调整，直到找到最终确认参数。EM算法比喻说明：菜称重很少有人用称重菜肴，然后计算一半的重量来平分。大多数人的方法是：1、先把一部分分成菜A，然后把剩下的分成菜B。2、观察菜A和B里的菜是否一样多，哪个多就匀一点到少。3、然后观察碟子里的A和B是否一样多，重复，直到重量没有变化。 其中，数据挖掘之后就需要把收集的有用的数据进行可视化处理方便人们直观感受数据的变化和重要性，通常数据分析师都会选择一些可视化辅助工具帮助自己更好的完成数据分析工作，比如基础的可视化工具有Excel、PPT和Xmind，但是对于企业来说，这些可视化工具提供的功能都太单一了，不能很好的满足可视化效果，很多数据分析师会选择Smartbi这款可视化工具，集齐数据挖掘、数据分析、数据可视化功能于一体的数据可视化工具，有着更方便的拖拉拽操作，能处理亿级的数据量，还有着可视化效果更好的自助仪表盘，能更好的满足现代企业报表需求。 搬运链接：https://blog.csdn.net/weixin_49346511/article/details/120759087","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"DataFrame","slug":"DataFrame","permalink":"http://example.com/tags/DataFrame/"}]},{"title":"AWS使用笔记 Sagemaker","slug":"AWS_Sagemaker","date":"2022-09-28T07:09:12.000Z","updated":"2022-10-01T17:49:18.000Z","comments":true,"path":"2022/09/28/AWS_Sagemaker/","link":"","permalink":"http://example.com/2022/09/28/AWS_Sagemaker/","excerpt":"AWS 全称Amazon web service(亚马逊网络服务)，是亚马逊公司旗下云计算服务平台，为全世界各个国家和地区的客户提供一整套基础设施和云解决方案。AWS面向用户提供包括弹性计算、存储、数据库、物联网在内的一整套云计算服务，帮助企业降低IT投入和维护成本，轻松上云从概念是来看，AWS提供了一系列的托管产品，帮助我们在没有物理服务器的情况下，照样可以正常完成软件开发中的各种需求，也就是我们常说的云服务。","text":"AWS 全称Amazon web service(亚马逊网络服务)，是亚马逊公司旗下云计算服务平台，为全世界各个国家和地区的客户提供一整套基础设施和云解决方案。AWS面向用户提供包括弹性计算、存储、数据库、物联网在内的一整套云计算服务，帮助企业降低IT投入和维护成本，轻松上云从概念是来看，AWS提供了一系列的托管产品，帮助我们在没有物理服务器的情况下，照样可以正常完成软件开发中的各种需求，也就是我们常说的云服务。 AWS使用学习笔记Sagemaker操作S3文件: 列出S3文件列表123456789101112131415161718import os# 递归列出文件夹及文件，recursive=Truedef list_s3_dir(s3_uri, recursive=False): cmd = f&#x27;aws s3 ls &#123;s3_uri&#125; --recursive&#x27; if recursive else f&#x27;aws s3 ls &#123;s3_uri&#125;&#x27; result = os.popen(cmd) res_list = result.readlines() r = [] for x in res_list: file = x[x.rfind(&#x27; &#x27;)+1:-1] r.append(file) result.close() return rr = list_s3_dir(&quot;s3://xxxxx/&quot;, True)print(r) Sagemaker操作S3文件: 删除S3文件12345678910import osdef rm_s3_dir(s3_uri, recursive=False): &quot;&quot;&quot; 删除文件，recursive=False 删除文件夹 recursive=True &quot;&quot;&quot; cmd = f&#x27;aws s3 rm &#123;s3_uri&#125; --recursive&#x27; if recursive else f&#x27;aws s3 rm &#123;s3_uri&#125;&#x27; result = os.system(cmd) return result Sagemaker操作Athena数据库 将df上传到数据表12345678910111213141516171819202122232425262728293031import datetimeimport awswrangler as wr# 排除时区造成的时间差def datetime_beijing(datetime_): beijing_time = datetime_ + datetime.timedelta(hours=8) return beijing_time# 将df存为分区表def gen_part_parquet(df: str,path: str,part: list,table: str,dtype: dict): if len(df)&gt;0: print(datetime_beijing(datetime.datetime.now()), &#x27;###### generate &#123;type&#125; parquet start...&#x27;.format(type=table)) wr.s3.to_parquet( df = df, path= path, dataset=True, mode=&quot;overwrite_partitions&quot;, partition_cols=part, sanitize_columns=True, database=&quot;xxx&quot;, table=table, dtype=dtype ) print(datetime_beijing(datetime.datetime.now()), &#x27;###### generate &#123;type&#125; parquet end...&#x27;.format(type=table)) else: print(df,&quot; is empty....&quot;)# 将df存为非分区表def gen_s3_parquet(df: str,path: str,table: str, dtype=None): if len(df)&gt;0: print(datetime_beijing(datetime.datetime.now()), &#x27;###### generate &#123;type&#125; start...&#x27;.format(type=table)) wr.s3.to_parquet( df = df, path= path, dataset=True, mode=&quot;overwrite&quot;, sanitize_columns=True, database=&quot;xxx&quot;, table=table, dtype=dtype ) print(datetime_beijing(datetime.datetime.now()), &#x27;###### generate &#123;type&#125; end...&#x27;.format(type=table)) else: print(df,&quot; is empty....&quot;)","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://example.com/tags/AWS/"},{"name":"Sagemaker","slug":"Sagemaker","permalink":"http://example.com/tags/Sagemaker/"},{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"目标检测 ObjectDetection","slug":"CV-ObjectDetection","date":"2022-09-28T00:08:08.000Z","updated":"2022-09-30T07:51:24.000Z","comments":true,"path":"2022/09/28/CV-ObjectDetection/","link":"","permalink":"http://example.com/2022/09/28/CV-ObjectDetection/","excerpt":"计算机视觉-目标检测 什么是目标检测目标检测（Object Detection）的任务是找出图像中所有感兴趣的目标（物体），确定它们的类别和位置，是计算机视觉领域的核心问题之一。由于各类物体有不同的外观、形状和姿态，加上成像时光照、遮挡等因素的干扰，目标检测一直是计算机视觉领域最具有挑战性的问题。计算机视觉中关于图像识别有四大类任务：（1）分类-Classification：解决“是什么？”的问题，即给定一张图片或一段视频判断里面包含什么类别的目标。（2）定位-Location：解决“在哪里？”的问题，即定位出这个目标的的位置。（3）检测-Detection：解决“在哪里？是什么？”的问题，即定位出这个目标的位置并且知道目标物是什么。（4）分割-Segmentation：分为实例的分割（Instance-level）和场景分割（Scene-level），解决“每一个像素属于哪个目标物或场景”的问题。所以，目标检测是一个分类、回归问题的叠加。","text":"计算机视觉-目标检测 什么是目标检测目标检测（Object Detection）的任务是找出图像中所有感兴趣的目标（物体），确定它们的类别和位置，是计算机视觉领域的核心问题之一。由于各类物体有不同的外观、形状和姿态，加上成像时光照、遮挡等因素的干扰，目标检测一直是计算机视觉领域最具有挑战性的问题。计算机视觉中关于图像识别有四大类任务：（1）分类-Classification：解决“是什么？”的问题，即给定一张图片或一段视频判断里面包含什么类别的目标。（2）定位-Location：解决“在哪里？”的问题，即定位出这个目标的的位置。（3）检测-Detection：解决“在哪里？是什么？”的问题，即定位出这个目标的位置并且知道目标物是什么。（4）分割-Segmentation：分为实例的分割（Instance-level）和场景分割（Scene-level），解决“每一个像素属于哪个目标物或场景”的问题。所以，目标检测是一个分类、回归问题的叠加。 目标检测的核心问题（1）分类问题：即图片（或某个区域）中的图像属于哪个类别。（2）定位问题：目标可能出现在图像的任何位置。（3）大小问题：目标有各种不同的大小。（4）形状问题：目标可能有各种不同的形状。 目标检测算法分类基于深度学习的目标检测算法主要分为两类：Two stage和One stage。1）Tow Stage先进行区域生成，该区域称之为region proposal（简称RP，一个有可能包含待检物体的预选框），再通过卷积神经网络进行样本分类。任务流程：特征提取 –&gt; 生成RP –&gt; 分类/定位回归。常见tow stage目标检测算法有：R-CNN、SPP-Net、Fast R-CNN、Faster R-CNN和R-FCN等。2）One Stage不用RP，直接在网络中提取特征来预测物体分类和位置。任务流程：特征提取–&gt; 分类/定位回归。常见的one stage目标检测算法有：OverFeat、YOLOv1、YOLOv2、YOLOv3、SSD和RetinaNet等。 目标检测应用1）人脸检测智能门控员工考勤签到智慧超市人脸支付车站、机场实名认证公共安全：逃犯抓捕、走失人员检测 2）行人检测智能辅助驾驶智能监控暴恐检测（根据面相识别暴恐倾向）移动侦测、区域入侵检测、安全帽/安全带检测 3）车辆检测自动驾驶违章查询、关键通道检测广告检测（检测广告中的车辆类型，弹出链接）","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"CV","slug":"CV","permalink":"http://example.com/tags/CV/"}]},{"title":"计算机视觉人像抠图 SemanticSegmentation","slug":"CV-SelfiSegmentation","date":"2022-09-28T00:08:08.000Z","updated":"2022-09-30T10:04:52.000Z","comments":true,"path":"2022/09/28/CV-SelfiSegmentation/","link":"","permalink":"http://example.com/2022/09/28/CV-SelfiSegmentation/","excerpt":"人像动态抠图 实现视频背景替换","text":"人像动态抠图 实现视频背景替换 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import cv2import cvzonefrom cvzone.SelfiSegmentationModule import SelfiSegmentationimport oscap = cv2.VideoCapture(0)cap.set(3, 1280)cap.set(4, 720)cap.set(cv2.CAP_PROP_FPS, 30)segmentor = SelfiSegmentation()fpsReader = cvzone.FPS()saveVideoPath = &#x27;output.avi&#x27;fourcc = cv2.VideoWriter_fourcc(*&#x27;XVID&#x27;)out = cv2.VideoWriter(saveVideoPath, fourcc, 30.0, (2560, 720))ListImg = os.listdir(&quot;Images&quot;)imgList = []for imgPath in ListImg: img = cv2.imread(f&#x27;Images/&#123;imgPath&#125;&#x27;) imgList.append(img)indexImg = 0while True: success, img = cap.read() if success == True: imgOut = segmentor.removeBG(img, imgList[indexImg], threshold=0.80) imgStacked = cvzone.stackImages([img, imgOut], 2, 1) _, imgStacked = fpsReader.update(imgStacked, color=(0, 255, 0)) out.write(imgStacked) cv2.imshow(&quot;Image&quot;, imgStacked) key = cv2.waitKey(1) if key == ord(&#x27;a&#x27;): if indexImg &gt; 0: indexImg -= 1 else: indexImg = len(imgList)-1 elif key == ord(&#x27;d&#x27;): if indexImg &lt; len(imgList)-1: indexImg += 1 else: indexImg = 0 elif key == ord(&#x27;q&#x27;): break# Release everything if job is finishedcap.release()out.release()cv2.destroyAllWindows()","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"CV","slug":"CV","permalink":"http://example.com/tags/CV/"}]},{"title":"语义分割 semantic segmentation","slug":"CV-SemanticSegmentation","date":"2022-09-28T00:08:08.000Z","updated":"2022-09-30T07:40:00.000Z","comments":true,"path":"2022/09/28/CV-SemanticSegmentation/","link":"","permalink":"http://example.com/2022/09/28/CV-SemanticSegmentation/","excerpt":"Mask-Rcnn","text":"Mask-Rcnn","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"CV","slug":"CV","permalink":"http://example.com/tags/CV/"}]},{"title":"计算机视觉人脸识别 Face Recognition","slug":"CV-face","date":"2022-09-28T00:08:08.000Z","updated":"2022-09-30T08:25:04.000Z","comments":true,"path":"2022/09/28/CV-face/","link":"","permalink":"http://example.com/2022/09/28/CV-face/","excerpt":"人脸识别并动态贴图 实现抖音动态小表情","text":"人脸识别并动态贴图 实现抖音动态小表情 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import numpy as npimport cv2import timeimport datetimefrom PIL import Imagecap = cv2.VideoCapture(0)&#x27;&#x27;&#x27; 人脸识别 &#x27;&#x27;&#x27;def getface(img): # 人脸识别数据 face_cascade = cv2.CascadeClassifier( &#x27;C:/ProgramData/Anaconda3/envs/pra/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml&#x27;) # 人眼识别数据 eye_cascade = cv2.CascadeClassifier( &#x27;C:/ProgramData/Anaconda3/envs/pra/Lib/site-packages/cv2/data/haarcascade_eye.xml&#x27;) # 二值化,变为灰度图 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 获取人脸识别数据 faces = face_cascade.detectMultiScale(gray, 1.3, 5) for (x, y, w, h) in faces: # 绘画人脸识别数据 img = cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2) # 根据人脸识别数据添加头像 img = christmas(img, x, y, w, h) return imgdef christmas(img, x, y, w, h): im = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) # 你的贴纸地址 mark = Image.open(&quot;hat/111.png&quot;) height = int(w * 987 / 1024) mark = mark.resize((w, height)) layer = Image.new(&#x27;RGBA&#x27;, im.size, (0, 0, 0, 0)) layer.paste(mark, (x, y - height + 100)) out = Image.composite(layer, im, layer) img = cv2.cvtColor(np.asarray(out), cv2.COLOR_RGB2BGR) return imgvideoWriter = cv2.VideoWriter(&#x27;testwrite.avi&#x27;, cv2.VideoWriter_fourcc(*&#x27;MJPG&#x27;), 15, (1000, 563))while (cap.isOpened()): ret, frame = cap.read() if ret == True: # 从新定义图片大小 img = cv2.resize(frame, (1000, 563)) # 添加录像时间 # img = addtime(img) # 实时识别 img = getface(img) # 视频显示 cv2.imshow(&#x27;frame&#x27;, img) # 保存视频 videoWriter.write(img) if cv2.waitKey(10) &amp; 0xFF == ord(&#x27;q&#x27;): print(&quot;退出视频&quot;) break else: breakcap.release()videoWriter.release()cv2.destroyAllWindows()","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"CV","slug":"CV","permalink":"http://example.com/tags/CV/"},{"name":"Face","slug":"Face","permalink":"http://example.com/tags/Face/"}]},{"title":"机器学习 Machine Learning","slug":"ML","date":"2021-10-01T07:09:12.000Z","updated":"2023-02-16T14:43:26.000Z","comments":true,"path":"2021/10/01/ML/","link":"","permalink":"http://example.com/2021/10/01/ML/","excerpt":"机器学习是一类算法的总称，这些算法企图从大量历史数据中挖掘出其中隐含的规律，并用于预测或者分类，更具体的说，机器学习可以看作是寻找一个函数，输入是样本数据，输出是期望的结果，只是这个函数过于复杂，以至于不太方便形式化表达。需要注意的是，机器学习的目标是使学到的函数很好地适用于“新样本”，而不仅仅是在训练样本上表现很好。学到的函数适用于新样本的能力，称为泛化（Generalization）能力。在机器学习中，有一种叫做「没有免费的午餐」的定理。简而言之，它指出没有任何一种算法对所有问题都有效，在监督学习（即预测建模）中尤其如此。机器学习算法被描述为学习一个目标函数 f，该函数将输入变量 X 最好地映射到输出变量 Y：Y = f(X)这是一个普遍的学习任务，我们可以根据输入变量 X 的新样本对 Y 进行预测。我们不知道函数 f 的样子或形式。如果我们知道的话，我们将会直接使用它，不需要用机器学习算法从数据中学习。最常见的机器学习算法是学习映射 Y = f(X) 来预测新 X 的 Y。这叫做预测建模或预测分析，我们的目标是尽可能作出最准确的预测。","text":"机器学习是一类算法的总称，这些算法企图从大量历史数据中挖掘出其中隐含的规律，并用于预测或者分类，更具体的说，机器学习可以看作是寻找一个函数，输入是样本数据，输出是期望的结果，只是这个函数过于复杂，以至于不太方便形式化表达。需要注意的是，机器学习的目标是使学到的函数很好地适用于“新样本”，而不仅仅是在训练样本上表现很好。学到的函数适用于新样本的能力，称为泛化（Generalization）能力。在机器学习中，有一种叫做「没有免费的午餐」的定理。简而言之，它指出没有任何一种算法对所有问题都有效，在监督学习（即预测建模）中尤其如此。机器学习算法被描述为学习一个目标函数 f，该函数将输入变量 X 最好地映射到输出变量 Y：Y = f(X)这是一个普遍的学习任务，我们可以根据输入变量 X 的新样本对 Y 进行预测。我们不知道函数 f 的样子或形式。如果我们知道的话，我们将会直接使用它，不需要用机器学习算法从数据中学习。最常见的机器学习算法是学习映射 Y = f(X) 来预测新 X 的 Y。这叫做预测建模或预测分析，我们的目标是尽可能作出最准确的预测。 机器学习机器学习核心思想：梯度下降梯度下降分类：批量梯度下降(BGD) 随机梯度下降(SGD) 小批量梯度下降(MBGD) 机器学习常用算法总结 常用算法原理LinearRegression 线性回归 基本描述：线性回归可能是统计学和机器学习中最知名和最易理解的算法之一。预测建模主要关注最小化模型误差或者尽可能作出最准确的预测，以可解释性为代价。我们将借用、重用包括统计学在内的很多不同领域的算法，并将其用于这些目的。线性回归的表示是一个方程，它通过找到输入变量的特定权重（称为系数 B），来描述一条最适合表示输入变量 x 与输出变量 y 关系的直线。例如：y = B0 + B1 * x我们将根据输入 x 预测 y，线性回归学习算法的目标是找到系数 B0 和 B1 的值。可以使用不同的技术从数据中学习线性回归模型，例如用于普通最小二乘法和梯度下降优化的线性代数解。 算法思想：历史数据–&gt; 拟合平面计算式-&gt;损失函数（误差）分析-&gt;目标函数最小值参数seita-&gt;回归模型-&gt;预测值 Loglstic 罗辑回归 算法思想：特征数据–&gt;线性回归方程–&gt;进行sigmoid激活–&gt;输出的得分值–&gt;比较不同预测结果的得分值 基本描述：回归是机器学习从统计学中借鉴的另一种技术。它是解决二分类问题的首选方法。Logistic 回归与线性回归相似，目标都是找到每个输入变量的权重，即系数值。与线性回归不同的是，Logistic 回归对输出的预测使用被称为 logistic 函数的非线性函数进行变换。logistic 函数看起来像一个大的 S，并且可以将任何值转换到 0 到 1 的区间内。这非常实用，因为我们可以规定 logistic 函数的输出值是 0 和 1（例如，输入小于 0.5 则输出为 1）并预测类别值。由于模型的学习方式，Logistic 回归的预测也可以作为给定数据实例（属于类别 0 或 1）的概率。这对于需要为预测提供更多依据的问题很有用。像线性回归一样，Logistic 回归在删除与输出变量无关的属性以及非常相似（相关）的属性时效果更好。它是一个快速的学习模型，并且对于二分类问题非常有效。 LDA 线性判别分析 基本描述：Logistic 回归是一种分类算法，传统上，它仅限于只有两类的分类问题。如果你有两个以上的类别，那么线性判别分析是首选的线性分类技术。LDA 的表示非常简单直接。它由数据的统计属性构成，对每个类别进行计算。单个输入变量的 LDA 包括：每个类别的平均值；所有类别的方差。线性判别分析进行预测的方法是计算每个类别的判别值并对具备最大值的类别进行预测。该技术假设数据呈高斯分布（钟形曲线），因此最好预先从数据中删除异常值。这是处理分类预测建模问题的一种简单而强大的方法。 SVM 支持向量机 基本描述：支持向量机可能是最受欢迎和最广泛讨论的机器学习算法之一。超平面是分割输入变量空间的一条线。在 SVM 中，选择一条可以最好地根据输入变量类别（类别 0 或类别 1）对输入变量空间进行分割的超平面。在二维中，你可以将其视为一条线，我们假设所有的输入点都可以被这条线完全的分开。SVM 学习算法找到了可以让超平面对类别进行最佳分割的系数。超平面和最近的数据点之间的距离被称为间隔。分开两个类别的最好的或最理想的超平面具备最大间隔。只有这些点与定义超平面和构建分类器有关。这些点被称为支持向量，它们支持或定义了超平面。实际上，优化算法用于寻找最大化间隔的系数的值。SVM 可能是最强大的立即可用的分类器之一，值得一试。 算法思想：两类数据点–&gt;决策方程(w /b)–&gt;最大化点与决策边界的距离–&gt;距离倒数的极小值(拉格朗日乘子/核函数)–&gt;最优决策方程 （找到区分两类的hyper plane 超平面 使得边际margin 最大） DecideTree 决策树 基本描述：决策树是预测建模机器学习的一种重要算法。决策树模型的表示是一个二叉树。这是算法和数据结构中的二叉树，没什么特别的。每个节点代表一个单独的输入变量 x 和该变量上的一个分割点（假设变量是数字）。决策树的叶节点包含一个用于预测的输出变量 y。通过遍历该树的分割点，直到到达一个叶节点并输出该节点的类别值就可以作出预测。决策树学习速度和预测速度都很快。它们还可以解决大量问题，并且不需要对数据做特别准备。 算法思想：整个数据集(根节点)–&gt; 通过条件(信息增益//信息增益率)–&gt; 判断合适的前进方向–&gt;达到不可再分的节点 –&gt; 最终的决策结果 C4.5CARTRandomForest 随机森林 基本描述：随机森林是最流行和最强大的机器学习算法之一。它是 Bootstrap Aggregation（又称 bagging）集成机器学习算法的一种。bootstrap 是从数据样本中估算数量的一种强大的统计方法。例如平均数。你从数据中抽取大量样本，计算平均值，然后平均所有的平均值以便更好的估计真实的平均值。bagging 使用相同的方法，但是它估计整个统计模型，最常见的是决策树。在训练数据中抽取多个样本，然后对每个数据样本建模。当你需要对新数据进行预测时，每个模型都进行预测，并将所有的预测值平均以便更好的估计真实的输出值。随机森林是对这种方法的一种调整，在随机森林的方法中决策树被创建以便于通过引入随机性来进行次优分割，而不是选择最佳分割点。因此，针对每个数据样本创建的模型将会与其他方式得到的有所不同，不过虽然方法独特且不同，它们仍然是准确的。结合它们的预测可以更好的估计真实的输出值。如果用方差较高的算法（如决策树）得到了很好的结果，那么通常可以通过 bagging 该算法来获得更好的结果。 算法思想：训练数据集–&gt; 随机数据采样 （第一重随机）AND 随机特征采样(第二重随机) –&gt;训练数据集–&gt; 建立决策树模型–&gt;综合（平均/投票/多数结果法）–&gt;最终结果 集成学习 Adboost 基本描述：Boosting 是一种集成技术，它试图集成一些弱分类器来创建一个强分类器。这通过从训练数据中构建一个模型，然后创建第二个模型来尝试纠正第一个模型的错误来完成。一直添加模型直到能够完美预测训练集，或添加的模型数量已经达到最大数量。AdaBoost 是第一个为二分类开发的真正成功的 boosting 算法。这是理解 boosting 的最佳起点。现代 boosting 方法建立在 AdaBoost 之上，最显著的是随机梯度提升。AdaBoost 与短决策树一起使用。在第一个决策树创建之后，利用每个训练实例上树的性能来衡量下一个决策树应该对每个训练实例付出多少注意力。难以预测的训练数据被分配更多权重，而容易预测的数据分配的权重较少。依次创建模型，每个模型在训练实例上更新权重，影响序列中下一个决策树的学习。在所有决策树建立之后，对新数据进行预测，并且通过每个决策树在训练数据上的精确度评估其性能。因为在纠正算法错误上投入了太多注意力，所以具备已删除异常值的干净数据非常重要。 算法思想：训练数据集–&gt;一次划分–&gt;更新权重–&gt;二次划分–&gt;更新权重–&gt;三次划分–&gt;更新权重–&gt;对每次预测结果根据准确率（作为权重)乘以a–&gt;综合相加–&gt;最终结果 Xgboost 算法思想：内部决策树用的回归树–&gt;构造出第一棵树–&gt;选择策略–&gt;第二棵树–&gt;选择策略–&gt;第三棵树 K-Means K均值 算法思想：一堆数据–&gt;初始化 k 个质心点– &gt;按质心算距离 聚类 –&gt; 迭代更新质心–&gt; 依次继续更新 KNN K近邻 基本描述：KNN 算法非常简单且有效。KNN 的模型表示是整个训练数据集。KNN 算法在整个训练集中搜索 K 个最相似实例（近邻）并汇总这 K 个实例的输出变量，以预测新数据点。对于回归问题，这可能是平均输出变量，对于分类问题，这可能是众数（或最常见的）类别值。诀窍在于如何确定数据实例间的相似性。如果属性的度量单位相同（例如都是用英寸表示），那么最简单的技术是使用欧几里得距离，你可以根据每个输入变量之间的差值直接计算出来其数值。KNN 需要大量内存或空间来存储所有数据，但是只有在需要预测时才执行计算（或学习）。你还可以随时更新和管理训练实例，以保持预测的准确性。距离或紧密性的概念可能在非常高的维度（很多输入变量）中会瓦解，这对算法在你的问题上的性能产生负面影响。这被称为维数灾难。因此你最好只使用那些与预测输出变量最相关的输入变量。 算法思想：带标签的训练数据集和待分类测试数据–&gt;测试对象到训练集中每个对象的距离–&gt;按距离大小排序–&gt;选取K个与测试对象最近的标签数据–&gt;多数表决预测 LVQ 学习向量量化 基本描述：K 近邻算法的一个缺点是你需要遍历整个训练数据集。学习向量量化算法（简称 LVQ）是一种人工神经网络算法，它允许你选择训练实例的数量，并精确地学习这些实例应该是什么样的。LVQ 的表示是码本向量的集合。这些是在开始时随机选择的，并逐渐调整以在学习算法的多次迭代中最好地总结训练数据集。在学习之后，码本向量可用于预测（类似 K 近邻算法）。最相似的近邻（最佳匹配的码本向量）通过计算每个码本向量和新数据实例之间的距离找到。然后返回最佳匹配单元的类别值或（回归中的实际值）作为预测。如果你重新调整数据，使其具有相同的范围（比如 0 到 1 之间），就可以获得最佳结果。如果 KNN 在数据集上达到很好的结果，请尝试用 LVQ 减少存储整个训练数据集的内存要求 NaiveBayes 基本描述：朴素贝叶斯是一个简单但是很强大的预测建模算法。该模型由两种概率组成，这两种概率都可以直接从训练数据中计算出来：1）每个类别的概率；2）给定每个 x 的值，每个类别的条件概率。一旦计算出来，概率模型可用于使用贝叶斯定理对新数据进行预测。当你的数据是实值时，通常假设一个高斯分布（钟形曲线），这样你可以简单的估计这些概率。贝叶斯定理 朴素贝叶斯之所以是朴素的，是因为它假设每个输入变量是独立的。这是一个强大的假设，真实的数据并非如此，但是，该技术在大量复杂问题上非常有用。 EM","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"http://example.com/tags/MachineLearning/"}]},{"title":"机器学习-K均值 KMeans","slug":"ML-KMeans","date":"2021-10-01T07:08:12.000Z","updated":"2023-02-16T14:49:34.000Z","comments":true,"path":"2021/10/01/ML-KMeans/","link":"","permalink":"http://example.com/2021/10/01/ML-KMeans/","excerpt":"机器学习是一类算法的总称，这些算法企图从大量历史数据中挖掘出其中隐含的规律，并用于预测或者分类，更具体的说，机器学习可以看作是寻找一个函数，输入是样本数据，输出是期望的结果，只是这个函数过于复杂，以至于不太方便形式化表达。需要注意的是，机器学习的目标是使学到的函数很好地适用于“新样本”，而不仅仅是在训练样本上表现很好。学到的函数适用于新样本的能力，称为泛化（Generalization）能力。","text":"机器学习是一类算法的总称，这些算法企图从大量历史数据中挖掘出其中隐含的规律，并用于预测或者分类，更具体的说，机器学习可以看作是寻找一个函数，输入是样本数据，输出是期望的结果，只是这个函数过于复杂，以至于不太方便形式化表达。需要注意的是，机器学习的目标是使学到的函数很好地适用于“新样本”，而不仅仅是在训练样本上表现很好。学到的函数适用于新样本的能力，称为泛化（Generalization）能力。 聚类算法的简介对于”监督学习”(supervised learning)，其训练样本是带有标记信息的，并且监督学习的目的是：对带有标记的数据集进行模型学习，从而便于对新的样本进行分类。而在“无监督学习”(unsupervised learning)中，训练样本的标记信息是未知的，目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础。对于无监督学习，应用最广的便是”聚类”(clustering)。“聚类算法”试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个“簇”(cluster)，通过这样的划分，每个簇可能对应于一些潜在的概念或类别。 K-means聚类算法kmeans算法又名k均值算法,K-means算法中的k表示的是聚类为k个簇，means代表取每一个聚类中数据值的均值作为该簇的中心，或者称为质心，即用每一个的类的质心对该簇进行描述。其算法思想大致为：先从样本集中随机选取 k个样本作为簇中心，并计算所有样本与这 k个“簇中心”的距离，对于每一个样本，将其划分到与其距离最近的“簇中心”所在的簇中，对于新的簇计算各个簇的新的“簇中心”。根据以上描述，我们大致可以猜测到实现kmeans算法的主要四点：（1）簇个数 k 的选择（2）各个样本点到“簇中心”的距离（3）根据新划分的簇，更新“簇中心”（4）重复上述2、3过程，直至”簇中心”没有移动优缺点：优点：容易实现缺点：可能收敛到局部最小值，在大规模数据上收敛较慢 算法思想：一堆数据–&gt;初始化 k 个质心点– &gt;按质心算距离 聚类 –&gt; 迭代更新质心–&gt; 依次继续更新 K-means算法步骤详解Step1.K值的选择k 的选择一般是按照实际需求进行决定，或在实现算法时直接给定 k 值。 说明：A.质心数量由用户给出，记为k，k-means最终得到的簇数量也是kB.后来每次更新的质心的个数都和初始k值相等C.k-means最后聚类的簇个数和用户指定的质心个数相等，一个质心对应一个簇，每个样本只聚类到一个簇里面D.初始簇为空 Step2.距离度量将对象点分到距离聚类中心最近的那个簇中需要最近邻的度量策略，在欧式空间中采用的是欧式距离，在处理文档中采用的是余弦相似度函数，有时候也采用曼哈顿距离作为度量，不同的情况实用的度量公式是不同的。 说明：A.经过step2，得到k个新的簇，每个样本都被分到k个簇中的某一个簇B.得到k个新的簇后，当前的质心就会失效，需要计算每个新簇的自己的新质心 Step3.新质心的计算 对于分类后的产生的k个簇，分别计算到簇内其他点距离均值最小的点作为质心（对于拥有坐标的簇可以计算每个簇坐标的均值作为质心） 说明：A.比如一个新簇有3个样本：[[1,4], [2,5], [3,6]]，得到此簇的新质心=[(1+2+3)/3, (4+5+6)/3]B.经过step3，会得到k个新的质心，作为step2中使用的质心 Step4.是否停止K-means 质心不再改变，或给定loop最大次数loopLimit 说明：A当每个簇的质心，不再改变时就可以停止k-menasB.当loop次数超过looLimit时，停止k-meansC.只需要满足两者的其中一个条件，就可以停止k-meansC.如果Step4没有结束k-means，就再执行step2-step3-step4D.如果Step4结束了k-means，则就打印(或绘制)簇以及质心 参考链接：https://blog.csdn.net/qq_43741312/article/details/97128745","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"http://example.com/tags/MachineLearning/"}]},{"title":"机器学习-随机森林 RandomForest","slug":"ML-RandomForest","date":"2021-10-01T07:06:12.000Z","updated":"2023-02-16T14:43:26.000Z","comments":true,"path":"2021/10/01/ML-RandomForest/","link":"","permalink":"http://example.com/2021/10/01/ML-RandomForest/","excerpt":"机器学习是一类算法的总称，这些算法企图从大量历史数据中挖掘出其中隐含的规律，并用于预测或者分类，更具体的说，机器学习可以看作是寻找一个函数，输入是样本数据，输出是期望的结果，只是这个函数过于复杂，以至于不太方便形式化表达。需要注意的是，机器学习的目标是使学到的函数很好地适用于“新样本”，而不仅仅是在训练样本上表现很好。学到的函数适用于新样本的能力，称为泛化（Generalization）能力。","text":"机器学习是一类算法的总称，这些算法企图从大量历史数据中挖掘出其中隐含的规律，并用于预测或者分类，更具体的说，机器学习可以看作是寻找一个函数，输入是样本数据，输出是期望的结果，只是这个函数过于复杂，以至于不太方便形式化表达。需要注意的是，机器学习的目标是使学到的函数很好地适用于“新样本”，而不仅仅是在训练样本上表现很好。学到的函数适用于新样本的能力，称为泛化（Generalization）能力。 随机森林随机森林是最流行和最强大的机器学习算法之一。它是 Bootstrap Aggregation（又称 bagging）集成机器学习算法的一种。bootstrap 是从数据样本中估算数量的一种强大的统计方法。例如平均数。你从数据中抽取大量样本，计算平均值，然后平均所有的平均值以便更好的估计真实的平均值。 bagging 使用相同的方法，但是它估计整个统计模型，最常见的是决策树。在训练数据中抽取多个样本，然后对每个数据样本建模。当你需要对新数据进行预测时，每个模型都进行预测，并将所有的预测值平均以便更好的估计真实的输出值。随机森林是对这种方法的一种调整，在随机森林的方法中决策树被创建以便于通过引入随机性来进行次优分割，而不是选择最佳分割点。因此，针对每个数据样本创建的模型将会与其他方式得到的有所不同，不过虽然方法独特且不同，它们仍然是准确的。结合它们的预测可以更好的估计真实的输出值。如果用方差较高的算法（如决策树）得到了很好的结果，那么通常可以通过 bagging 该算法来获得更好的结果。算法思想: 训练数据集–&gt; 随机数据采样 （第一重随机）AND 随机特征采样(第二重随机) –&gt;训练数据集–&gt; 建立决策树模型–&gt;综合（平均/投票/多数结果法）–&gt;最终结果 随机森林模型调参方法随机森林学习器的默认参数配置： 12345678910111213141516# 1. bootstrap=True# 2. criterion=&#x27;mse&#x27;# 3. max_depth=None# 4. max_features=&#x27;auto&#x27;# 5. max_leaf_nodes=None# 6. min_impurity_decrease=0.0# 7. min_impurity_split=None# 8. min_samples_leaf=1# 9. min_samples_split=2# 10. min_weight_fraction_leaf=0.0# 11. n_estimators=10# 12. n_jobs=1# 13. oob_score=False# 14. random_state=None# 15. verbose=0# 16. warm_start=False 1、系统参数（1）random_state（随机发生器种子数）如果是int，random_state是随机数发生器使用的种子; 如果是RandomState实例，random_state是随机数生成器; 如果为None，则随机数生成器是np.random使用的RandomState实例。 2、决策树参数 123456789101112131415161718192021222324（1）max_features（最大特征数）划分特征时的最多特征数，可以是多种类型的值。默认为“None”，即划分时考虑所有特征数。其他值：“log2”——最多考虑log2N个特征；“sqrt”/“auto”——最多考虑sqrt(N)个特征；int(n)——可填任意大于1且不大于特征数量的整数。一般而言，当样本特征数较少（&lt;50）时，使用默认配置即可。（2）max_depth（决策树最大深度）默认为“None”，即决策树建立子树时不限制子树的深度。在样本量较少或特征数较少的情况下可以使用默认配置。否则，推荐取值10-100之间。（3）min_samples_split（内部结点再划分所需最小样本数）当某节点的样本数少于min_samples_split时，不会继续再尝试选择最优特征来进行划分。 默认为2，如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大该值。（4）min_samples_leaf（叶结点最少样本数）当某叶结点数目小于样本数，则和兄弟结点一起被剪枝。默认为1。当样本量不大时，可以使用默认配置。否则推荐增大该值。 5）min_weight_fraction_leaf（叶结点最小样本权重和）该值限制了叶结点所有样本权重和的最小值，如果小于该值，则会和兄弟节点一起被剪枝。 默认为0，即不考虑权重问题。当样本存在较多缺失值，或分类树样本的分布类别偏差很大时，将引入样本权重，此时需要考虑该值。（6）max_leaf_nodes（最大叶结点数）该值能够防止过拟合，默认为“None”，即不限制最大叶结点数。但特征不多时，使用默认配置即可。否则需要设置该值，具体数值通过交叉验证获得。（7）min_impurity_split（结点划分最小不纯度）该值限制了决策树的增长，当某结点的不纯度小于阈值，则该结点不再生成子结点，一般推荐使用默认值1e-7。 3、Bagging框架参数 Bagging框架中各弱学习器之间没有依赖，因此随机森林的调参难度低于梯度提升树。 12345678（1）n_estimators（弱学习器最大迭代次数） 即弱学习器的个数。一般而言，该值太小易发生欠拟合，太大则成本增加且效果不明显。一般选取适中的数值，默认为10。（2）oob_score （是否采用袋外样本评价模型） 默认为False。推荐使用True，因为这样可以反映模型拟合后的泛化能力。（3）criterion（特征评价标准） 分类和回归模型的损失函数不同：分类模型默认为基尼指数，也可选择信息增益；回归模型默认为均方差（mse），也可选择绝对值差（mae）。一般而言选择默认配置即可。 参考链接: https://blog.csdn.net/Caesar1993_Wang/article/details/80337103","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"http://example.com/tags/MachineLearning/"}]},{"title":"人工智能 AI Science","slug":"AI-Science","date":"2021-09-28T07:09:12.000Z","updated":"2022-10-01T17:53:08.000Z","comments":true,"path":"2021/09/28/AI-Science/","link":"","permalink":"http://example.com/2021/09/28/AI-Science/","excerpt":"人工智能（Artificial Intelligence），英文缩写为AI。它是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。人工智能是计算机科学的一个分支，它企图了解智能的实质，并生产出一种新的能以人类智能相似的方式做出反应的智能机器，该领域的研究包括机器人、语言识别、图像识别、自然语言处理和专家系统等。人工智能从诞生以来，理论和技术日益成熟，应用领域也不断扩大，可以设想，未来人工智能带来的科技产品，将会是人类智慧的“容器”。人工智能可以对人的意识、思维的信息过程的模拟。人工智能不是人的智能，但能像人那样思考、也可能超过人的智能。人工智能是一门极富挑战性的科学，从事这项工作的人必须懂得计算机知识，心理学和哲学。人工智能是包括十分广泛的科学，它由不同的领域组成，如机器学习，计算机视觉等等，总的说来，人工智能研究的一个主要目标是使机器能够胜任一些通常需要人类智能才能完成的复杂工作。但不同的时代、不同的人对这种“复杂工作”的理解是不同的。2017年12月，人工智能入选“2017年度中国媒体十大流行语”。2021年9月25日，为促进人工智能健康发展，《新一代人工智能伦理规范》发布。","text":"人工智能（Artificial Intelligence），英文缩写为AI。它是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。人工智能是计算机科学的一个分支，它企图了解智能的实质，并生产出一种新的能以人类智能相似的方式做出反应的智能机器，该领域的研究包括机器人、语言识别、图像识别、自然语言处理和专家系统等。人工智能从诞生以来，理论和技术日益成熟，应用领域也不断扩大，可以设想，未来人工智能带来的科技产品，将会是人类智慧的“容器”。人工智能可以对人的意识、思维的信息过程的模拟。人工智能不是人的智能，但能像人那样思考、也可能超过人的智能。人工智能是一门极富挑战性的科学，从事这项工作的人必须懂得计算机知识，心理学和哲学。人工智能是包括十分广泛的科学，它由不同的领域组成，如机器学习，计算机视觉等等，总的说来，人工智能研究的一个主要目标是使机器能够胜任一些通常需要人类智能才能完成的复杂工作。但不同的时代、不同的人对这种“复杂工作”的理解是不同的。2017年12月，人工智能入选“2017年度中国媒体十大流行语”。2021年9月25日，为促进人工智能健康发展，《新一代人工智能伦理规范》发布。 基础科普人工智能应用场景 商业场景：个性化推荐 精准营销 客户细分/用户画像 预测建模模式识别 数据挖掘 统计学习 语音识别 自然语言处理 计算机视觉 人工智能 机器学习 深度学习的关系 机器学习流程 模型评估模型评估依据 常用工具及框架工具numpy NumPy（Numeric Python）提供了许多高级的数值编程工具，如：矩阵数据类型、矢量处理，以及精密的运算库。专为进行严格的数字处理而产生 pandas pandas是基于NumPy 的一种工具，用于解决数据分析任务 ，提供了高效地操作大型数据集所需的工具。提供了大量能使我们快速便捷地处理数据的函数和方法 框架Scikit-Learn Scikit-Learn库包含了常见的机器学习算法 作为python机器学习功能强大的支持包，它已经把底层的脏活、累活都默默完成了，使用者能够将宝贵的注意力和精力集中在解决问题上，极大地提高产出效率 Tensorflow Tensorflow:一个端到端开源机器","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"}]},{"title":"自然语言 NLP","slug":"NLP","date":"2021-09-28T07:09:12.000Z","updated":"2023-02-21T00:34:42.000Z","comments":true,"path":"2021/09/28/NLP/","link":"","permalink":"http://example.com/2021/09/28/NLP/","excerpt":"《圣经》里有一个故事说巴比伦人想建造一座塔直通天堂。建塔的人都说着同一种语言，心意相通、齐心协力。上帝看到人类竟然敢做这种事情，就让他们的语言变得不一样。因为人们听不懂对方在讲什么，于是大家整天吵吵闹闹，无法继续建塔。后来人们把这座塔叫作巴别塔，而“巴别”的意思就是“分歧”。虽然巴别塔停建了，但一个梦想却始终萦绕在人们心中：人类什么时候才能拥有相通的语言，重建巴别塔呢？机器翻译被视为“重建巴别塔”的伟大创举。假如能够实现不同语言之间的机器翻译，我们就可以理解世界上任何人说的话，与他们进行交流和沟通，再也不必为相互不能理解而困扰。","text":"《圣经》里有一个故事说巴比伦人想建造一座塔直通天堂。建塔的人都说着同一种语言，心意相通、齐心协力。上帝看到人类竟然敢做这种事情，就让他们的语言变得不一样。因为人们听不懂对方在讲什么，于是大家整天吵吵闹闹，无法继续建塔。后来人们把这座塔叫作巴别塔，而“巴别”的意思就是“分歧”。虽然巴别塔停建了，但一个梦想却始终萦绕在人们心中：人类什么时候才能拥有相通的语言，重建巴别塔呢？机器翻译被视为“重建巴别塔”的伟大创举。假如能够实现不同语言之间的机器翻译，我们就可以理解世界上任何人说的话，与他们进行交流和沟通，再也不必为相互不能理解而困扰。 语音识别，语音合成自动分词，句法分析，语法纠错，关键词提取，文本分类/聚类，文本自动摘要，信息检索（ES,Solr）知识图谱，机器翻译，人机对话，机器写作推荐系统，高考机器人 信息抽取，网络爬虫，情感分析，问答系统 分词词向量常用工具 Jieba HanLP Gensim 算法 Seq2Seq 自编码神经网络 RNN LSTM Attention Transformer Bert","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"}]},{"title":"计算机视觉 CV","slug":"CV","date":"2021-09-28T00:08:08.000Z","updated":"2022-10-01T17:55:02.000Z","comments":true,"path":"2021/09/28/CV/","link":"","permalink":"http://example.com/2021/09/28/CV/","excerpt":"计算机视觉是一门研究如何使机器“看”的科学，更进一步的说，就是是指用摄影机和电脑代替人眼对目标进行识别、跟踪和测量等机器视觉，并进一步做图形处理，使电脑处理成为更适合人眼观察或传送给仪器检测的图像。作为一个科学学科，计算机视觉研究相关的理论和技术，试图建立能够从图像或者多维数据中获取‘信息’的人工智能系统。这里所指的信息指Shannon定义的，可以用来帮助做一个“决定”的信息。因为感知可以看作是从感官信号中提 取信息，所以计算机视觉也可以看作是研究如何使人工系统从图像或多维数据中“感知”的科学。","text":"计算机视觉是一门研究如何使机器“看”的科学，更进一步的说，就是是指用摄影机和电脑代替人眼对目标进行识别、跟踪和测量等机器视觉，并进一步做图形处理，使电脑处理成为更适合人眼观察或传送给仪器检测的图像。作为一个科学学科，计算机视觉研究相关的理论和技术，试图建立能够从图像或者多维数据中获取‘信息’的人工智能系统。这里所指的信息指Shannon定义的，可以用来帮助做一个“决定”的信息。因为感知可以看作是从感官信号中提 取信息，所以计算机视觉也可以看作是研究如何使人工系统从图像或多维数据中“感知”的科学。 计算机视觉基本任务类型 图像分类 目标检测 语义分割 实例分割 视频分类 人体关键点检测 场景文字识别 目标跟踪 图像分类VGGGoogleNetRestNet 目标检测RCNNFast RCNNFaster RCNNYOLOSSDSPPNet 图像定位RCNNFast RCNNFaster RCNNYOLOSSD 历史算法==================================================================================================================[R-CNN]算法特点: R-CNN 采用 AlexNet R-CNN 采用 Selective Search 技术生成 Region Proposal. R-CNN 在 ImageNet 上先进行预训练，然后利用成熟的权重参数在 PASCAL VOC 数据集上进行 fine-tune R-CNN 用 CNN 抽取特征，然后用一系列的的 SVM 做类别预测。 R-CNN 的 bbox 位置回归基于 DPM 的灵感，自己训练了一个线性回归模型。 R-CNN 的语义分割采用 CPMC 生成 Region算法步骤: 1. 在图像中确定约1000-2000个候选框 (使用选择性搜索) 2. 每个候选框内图像块缩放至相同大小，并输入到CNN内进行特征提取 3. 对候选框中提取出的特征，使用分类器判别是否属于一个特定类 4. 对于属于某一特征的候选框，用回归器进一步调整其位置 [OverFeat] [MultiBox] [SPP-Net] [MR-CNN] [DeepBox] [AttentionNet] ==================================================================================================================[Fast R-CNN]算法步骤： 1. 在图像中确定约1000-2000个候选框 (使用选择性搜索) 2. 对整张图片输进CNN，得到feature map 3. 找到每个候选框在feature map上的映射patch，将此patch作为每个候选框的卷积特征输入到SPP layer和之后的层 4. 对候选框中提取出的特征，使用分类器判别是否属于一个特定类 5. 对于属于某一特征的候选框，用回归器进一步调整其位置 [DeepProposal] [Faster R-CNN]算法步骤： 1. 对整张图片输进CNN，得到feature map 2. 卷积特征输入到RPN，得到候选框的特征信息 3. 对候选框中提取出的特征，使用分类器判别是否属于一个特定类 4. 对于属于某一特征的候选框，用回归器进一步调整其位置 [OHEM] [YOLO V1]核心思想: 利用整张图作为网络的输入，直接在输出层回归bounding box的位置和bounding box所属的类别。 Faster RCNN中也直接用整张图作为输入，但是Faster-RCNN整体还是采用了RCNN那种 proposal+classifier的思想，只不过是将提取proposal的步骤放在CNN中实现了,而YOLOv1则采用直接回归的思路。 在YOLOv1的损失函数中： 只有当某个网格中有object的时候才对classification error进行惩罚。 只有当某个box predictor对某个ground truth box负责的时候，才会对box的coordinate error进行惩罚，而对哪个ground truth box负责就看其预测值和ground truth box的IoU是不是在那个cell的所有box中最大。 算法特点： YOLOv1方法模型训练依赖于物体识别标注数据，因此，对于非常规的物体形状或比例，YOLOv1的检测效果并不理想。 YOLOv1采用了多个下采样层，网络学到的物体特征并不精细，因此也会影响检测效果。 YOLOv1的loss函数中，大物体IOU误差和小物体IOU误差对网络训练中loss贡献值接近（虽然采用求平方根方式，但没有根本解决问题）。因此，对于小物体，小的IOU误差也会对网络优化过程造成很大的影响，从而降低了物体检测的定位准确性。 YOLO的缺点 YOLO对相互靠的很近的物体和很小的群体检测效果不好，这是因为一个网格中只预测了两个框，并且只属于一类； 同一类物体出现的新的不常见的长宽比和其他情况时，泛化能力偏弱； 由于损失函数的问题，定位误差是影响检测效果的主要原因。尤其是大小物体的处理上，还有待加强。 [G-CNN] [AZNet] ==================================================================================================================[Inside-OutsideNet(ION)] [HyperNet] [CRAFT] [MultiPathNet(MPN)] [SSD] [GBDNet] ==================================================================================================================[CPF] [MS-CNN] [R-FCN] [PVANET] [DeepID-Net] [NoC] [DSSD] [TDM] [YOLO v2] ==================================================================================================================[Feature Pyramid Net(FPN)] [RON] [DCN] [DeNet] [CoupleNet] [RetinaNet] [DSOD] ==================================================================================================================[Mask R-CNN] [SMN] [YOLO V3] [SIN] [STDN] [RefineDet] [MLKP] [Relation-Net] ==================================================================================================================[Cascade R_CNN] [RFBNet] [CornerNet] [PFPNet] [Pelee] [HKRM] [R-DAD] [M2Det]","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"CV","slug":"CV","permalink":"http://example.com/tags/CV/"}]},{"title":"深度学习 Deep Learning","slug":"DL","date":"2021-09-22T07:09:12.000Z","updated":"2022-09-30T08:25:04.000Z","comments":true,"path":"2021/09/22/DL/","link":"","permalink":"http://example.com/2021/09/22/DL/","excerpt":"人类大脑中，大约有1000亿个神经元，每个神经元与大约10万个神经元相连。从本质上说，这就是我们想要创造的，在某种程度上，这对机器来说是可行的。深度学习的目的是模仿人类大脑的工作方式。这在神经元，轴突，树突等方面意味着什么？嗯，神经元有胞体，树突和轴突。来自一个神经元的信号沿着轴突传播并转移到下一个神经元的树突。传递信号的那个连接被称为突触。","text":"人类大脑中，大约有1000亿个神经元，每个神经元与大约10万个神经元相连。从本质上说，这就是我们想要创造的，在某种程度上，这对机器来说是可行的。深度学习的目的是模仿人类大脑的工作方式。这在神经元，轴突，树突等方面意味着什么？嗯，神经元有胞体，树突和轴突。来自一个神经元的信号沿着轴突传播并转移到下一个神经元的树突。传递信号的那个连接被称为突触。 03 深度学习3.1 基础3.1.0 Tensorflow 3.1.1 深度学习应用 · 人脸识别，手机解锁和高铁通行验证 扫脸支付· 医疗影像诊断:放射性拍片-提升超分辨率· 工业4.0： 预测性维护是指用连续的数据收集来预测设备故障· 无人零售 · 深度强化学习(Alpha zero等)· AUTOML-机器学习自动化· 自动驾驶：（百度Apollo，Google的Waymo）· 自动辅助系统· 跟车系统· 高速自动巡航系统· 自动泊车系统 自动运输卡车· 农作物监测：管理杀虫剂、发现问题，预测天气变化如何影响农业· 药物发现:缩短药物发现周期 3.1.2 基本概念 感知机模型 反向传播 正向传播 多层反向传播 3.2 CNN(convolutional Neural Networks) 卷积神经网络 ==结构== 数据输入层：Input Layer （图片） 卷积计算层：CONV Layer ReLU激励层：ReLU Incentive Layer （激活） 池化层：Pooling Layer （下采样） 全连接层：FC Layer 3.3 RNN(Recurrent Neural Network) 循环神经网络 3.4 GANS(Generative Adversarial Networks) 生成对抗神经网络 04 计算机视觉 大规模(大数据量)图片识别(聚类/分类)，如人脸识别，车牌识别，OCR以图搜图，图像分割 目标检测，如自动驾驶的行人检测，安防系统的异常人群检测 目标检测 图像定位 Alex Net SPP Net CNN-VGGNet Fast R-CNN Fast R-CNN RPN Faster RCNN R FCN YOLO YOLO v1 YOLO v2 YOLO v3 SSD Cascade R-CNN 图像分类 VGG GoogleNet RestNet 3D目标检测 Anchor Free Anchor Free_UnitBox Anchor Free_FSAF Anchor Free_FCOS Anchor Free_CenterNet Anchor Free_CornerNet Anchor Free_CornerNet-Lite Anchor Free_GA RPN","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://example.com/tags/DeepLearning/"}]},{"title":"目标检测 YoloV5","slug":"CV-ObjectDetection-YoloV5","date":"2021-08-28T00:08:08.000Z","updated":"2023-05-23T15:48:50.343Z","comments":true,"path":"2021/08/28/CV-ObjectDetection-YoloV5/","link":"","permalink":"http://example.com/2021/08/28/CV-ObjectDetection-YoloV5/","excerpt":"环境配置GPU环境配置","text":"环境配置GPU环境配置 环境配置教程https://blog.csdn.net/qq_44697805/article/details/107702939 查看当前环境列表conda env list 创建yolov5 python环境conda create -n yolov5gpu python=3.7 查看下载源地址conda config –show-sources 添加镜像源地址conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/freeconda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main ########### 设置搜索时显示通道地址conda config –set show_channel_urls yes 切换默认源地址conda config –remove-key channels anaconda安装新环境失败https://blog.csdn.net/hdq1745/article/details/105105728 查看自己电脑应该安装什么版本的cudahttps://blog.csdn.net/HDWFIX/article/details/108131070 各个版本的cuda下载地址https://developer.nvidia.com/cuda-toolkit-archive 链接数据库Python链接hive 文件安装saslhttps://www.lfd.uci.edu/~gohlke/pythonlibs/#sasl JDBC链接hive数据库Jar包下载地址https://mvnrepository.com/https://mvnrepository.com/artifact/org.slf4j/slf4j-simple/1.7.25 Jdk安装包http://jar.bds-analytics.com:9090/group1/default/20220117/16/44/4/jdk-8u172-windows-x64.zip TypeError: Class org.apache.hive.jdbc.HiveDriver is not found加上jdbc配置文件 下载图片到本地https://blog.csdn.net/weixin_44266650/article/details/106787305 Mmdetection安装1.10.1+cu113 mmcv-full==1.3.9 https://github.com/yaochenglouis/mmdetection/blob/yolov4zhang/docs/en/get_started.md 安装版本选择https://github.com/open-mmlab/mmcv 安装语句pip install mmcv-full==1.3.9 -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.10.0/index.html 参数调整与优化模型配置文件yolov5s模型配置文件如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# YOLOv5 🚀 by Ultralytics, GPL-3.0 license# Parametersnc: 80 # number of classesdepth_multiple: 0.33 # model depth multiplewidth_multiple: 0.50 # layer channel multipleanchors: - [10,13, 16,30, 33,23] # P3/8 - [30,61, 62,45, 59,119] # P4/16 - [116,90, 156,198, 373,326] # P5/32# YOLOv5 v6.0 backbone# backbone: # [from, number, module, args] [[-1, 1, Conv, [64, 6, 2, 2]], # 0-P1/2 [-1, 1, Conv, [128, 3, 2]], # 1-P2/4 [-1, 3, C3, [128]], [-1, 1, Conv, [256, 3, 2]], # 3-P3/8 [-1, 6, C3, [256]], [-1, 1, Conv, [512, 3, 2]], # 5-P4/16 [-1, 9, C3, [512]], [-1, 1, Conv, [1024, 3, 2]], # 7-P5/32 [-1, 3, C3, [1024]], [-1, 1, SPPF, [1024, 5]], # 9 ]# YOLOv5 v6.0 head# head: [[-1, 1, Conv, [512, 1, 1]], [-1, 1, nn.Upsample, [None, 2, &#x27;nearest&#x27;]], [[-1, 6], 1, Concat, [1]], # cat backbone P4 [-1, 3, C3, [512, False]], # 13 [-1, 1, Conv, [256, 1, 1]], [-1, 1, nn.Upsample, [None, 2, &#x27;nearest&#x27;]], [[-1, 4], 1, Concat, [1]], # cat backbone P3 [-1, 3, C3, [256, False]], # 17 (P3/8-small) [-1, 1, Conv, [256, 3, 2]], [[-1, 14], 1, Concat, [1]], # cat head P4 [-1, 3, C3, [512, False]], # 20 (P4/16-medium) [-1, 1, Conv, [512, 3, 2]], [[-1, 10], 1, Concat, [1]], # cat head P5 [-1, 3, C3, [1024, False]], # 23 (P5/32-large) [[17, 20, 23], 1, Detect, [nc, anchors]], # Detect(P3, P4, P5) ] from：输入来自那一层，-1代表上一次，1代表第1层，3代表第3层 number：模块的数量，最终数量需要乘width，然后四舍五入取整，如果小于1，取1。 module：子模块 args：模块参数，channel，kernel_size，stride，padding，bias等 Focus：对特征图进行切片操作，[64,3]得到[3,32,3]，即输入channel=3（RGB），输出为640.5(width_multiple)=32，3为卷积核尺寸。 Conv：nn.conv(kenel_size=1，stride=1，groups=1，bias=False) + Bn + Leaky_ReLu。[-1, 1, Conv, [128, 3, 2]]：输入来自上一层，模块数量为1个，子模块为Conv，网络中最终有1280.5=32个卷积核，卷积核尺寸为3，stride=2,。 BottleNeckCSP：借鉴CSPNet网络结构，由3个卷积层和X个残差模块Concat组成，若有False，则没有残差模块，那么组成结构为nn.conv+Bn+Leaky_ReLu SPP：[-1, 1, SPP, [1024, [5, 9, 13]]]表示5×5，9×9，13×13的最大池化方式，进行多尺度融合 超参文件yolov5/data/hyps/hyp.scratch-low.yaml ：YOLOv5 COCO训练从头优化，数据增强低yolov5/data/hyps/hyp.scratch-mdeia.yaml（数据增强中）yolov5/data/hyps/hyp.scratch-high.yaml（数据增强高） 12345678910111213141516171819202122232425262728293031lr0: 0.01 # 初始学习率 (SGD=1E-2, Adam=1E-3)lrf: 0.2 # 循环学习率 (lr0 * lrf)momentum: 0.937 # SGD momentum/Adam beta1 学习率动量weight_decay: 0.0005 # 权重衰减系数warmup_epochs: 3.0 # 预热学习 (fractions ok)warmup_momentum: 0.8 # 预热学习动量warmup_bias_lr: 0.1 # 预热初始学习率box: 0.05 # iou损失系数cls: 0.5 # cls损失系数cls_pw: 1.0 # cls BCELoss正样本权重obj: 1.0 # 有无物体系数(scale with pixels)obj_pw: 1.0 # 有无物体BCELoss正样本权重iou_t: 0.20 # IoU训练时的阈值anchor_t: 4.0 # anchor的长宽比（长:宽 = 4:1）# anchors: 3 # 每个输出层的anchors数量(0 to ignore)#以下系数是数据增强系数，包括颜色空间和图片空间fl_gamma: 0.0 # focal loss gamma (efficientDet default gamma=1.5)hsv_h: 0.015 # 色调 (fraction)hsv_s: 0.7 # 饱和度 (fraction)hsv_v: 0.4 # 亮度 (fraction)degrees: 0.0 # 旋转角度 (+/- deg)translate: 0.1 # 平移(+/- fraction)scale: 0.5 # 图像缩放 (+/- gain)shear: 0.0 # 图像剪切 (+/- deg)perspective: 0.0 # 透明度 (+/- fraction), range 0-0.001flipud: 0.0 # 上下翻转概率 (probability)fliplr: 0.5 # 左右翻转概率 (probability)mosaic: 1.0 # 进行Mosaic概率 (probability)mixup: 0.0 # 进行图像混叠概率（即，多张图像重叠在一起） (probability) 代码中参数train.py参数解析1234567891011121314151617181920212223242526272829303132333435363738394041parser = argparse.ArgumentParser() parser.add_argument(&#x27;--weights&#x27;, type=str, default=ROOT / &#x27;yolov5s.pt&#x27;, help=&#x27;initial weights path&#x27;) parser.add_argument(&#x27;--cfg&#x27;, type=str, default=&#x27;&#x27;, help=&#x27;model.yaml path&#x27;) parser.add_argument(&#x27;--data&#x27;, type=str, default=ROOT / &#x27;data/coco128.yaml&#x27;, help=&#x27;dataset.yaml path&#x27;) parser.add_argument(&#x27;--hyp&#x27;, type=str, default=ROOT / &#x27;data/hyps/hyp.scratch-low.yaml&#x27;, help=&#x27;hyperparameters path&#x27;) parser.add_argument(&#x27;--epochs&#x27;, type=int, default=300, help=&#x27;total training epochs&#x27;) parser.add_argument(&#x27;--batch-size&#x27;, type=int, default=16, help=&#x27;total batch size for all GPUs, -1 for autobatch&#x27;) parser.add_argument(&#x27;--imgsz&#x27;, &#x27;--img&#x27;, &#x27;--img-size&#x27;, type=int, default=640, help=&#x27;train, val image size (pixels)&#x27;) parser.add_argument(&#x27;--rect&#x27;, action=&#x27;store_true&#x27;, help=&#x27;rectangular training&#x27;) parser.add_argument(&#x27;--resume&#x27;, nargs=&#x27;?&#x27;, const=True, default=False, help=&#x27;resume most recent training&#x27;) parser.add_argument(&#x27;--nosave&#x27;, action=&#x27;store_true&#x27;, help=&#x27;only save final checkpoint&#x27;) parser.add_argument(&#x27;--noval&#x27;, action=&#x27;store_true&#x27;, help=&#x27;only validate final epoch&#x27;) parser.add_argument(&#x27;--noautoanchor&#x27;, action=&#x27;store_true&#x27;, help=&#x27;disable AutoAnchor&#x27;) parser.add_argument(&#x27;--noplots&#x27;, action=&#x27;store_true&#x27;, help=&#x27;save no plot files&#x27;) parser.add_argument(&#x27;--evolve&#x27;, type=int, nargs=&#x27;?&#x27;, const=300, help=&#x27;evolve hyperparameters for x generations&#x27;) parser.add_argument(&#x27;--bucket&#x27;, type=str, default=&#x27;&#x27;, help=&#x27;gsutil bucket&#x27;) parser.add_argument(&#x27;--cache&#x27;, type=str, nargs=&#x27;?&#x27;, const=&#x27;ram&#x27;, help=&#x27;--cache images in &quot;ram&quot; (default) or &quot;disk&quot;&#x27;) parser.add_argument(&#x27;--image-weights&#x27;, action=&#x27;store_true&#x27;, help=&#x27;use weighted image selection for training&#x27;) parser.add_argument(&#x27;--device&#x27;, default=&#x27;&#x27;, help=&#x27;cuda device, i.e. 0 or 0,1,2,3 or cpu&#x27;) parser.add_argument(&#x27;--multi-scale&#x27;, action=&#x27;store_true&#x27;, help=&#x27;vary img-size +/- 50%%&#x27;) parser.add_argument(&#x27;--single-cls&#x27;, action=&#x27;store_true&#x27;, help=&#x27;train multi-class data as single-class&#x27;) parser.add_argument(&#x27;--optimizer&#x27;, type=str, choices=[&#x27;SGD&#x27;, &#x27;Adam&#x27;, &#x27;AdamW&#x27;], default=&#x27;SGD&#x27;, help=&#x27;optimizer&#x27;) parser.add_argument(&#x27;--sync-bn&#x27;, action=&#x27;store_true&#x27;, help=&#x27;use SyncBatchNorm, only available in DDP mode&#x27;) parser.add_argument(&#x27;--workers&#x27;, type=int, default=8, help=&#x27;max dataloader workers (per RANK in DDP mode)&#x27;) parser.add_argument(&#x27;--project&#x27;, default=ROOT / &#x27;runs/train&#x27;, help=&#x27;save to project/name&#x27;) parser.add_argument(&#x27;--name&#x27;, default=&#x27;exp&#x27;, help=&#x27;save to project/name&#x27;) parser.add_argument(&#x27;--exist-ok&#x27;, action=&#x27;store_true&#x27;, help=&#x27;existing project/name ok, do not increment&#x27;) parser.add_argument(&#x27;--quad&#x27;, action=&#x27;store_true&#x27;, help=&#x27;quad dataloader&#x27;) parser.add_argument(&#x27;--cos-lr&#x27;, action=&#x27;store_true&#x27;, help=&#x27;cosine LR scheduler&#x27;) parser.add_argument(&#x27;--label-smoothing&#x27;, type=float, default=0.0, help=&#x27;Label smoothing epsilon&#x27;) parser.add_argument(&#x27;--patience&#x27;, type=int, default=100, help=&#x27;EarlyStopping patience (epochs without improvement)&#x27;) parser.add_argument(&#x27;--freeze&#x27;, nargs=&#x27;+&#x27;, type=int, default=[0], help=&#x27;Freeze layers: backbone=10, first3=0 1 2&#x27;) parser.add_argument(&#x27;--save-period&#x27;, type=int, default=-1, help=&#x27;Save checkpoint every x epochs (disabled if &lt; 1)&#x27;) parser.add_argument(&#x27;--seed&#x27;, type=int, default=0, help=&#x27;Global training seed&#x27;) parser.add_argument(&#x27;--local_rank&#x27;, type=int, default=-1, help=&#x27;Automatic DDP Multi-GPU argument, do not modify&#x27;) # Logger arguments parser.add_argument(&#x27;--entity&#x27;, default=None, help=&#x27;Entity&#x27;) parser.add_argument(&#x27;--upload_dataset&#x27;, nargs=&#x27;?&#x27;, const=True, default=False, help=&#x27;Upload data, &quot;val&quot; option&#x27;) parser.add_argument(&#x27;--bbox_interval&#x27;, type=int, default=-1, help=&#x27;Set bounding-box image logging interval&#x27;) parser.add_argument(&#x27;--artifact_alias&#x27;, type=str, default=&#x27;latest&#x27;, help=&#x27;Version of dataset artifact to use&#x27;) weights：指定预训练权重路径；如果这里设置为空的话，就是自己从头开始进行训练 cfg：模型配置文件，比如models/yolov5s.yaml。 data：数据集对应的yaml参数文件；里面主要存放数据集的类别和路径信息，例如： 123456789101112yaml:names:- crazing- inclusion- pitted_surface- scratches- patches- rolled-in_scalenc: 6path: /kaggle/working/train: /kaggle/working/train.txtval: /kaggle/working/val.txt rect:是否使用矩阵推理的方式训练模型 resume：断点续训：即是否在之前训练的一个模型基础上继续训练，default 值默认是 false。一种方式是先将train.py中这一行default=False 改为 default=True：1parser.add_argument(&#x27;--resume&#x27;, nargs=&#x27;?&#x27;, const=True, default=True, help=&#x27;resume most recent training&#x27;) 然后执行代码： 1python train.py --resume \\runs\\train\\exp\\weights\\last.pt 或者参考其他写法 nosave：是否只保存最后一轮的pt文件；我们默认是保存best.pt和last.pt两个的。 noval：是否只在最后一轮测试 正常情况下每个epoch都会计算mAP，但如果开启了这个参数，那么就只在最后一轮上进行测试，不建议开启。 noautoanchor：是否禁用自动锚框；默认是开启的。 noplots：开启这个参数后将不保存绘图文件 evolve：yolov5使用遗传超参数进化，提供的默认参数是通过在COCO数据集上使用超参数进化得来的（也就是hpy文件夹下默认的超参数）。由于超参数进化会耗费大量的资源和时间，所以建议大家不要动这个参数。（开了貌似不评估mertic了） bucket：谷歌云盘；通过这个参数可以下载谷歌云盘上的一些东西，但是现在没必要使用了 cache：是否提前缓存图片到内存，以加快训练速度，默认False；开启这个参数就会对图片进行缓存，从而更好的训练模型 image-weights：是否启用加权图像策略，默认是不开启的主要是为了解决样本不平衡问题。开启后会对于上一轮训练效果不好的图片，在下一轮中增加一些权重 multi-scale：是否启用多尺度训练，默认是不开启的多尺度训练是指设置几种不同的图片输入尺度，训练时每隔一定iterations随机选取一种尺度训练，这样训练出来的模型鲁棒性更强。 single-cls：训练数据集是否是单类别，默认False optimizer：优化器；默认为SGD，可选SGD，Adam，AdamW。 sync-bn：是否开启跨卡同步BN开启后，可使用 SyncBatchNorm 进行多 GPU分布式训练 workers：进程数 project：指定模型的保存路径；默认在runs/train。 name：模型保存的文件夹名，默认在exp文件夹。 exist-ok：每次模型预测结果是否保存在原来的文件夹如果指定了这个参数的话，那么本次预测的结果还是保存在上一次保存的文件夹里如果不指定，就是每预测一次结果，就保存在一个新的文件夹里。 quad：暂不明 cos-lr：是否开启余弦学习率。（下面是开启前后学习率曲线对比图） label-smoothing：是否启用标签平滑处理，默认不启用 patience：早停轮数，默认100。如果模型在100轮里没有提升，则停止训练模型 freeze：指定冻结层数量；可以在yolov5s.yaml中查看主干网络层数 save-period：多少个epoch保存一下checkpoint，default=-1。 seed：随机种子。v6.2版本更新的一个非常重要的参数，使用torch&gt;=1.12.0的单GPU YOLOv5训练现在完全可再现 local_rank：DistributedDataParallel 单机多卡训练，单GPU设备不需要设置 entity：在线可视化工具wandb upload_dataset：是否上传dataset到wandb tabel，默认False启用后，将数据集作为交互式 dsviz表 在浏览器中查看、查询、筛选和分析数据集 bbox_interval：设置界框图像记录间隔 Set bounding-box image logging interval for W&amp;B 默认-1 artifact_alias：使用数据的版本 detact.py参数解析123456789101112131415161718192021222324252627282930313233def parse_opt(): parser = argparse.ArgumentParser() parser.add_argument(&#x27;--weights&#x27;, nargs=&#x27;+&#x27;, type=str, default=ROOT / &#x27;yolov5s.pt&#x27;, help=&#x27;model path or triton URL&#x27;) parser.add_argument(&#x27;--source&#x27;, type=str, default=ROOT / &#x27;data/images&#x27;, help=&#x27;file/dir/URL/glob/screen/0(webcam)&#x27;) parser.add_argument(&#x27;--data&#x27;, type=str, default=ROOT / &#x27;data/coco128.yaml&#x27;, help=&#x27;(optional) dataset.yaml path&#x27;) parser.add_argument(&#x27;--imgsz&#x27;, &#x27;--img&#x27;, &#x27;--img-size&#x27;, nargs=&#x27;+&#x27;, type=int, default=[640], help=&#x27;inference size h,w&#x27;) parser.add_argument(&#x27;--conf-thres&#x27;, type=float, default=0.25, help=&#x27;confidence threshold&#x27;) parser.add_argument(&#x27;--iou-thres&#x27;, type=float, default=0.45, help=&#x27;NMS IoU threshold&#x27;) parser.add_argument(&#x27;--max-det&#x27;, type=int, default=1000, help=&#x27;maximum detections per image&#x27;) parser.add_argument(&#x27;--device&#x27;, default=&#x27;&#x27;, help=&#x27;cuda device, i.e. 0 or 0,1,2,3 or cpu&#x27;) parser.add_argument(&#x27;--view-img&#x27;, action=&#x27;store_true&#x27;, help=&#x27;show results&#x27;) parser.add_argument(&#x27;--save-txt&#x27;, action=&#x27;store_true&#x27;, help=&#x27;save results to *.txt&#x27;) parser.add_argument(&#x27;--save-conf&#x27;, action=&#x27;store_true&#x27;, help=&#x27;save confidences in --save-txt labels&#x27;) parser.add_argument(&#x27;--save-crop&#x27;, action=&#x27;store_true&#x27;, help=&#x27;save cropped prediction boxes&#x27;) parser.add_argument(&#x27;--nosave&#x27;, action=&#x27;store_true&#x27;, help=&#x27;do not save images/videos&#x27;) parser.add_argument(&#x27;--classes&#x27;, nargs=&#x27;+&#x27;, type=int, help=&#x27;filter by class: --classes 0, or --classes 0 2 3&#x27;) parser.add_argument(&#x27;--agnostic-nms&#x27;, action=&#x27;store_true&#x27;, help=&#x27;class-agnostic NMS&#x27;) parser.add_argument(&#x27;--augment&#x27;, action=&#x27;store_true&#x27;, help=&#x27;augmented inference&#x27;) parser.add_argument(&#x27;--visualize&#x27;, action=&#x27;store_true&#x27;, help=&#x27;visualize features&#x27;) parser.add_argument(&#x27;--update&#x27;, action=&#x27;store_true&#x27;, help=&#x27;update all models&#x27;) parser.add_argument(&#x27;--project&#x27;, default=ROOT / &#x27;runs/detect&#x27;, help=&#x27;save results to project/name&#x27;) parser.add_argument(&#x27;--name&#x27;, default=&#x27;exp&#x27;, help=&#x27;save results to project/name&#x27;) parser.add_argument(&#x27;--exist-ok&#x27;, action=&#x27;store_true&#x27;, help=&#x27;existing project/name ok, do not increment&#x27;) parser.add_argument(&#x27;--line-thickness&#x27;, default=3, type=int, help=&#x27;bounding box thickness (pixels)&#x27;) parser.add_argument(&#x27;--hide-labels&#x27;, default=False, action=&#x27;store_true&#x27;, help=&#x27;hide labels&#x27;) parser.add_argument(&#x27;--hide-conf&#x27;, default=False, action=&#x27;store_true&#x27;, help=&#x27;hide confidences&#x27;) parser.add_argument(&#x27;--half&#x27;, action=&#x27;store_true&#x27;, help=&#x27;use FP16 half-precision inference&#x27;) parser.add_argument(&#x27;--dnn&#x27;, action=&#x27;store_true&#x27;, help=&#x27;use OpenCV DNN for ONNX inference&#x27;) parser.add_argument(&#x27;--vid-stride&#x27;, type=int, default=1, help=&#x27;video frame-rate stride&#x27;) opt = parser.parse_args() opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1 # expand print_args(vars(opt)) return opt source：测试集文件/文件夹 data：配置文件路径，和train.py里面的data是一样的 conf-thres：置信度的阈值 超过这个阈值的预测框就会被预测出来。比如conf-thres参数依次设置成“0”, “0.25”，“0.8” iou-thres：iou阈值 max-det：每张图最大检测数量，默认是最多检测1000个目标 view-img：检测的时候是否实时的把检测结果显示出来如果输入代码python detect.py –view-img，在检测的时候系统要把我检测的结果实时的显示出来，假如我文件夹有5张图片，那么模型每检测出一张就会显示出一张，直到所有图片检测完成。 save-txt：是否把检测结果保存成一个.txt的格式txt默认保存物体的类别索引和预测框坐标（YOLO格式），每张图一个txt，txt中每行表示一个物体 save-conf：上面保存的txt中是否包含置信度 save-crop：是否把模型检测的物体裁剪下来开启了这个参数会在crops文件夹下看到几个以类别命名的文件夹，里面保存的都是裁剪下来的图片。 nosave：不保存预测的结果但是还会生成exp文件夹，只不过是一个空的exp。这个参数应该是和“–view-img”配合使用的 classes：指定检测某几种类别。比如coco128.yaml中person是第一个类别，classes指定“0”，则表示只检测图片中的person。 agnostic-nms：跨类别nms比如待检测图像中有一个长得很像排球的足球，pt文件的分类中有足球和排球两种，那在识别时这个足球可能会被同时框上2个框：一个是足球，一个是排球。开启agnostic-nms后，那只会框出一个框 augment：数据增强。下面是启用前后的对比示例 visualize：是否可视化特征图。如果开启了这和参数可以看到exp文件夹下又多了一些文件，这里.npy格式的文件就是保存的模型文件，可以使用numpy读写。还有一些png文件。下面来看一下保存 update：如果指定这个参数，则对所有模型进行strip_optimizer操作，去除pt文件中的优化器等信息 project：预测结果保存的路径 name：预测结果保存文件夹名 exist-ok：每次预测模型的结果是否保存在原来的文件夹如果指定了这个参数的话，那么本次预测的结果还是保存在上一次保存的文件夹里；如果不指定就是每次预测结果保存一个新的文件夹下 line-thickness：调节预测框线条粗细的，default=3因为有的时候目标重叠太多会产生遮挡，比如python detect.py –line-thickness 10 hide-labels：隐藏预测图片上的标签（只有预测框） hide-conf：隐藏置信度（还有预测框和类别信息，但是没有置信度） half：是否使用 FP16 半精度推理。在training阶段，梯度的更新往往是很微小的，需要相对较高的精度，一般要用到FP32以上。在inference的时候，精度要求没有那么高，一般F16（半精度）就可以，甚至可以用INT8（8位整型），精度影响不会很大。同时低精度的模型占用空间更小了，有利于部署在嵌入式模型里面。 dnn：是否使用 OpenCV DNN 进行 ONNX 推理。 val.py参数解析val.py的作用：我们在训练结束后会打印出每个类别的一些评价指标，但是如果当时忘记记录，那么我们就可以通过这个文件再次打印这些评价指标可以打印出测试集评价指标，测试集的图片也是需要标注的。 123456789101112131415161718192021222324252627282930def parse_opt(): parser = argparse.ArgumentParser() parser.add_argument(&#x27;--data&#x27;, type=str, default=ROOT / &#x27;data/coco128.yaml&#x27;, help=&#x27;dataset.yaml path&#x27;) parser.add_argument(&#x27;--weights&#x27;, nargs=&#x27;+&#x27;, type=str, default=ROOT / &#x27;yolov5s.pt&#x27;, help=&#x27;model path(s)&#x27;) parser.add_argument(&#x27;--batch-size&#x27;, type=int, default=32, help=&#x27;batch size&#x27;) parser.add_argument(&#x27;--imgsz&#x27;, &#x27;--img&#x27;, &#x27;--img-size&#x27;, type=int, default=640, help=&#x27;inference size (pixels)&#x27;) parser.add_argument(&#x27;--conf-thres&#x27;, type=float, default=0.001, help=&#x27;confidence threshold&#x27;) parser.add_argument(&#x27;--iou-thres&#x27;, type=float, default=0.6, help=&#x27;NMS IoU threshold&#x27;) parser.add_argument(&#x27;--max-det&#x27;, type=int, default=300, help=&#x27;maximum detections per image&#x27;) parser.add_argument(&#x27;--task&#x27;, default=&#x27;val&#x27;, help=&#x27;train, val, test, speed or study&#x27;) parser.add_argument(&#x27;--device&#x27;, default=&#x27;&#x27;, help=&#x27;cuda device, i.e. 0 or 0,1,2,3 or cpu&#x27;) parser.add_argument(&#x27;--workers&#x27;, type=int, default=8, help=&#x27;max dataloader workers (per RANK in DDP mode)&#x27;) parser.add_argument(&#x27;--single-cls&#x27;, action=&#x27;store_true&#x27;, help=&#x27;treat as single-class dataset&#x27;) parser.add_argument(&#x27;--augment&#x27;, action=&#x27;store_true&#x27;, help=&#x27;augmented inference&#x27;) parser.add_argument(&#x27;--verbose&#x27;, action=&#x27;store_true&#x27;, help=&#x27;report mAP by class&#x27;) parser.add_argument(&#x27;--save-txt&#x27;, action=&#x27;store_true&#x27;, help=&#x27;save results to *.txt&#x27;) parser.add_argument(&#x27;--save-hybrid&#x27;, action=&#x27;store_true&#x27;, help=&#x27;save label+prediction hybrid results to *.txt&#x27;) parser.add_argument(&#x27;--save-conf&#x27;, action=&#x27;store_true&#x27;, help=&#x27;save confidences in --save-txt labels&#x27;) parser.add_argument(&#x27;--save-json&#x27;, action=&#x27;store_true&#x27;, help=&#x27;save a COCO-JSON results file&#x27;) parser.add_argument(&#x27;--project&#x27;, default=ROOT / &#x27;runs/val&#x27;, help=&#x27;save to project/name&#x27;) parser.add_argument(&#x27;--name&#x27;, default=&#x27;exp&#x27;, help=&#x27;save to project/name&#x27;) parser.add_argument(&#x27;--exist-ok&#x27;, action=&#x27;store_true&#x27;, help=&#x27;existing project/name ok, do not increment&#x27;) parser.add_argument(&#x27;--half&#x27;, action=&#x27;store_true&#x27;, help=&#x27;use FP16 half-precision inference&#x27;) parser.add_argument(&#x27;--dnn&#x27;, action=&#x27;store_true&#x27;, help=&#x27;use OpenCV DNN for ONNX inference&#x27;) opt = parser.parse_args() opt.data = check_yaml(opt.data) # check YAML opt.save_json |= opt.data.endswith(&#x27;coco.yaml&#x27;) opt.save_txt |= opt.save_hybrid print_args(vars(opt)) return opt 前六个参数和detect.py意义一样。 task：可以是train, val, test。比如：python val.py –task test表示打印测试集指标 augment：测试是否使用TTA Test Time Augment，指定这个参数后各项指标会明显提升几个点。 verbose：是否打印出每个类别的mAP，默认False。 save-hybrid：将标签+预测混合结果保存到 .txt save-json：是否按照coco的json格式保存预测框，并且使用cocoapi做评估（需要同样coco的json格式的标签） 默认False half：是否使用半精度推理 默认False其它参数内容同detect.py。 添加注意力机制1234Epoch GPU_mem box_loss obj_loss cls_loss Instances Size98/99 3.81G 0.03403 0.0175 0.002002 72 256: 100% 75/75 [00:29&lt;00:00, 2.52it/s] Class Images Instances P R mAP50 mAP50-95: 100% 7/7 [00:02&lt;00:00, 2.93it/s] all 200 420 0.765 0.753 0.794 0.445","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"CV","slug":"CV","permalink":"http://example.com/tags/CV/"},{"name":"Yolo","slug":"Yolo","permalink":"http://example.com/tags/Yolo/"}]},{"title":"推荐系统 Recommendation","slug":"Recommendation","date":"2020-09-28T00:08:08.000Z","updated":"2022-09-30T08:27:08.000Z","comments":true,"path":"2020/09/28/Recommendation/","link":"","permalink":"http://example.com/2020/09/28/Recommendation/","excerpt":"推荐系统是信息过载所采用的措施，面对海量的数据信息，从中快速推荐出符合用户特点的物品。解决一些人的“选择恐惧症”；面向没有明确需求的人。解决如何从大量信息中找到自己感兴趣的信息解决如何让自己生产的信息脱颖而出，受到大众的喜爱总得来说：让用户更好更快获取到自己喜欢的内容，让内容更好更快地推送到喜欢它的用户手中，让网站（平台）更有效的保留用户资源。","text":"推荐系统是信息过载所采用的措施，面对海量的数据信息，从中快速推荐出符合用户特点的物品。解决一些人的“选择恐惧症”；面向没有明确需求的人。解决如何从大量信息中找到自己感兴趣的信息解决如何让自己生产的信息脱颖而出，受到大众的喜爱总得来说：让用户更好更快获取到自己喜欢的内容，让内容更好更快地推送到喜欢它的用户手中，让网站（平台）更有效的保留用户资源。 信息超载（information overload）问题:互联网的出现和普及给用户带来了大量的信息，满足了用户在信息时代对信息的需求，但随着网络的迅速发展而带来的网上信息量的大幅增长，使得用户在面对大量信息时无法从中获得对自己真正有用的那部分信息，对信息的使用效率反而降低 目前，针对信息超载问题的解决办法之一是以搜索引擎为代表信息检索系统，比如Google、Baidu等，它们在帮助用户获取网络信息方面发挥着极其重要的作用。但使用搜索擎的用户在使用同一个关键字搜索信息时，得到的结果是相同的。另一方面来看，信息及其传播是多样化的，而用户对信息的需求是多元化和个性化的，那么通过以搜索引擎为代表的信息检索系统获得的结果不能满足用户的个性化需求，仍然无法很好地解决信息超载问题。 解决信息超载问题另外一个非常有潜力的办法是个性化推荐系统，它是根据用户的信息需求、兴趣等，将用户感兴趣的信息、产品等推荐给用户的个性化信息推荐系统。和搜索引擎相比推荐系统通过研究用户的兴趣偏好，进行个性化计算，由系统发现用户的兴趣点，从而引导用户发现自己的信息需求。一个好的推荐系统不仅能为用户提供个性化的服务，还能和用户之间建立密切关系，让用户对推荐产生依赖。 推荐系统定义推荐系统的定义有不少，但被广泛接受的推荐系统的概念和定义是Resnick和Varian在1997年给出的：“它是利用电子商务网站向客户提供商品信息和建议，帮助用户决定应该购买什么产品，模拟销售人员帮助客户完成购买过程”。推荐系统有3个重要的模块：用户建模模块、推荐对象建模模块、推荐算法模块推荐系统把用户模型中兴趣需求信息和推荐对象模型中的特征信息匹配，同时使用相应的推荐算法进行计算筛选，找到用户可能感兴趣的推荐对象，然后推荐给用户。 用户建模模块一个好的推荐系统要给用户提供个性化的、高效的、准确的推荐，那么推荐系统应能够获取反映用户多方面的、动态变化的兴趣偏好，推荐系统有必要为用户建立一个用户模型，该模型能获取、表示、存储和修改用户兴趣偏好，能进行推理，对用户进行分类和识别，帮助系统更好地理解用户特征和类别，理解用户的需求和任务，从而更好地实现用户所需要的功能。推荐系统根据用户的模型进行推荐，所以用户描述文件对推荐系统的质量有至关重要的影响。建立用户模型之前，需要考虑下面几个问题：（1）模型的输入数据有哪些，如何获取模型的输入数据（2）如何考虑用户的兴趣及需求的变化（3）建模的对象是谁（4）清楚了上述内容后，怎么建模（5）模型的输出是什么 获取用户信息就是解决模型输入数据的问题，模型的输入数据主要有以下几种：（1）用户属性：这是用户最基本的信息，包括社会属性和自然属性，比如用户的姓名、年龄、职业、收入、学历等。用用户注册时的自然属性和社会属性进行初始建模。（2）用户手工输入的信息：这部分是用户主动提供给系统的信息，包括用户在搜索引擎中输入的关键词，用户输入的感兴趣的主题、频道。还有一类重要的信息就是用户反馈的信息，包括用户自己对推荐对象的喜好程度；用户标注的浏览页面的感兴趣、不感兴趣或感兴趣的程度等。（3）用户的浏览行为和浏览内容：用户浏览的行为和内容体现了用户的兴趣和需求，它们包括浏览次数、频率、停留时间等，浏览页面时的操作（收藏、保存、复制等）、浏览时用户表情的变化等。服务器端保存的日志也能较好地记录用户的浏览行为和内容。（4）推荐对象的属性特征：不同的推荐对象，用户建模的输入数据也不同。网页等推荐对象通常考虑对象的内容和用户之间的相似性，而产品等推荐对象通常考虑用户对产品的评价。为提高推荐质量，推荐对象的相关的属性也要考虑进去，比如除网页内容以外，还要考虑网页的发布人、时间等。产品类的对象还要考虑产品的品牌、价格、出售时间等。扩展了二维的评价矩阵，综合考虑了影响用户兴趣的各种因素。考虑了Web服务的Qos来对户的兴趣建模。 获取模型输入数据的方式有显式获取、隐式获取和启发式获取三种方式。显式的获取方式用户主动告之。例如MyYahoo和WebWatcher都要户自己给出感兴趣的栏目和关键。另外一类显式的方式要求用户提供与其兴趣相关的示例及类别属性来建立用户模型，LIRA、Syskill&amp;Webert、WebMate等是该方法的代表。 显式获取兴趣偏好的方法是简单而直接的做法，能相对准确地反映用户的需求，同时所得的信息比较具体、全面、客观，结果往往比较可靠。缺点就是很难收到实效，主要原因就是很少用户愿意花时间或不愿向系统表达自己的喜好。而且这一方法灵活性差，存在答案异质性，用户兴趣主题改变时要手动更改系统中用户兴趣等诸多问题，使得该方法的实时性、可操作性很难得到保证。同时该方法对用户不是很友好，具有很大的侵袭性。解决侵袭性问题是推荐系统未来的一个研究方向，来研究用户能够接受的评价方式是什么，比如能够有耐心进行几次评分。文献[16]利用固定负担模型来计量用户评价的负担，将侵袭性问题转化为最优化问题来研究。 隐式获取法是指系统通过跟踪用户行为，通过推理获取用户的兴趣偏好，因为用户的很多动作都能暗示用户的喜好，比如查询、浏览页面和文章、标记书签、反馈信息、点击鼠标、拖动滚动条，Web 日志挖掘等。典型的系统有 ELFI、Letizia等。隐式的跟踪可以减少用户很多不必要的负担，不会打扰用户的正常生活。这种方法的缺点就是跟踪的结果未必能正确反映用户的兴趣偏好 ,但是利用日志跟踪用户兴趣偏好存在兴趣偏好走样的问题。同时系统若过度跟踪用户的历史记录，有时会引起用户反感，而放弃对当前推荐系统的使。 上述获取兴趣偏好的方法有时受用户知识背景、资源和经验等方面因素的限制，用户有时意识不到自己的兴趣主题，因此，为用户提供启发式信息，如专家意见、领域术语抽取，可以实现领域知识的复用，为用户间的协同提供支持，提高用户兴趣获取质量。 用户的兴趣和需求会随着时间和情景发生变化，用户建模时要考虑到用户长期兴趣偏好和短期兴趣偏好，还要考虑兴趣的变化，目前很多研究关注了用户的长期兴趣，建立了静态模型，用户兴趣更新的动态模型也受到了很多关注，短期兴趣的关注还比较少。结合长期和短期兴趣的建模将是未来的一个研究方向，文献对此进行了研究。而且采用时间窗方法和遗忘机制来反映用户兴趣的变化。目前的更新机制无法及时跟踪用户兴趣的变化，just-in-time型有更强学习效率和动态变化适应能力的建模也是未来的重要研究方向。建模的对象有单用户建模和群组建模之分，单用户建模针对单个用户进行建模，比如基于内容的推荐，群组建模是针对群体用户进行建模，比如协同推荐。 用户模型的建模方法主要有遗传算法、基于机器学习的方法，例如TF-IDF、自动聚类、贝叶斯分类器、决策树归纳和神经网络方法等。遗传算法采用遗传结合、遗传交叉变异以及自然选择等操作实现建模，通过遗传进化满足用户兴趣变化时完成模型的更新 TF-IDF将用户感兴趣的文档表示成关键词向量，并计算出每个关键词权重来建立用户模型；使用贝叶斯分类器的系统计算用户浏览或访问过的推荐对象属于某个给定类的概率，然后依据概率将资源项目分类来建立用户对这些资源项目的偏好模型；使用决策树归纳作为用户模型学习技术的系统将用户偏好的获取过程表达成一棵决策树，用户从根节点开始，被引导来回答一系列问题。树的每个节点表示了决策点，所采取的方向取决于对问题的回答或者对可用数据的计算。一旦叶节点被达到，则可得到对用户偏好的完整描述；运用神经网络建模的算法，对系统对用户偏好的输入假设进行学习并调整网络连接权重，直到网络中的所有节点达到稳定激活状态。此时输出层中被激活的节点所对应的模式类，如感兴趣/不感兴趣类，即表示了系统识别的用户偏好；聚类将具有相似特征的项目或用户分组，使用这类技术的系统一般建立用户群组的综合模型 推荐对象的建模推荐系统应用于不同的领域，它推荐的对象也就各不相同，如何对推荐对象进行描述对推荐系统也有很重要的影响。和用户描述文件一样，要对推荐对象进行描述之前也要考虑以下几个问题：（1）提取推荐对象的什么特征，如何提取，提取的特征用于什么目的。（2）对象的特征描述和用户文件描述之间有关联。（3）提取到的每个对象特征对推荐结果会有什么影响。（4）对象的特征描述文件能否自动更新。推荐对象的描述文件中的对象特征和用户的描述文件中的兴趣偏好进行推荐计算，获得推荐对象的推荐度，所以推荐对象的描述文件与用户的描述文件密切相关，通常的做法是用同样的方法来表达用户的兴趣偏好和推荐对象。推荐系统推荐对象包括众多的领域，比如报纸、Usenet新闻、科技文档、Email，还有诸如音乐、电影等多媒体资源等等。不同的对象，特征也不相同，目前并没有一个统一的标准来进行统一描述，主要有基于内容的方法和基于分类的方法两大类方法。针对文档类对象的这两个表示方法给以分析。 基于内容的方法是从对象本身抽取信息来表示对象，使用最广泛的方法是用加权关键词矢量，该方法通过对一组文档的统计分析得出文档的特征向量。方法很多，比较简单的做法就是计算每个特征的熵，选取具有最大熵值的若干个特征；也可以计算每个特征的信息增量（Information gain），也就是计算每个特征在文档中出现前后的信息熵之差；还可以计算每个特征的互信息（mutual information），也就是计算每个特征和文档的相关性；还可使用 X 2 统计方法。对比研究表明，信息增量方法和 X 2 统计方法表现较好，但这两种方法的计算量比较大。 在完成文档特征的选取后，还得计算每个特征的权值，权值大的对推荐结果的影响就大。目前使用最广泛的是TFIDF方法。基于分类的方法是把推荐对象放入不同类别中，这样可以把同类文档推荐给对该类文档感兴趣的用户了。文本分类的方法有多种，比如朴素贝叶斯（Naive-Bayes），k最近邻方法（KNN）和支持向量机（SVM）等。对象的类别可以预先定义，也可以利用聚类技术自动产生。许多研究表明：聚类的精度非常依赖于文档的数量，而且由自动聚类产生的类型可能对用户来说是毫无意义的，因此可以先使用手工选定的类型来分类文档，在没有对应的候选类型或需要进一步划分某类型时，才使用聚类产生的类型。 文本等对象特征提取技术相对比较成熟，但推荐系统的对象不一定具有文本特征或文本不足以作为描述，尤其是网络上广泛存在的多媒体数据，自动化的特征提取方法需要结合多媒体内容分析领域的相关技术。 推荐系统推荐给用户的对象首先首先不能与用户看过的对象重复，其次也不能与用户刚刚看过的对象不是太形似或者太不相关，这就是所谓的模型过拟合问题（可扩展性问题）。出现这一问题的本质上来自数据的不完备性，解决的主要的方法是引入随机性，使算法收敛到全局最优或者逼近全局最优，比如遗传算法等。针对这一问题考察了被推荐的对象的相关性（relevant）和冗余性（redundancy），认为既要保证推荐的多样性，又不能与用户看过的对象重复或毫不相关。关于这一问题的研究是推荐系统研究的一个难点和重点。推荐系统中出现新的对象时，推荐系统尤其是协同过滤系统中，新对象出现后必须等待一段时间才会有用户查看并进行评价，在此之前推荐系统无法对此对象进行分析和推荐，这就是推荐系统研究的另一个难点和重点——冷启动问题。目前，解决这一问题的方法就是从推荐方法上考虑，比如使用组合推荐方法来应付。对推荐对象的描述能动态更新会成为研究一个方向 推荐算法模块推荐算法（或叫推荐策略）是整个推荐系统中最核心和关键的部分，在很大程度上决定了推荐系统类型和性能的优劣，推荐策略的研究是推荐系统最为繁荣的部分，大量的论文和著作都关注了这个方面。目前，出现的推荐策略有很多，对其分类的标准也没有一个统一的标准，但受到大家公认的推荐策略基本包括以下几种：基于内容的推荐、协同过滤推荐、基于知识的推荐、基于网络结构的推荐、组合推荐及其他推荐。以下来介绍各种推荐策略及其优缺点 基于内容的推荐基于内容的推荐（content-based recommendation）方法源于信息获取领域，是信息检索领域的重要研究内容。该方法是根据用户已经选择的对象，从推荐对象中选择其他特征相似的对象作为推荐结果。这一推荐策略首先提取推荐对象的内容特征，和用户模型中的用户兴趣偏好匹配，匹配度较高的推荐对象就可作为推荐结果推荐给用户。例如在进行音乐推荐时，系统分析用户以前选择的音乐的共性，找到用户的兴趣点。然后从其他音乐中选择和用户兴趣点相似的音乐推荐给用户。计算推荐对象的内容特征和用户模型中兴趣特征二者之间的相似性是该推荐策略中一个关键部分 u(c,s) = score(userprofile,content) 计算所得的值按其大小排序，将最靠前的若干个对象作为推荐结果呈现给用户。基于内容的推荐策略中的关键就是用户模型描述和推荐对象内容特征描述。其中对推荐对象内容进行特征提取，目前对文本内容进行特征提取方法比较成熟，如浏览页面的推荐、新闻推荐等。但网上的多媒体信息大量涌现，而对这些多媒体数据进行特征提取还有待技术支持，所以多媒体信息还没有大量用于基于内容的推荐。基于内容的推荐的优点如下：（1）简单、有效，推荐结果直观，容易理解，不需要领域知识。（2）不需要用户的历史数据，如对对象的评价等。（3）没有关于新推荐对象出现的冷启动问题。（4）没有稀疏问题。（5）比较成熟的分类学习方法能够为该方法提供支持，如数据挖掘、聚类分析等。 基于内容的推荐的缺点如下：（1）该方法的广泛应用受到了推荐对象特征提取能力的限制较为严重。因为多媒体资源 没有有效的特征提取方法，比如图像、视频、音乐等。既使文本资源，其特征提取方法也只能反映资源的一部分内容，例如，难以提取网页内容的质量，这些特征可能影响到用户的满意度。（2）很难出现新的推荐结果。推荐对象的内容特征和用户的兴趣偏好匹配才能获得推荐，用户将仅限于获得跟以前类似的推荐结果，很难为用户发现新的感兴趣的信息。（3）存在新用户出现时的冷启动问题。当新用户出现时，系统较难获得该用户的兴趣偏好，就不能和推荐对象的内容特征进行匹配，该用户将较难获得满意的推荐结果。（4）对推荐对象内容分类方法需要的数据量较大。目前，尽管分类方法很多，但构造分类器时需要的数据量巨大，给分类带来一定困难。（5）不同语言的描述的用户模型和推荐对象模型无法兼容也是基于内容推荐系统面临的又一个大的问题。 协同过滤推荐协同过滤推荐（collaborative filtering recommendation）是推荐策略中最成功的策略，它于20世纪90年代开始研究并促进了整个推荐系统研究的繁荣。大量论文和研究都属于该类别。比如Grundy书籍推荐系统、Tapestry邮件处理系统，Grouplens、Ringo等推荐系统都属于该类推荐。协同过滤推荐的基本思想借鉴了日常在选购商品、选择用餐饭店、选择看哪部电影等等的方法。如果自己身边的很多朋友都选购某种商品，那么自己就会很大概率的选择该商品。或者用户喜欢某类商品，当看到和这类商品相似商品并且其他用户对此类商品评价很高时，则购买的概率就会很大。协同推荐的用户模型为用户-项目评价矩阵协同过滤推荐一般分为三类：基于用户的协同推荐（Userbased Collaborative Filtering）（或基于内存的协同推荐（Memory-Based Collaborative Filtering）、基于项目的协同推荐（Item-Based Collaborative Filtering）和基于模型的协同推荐（Model-Based Collaborative Filtering）。 基于用户的协同推荐（UB-CF）该推荐策略又叫基于内存的推荐（MB-CF），它的基本思想是用户选择某个推荐对象是基于朋友的推荐。也就是说如果一些用户对某些推荐对象的评分比较相似，则说明这些用户的兴趣偏好相似，那么他们对其他推荐对象的评分应该也是相似的。所以协同过滤推荐首先找到和目标用户兴趣偏好相似的最近邻居，然后根据他的最近邻居对推荐对象的评分来预测目标用户对未评分的推荐对象的评分，选择预测评分最高的若干个推荐对象作为推荐结果反馈给用户 基于项目的协同过滤推荐（IB-CF）如果基于用户的协同推荐的依据是基于朋友的推荐的话，基于项目的协同推荐是基于用户对推荐对象品牌的信任而进行的推荐。基于项目的协同推荐是基于这样一个假设：如果大部分用户对一些推荐对象的评分比较相似，则当前用户对这些项的评分也比较相似。就好像很多用户对某个品牌比较信任，则其他用户就比较容易选择该品牌的产品。 基于项目的协同推荐的基本思路对象的最近邻居，由于当前用户对最近邻居的评分与对目标推荐对象的评分比较类似，所以可以根据当前用户对最近邻居的评分预测当前用户对目标推荐对象的评分，然后选择预测评分最高的若干个目标对象作为推荐结果呈现给当前用户。 基于项目的协同推荐的主要工作有两个，首先是查询目标推荐对象的最近邻居，然后产生推荐。其核心是推荐对象的最近邻居查询。 基于模型的协同推荐（MB-CF）这类方法是利用用户c对众多对象的评分来得到一个用户c的模型，进而对某对象预测打分。和上述两种协同推荐的不同在于对已有数据应用统计和机器学习的方法得到模型进行预测的建立用户模型是核心，常用的方法有机器学习方法、统计模型、贝叶斯模型、概率相关模型、线性回归模型和最大熵模型。另外还有一些其他的模型，例如Shanideng基于 Markov 链的模型、潜层语义分析模型、语义生成模型，Yu等还提出了输入选择技术，解决给予模型的算法需要对大规模数据进行学习的问题。 协同过滤的优点：（1）复杂的非结构化的对象可以应用协同过滤，比如电影、音乐、图像等推荐对象。（2）善于发现用户新的兴趣点。协同过滤可以发现内容上完全不相似的资源，用户对推荐信息的内容事先是预料不到的。（3）不需要专业知识即可进行推荐。（4）随着用户的增多，其推荐性能会不断提升。（5）以用户为中心自动进行推荐。协同过滤的缺点：（1）存在冷启动问题。新进入的用户由于得不到他们的兴趣偏好而无法获得推荐，新的推荐项目由于没有用户评价它就得不到推荐，这就是冷启动问题。冷启动问题是推荐系统研究的难点和重点。（2）存在稀疏性问题。由于用户数目的大量增长，而且用户之间选择存在差异性，使得用户的评分差别非常大。同时推荐对象的数量也大量增长，使得大量的推荐对象没有经过用户的评价。这些会导致部分用户无法获得推荐，部分推荐对象得不到推荐，这就是稀疏性问题。（3）系统开始时推荐质量差及推荐质量取决于历史数据集 基于社会网络分析方法的推荐基于社会网络分析方法（Social Network Analysis，SNA）的推荐把社会网络分析理论应用于推荐系统的一类方法，目前该方法研究是协同过滤推荐的延伸。社会网络（social network）是为达到特定的目的，人与人之间、组织之间等进行信息交流时形成的关系网。该网由结点和结点间的连线组成，结点可以人、组织、计算机等实体，连线表示这些实体之间的信息交互。社会网络分析（SNA）是对社会网络进行研究的一个重要工具，它为多结点之间的关系进行描述，并对其价值进行估量的一个工具。目前该方法被广发应用于其他很多跨学科领域，例如信息推荐、Web超链分析等。 用户在购买或浏览网页信息时，形成用户和产品之间的链接关系，从而形成社会网络关系，通过社会网络分析方法可以考察结点之间（用户和用户之间或产品之间）的相关性，并依此进行进行推荐。利用结点之间的关系计算结点之间信任度，利用它们之间的信任度进行推荐可以比一般的协同推荐获得更高推荐效果。 基于网络结构的推荐策略基于网络结构的推荐策略是一种较新的推荐策略，该策略中不用考虑用户和推荐对象的内容，而是把用户和推荐对象抽象为节点，而用户选择了某一推荐对象就会在用户和对象之间存在选择关系，该策略认为信息就隐藏在该选择关系中。该策略由周涛、Huang、刘建国等人提出。 周涛、Huang等认为在一个由m个用户和n个对象构成的推荐系统中，如果用户i选择过对象j，则在用户i和对象 j 之间存在一条边 aij = 1 ，否则不存在该边，其中 i=1，2，…，m；j=1，2，…，n，所以系统可以表示为一个m+n个节点组成的二部分图（bipartite network），而推荐算法的目的就是对任意的用户，能把他没有选择的对象按照其喜好程度排序，并把排序靠前的对象推荐给该用户。周涛、Huang等在用户—产品二部分图的基础上把物理学理论和复杂网络的理论应用于推荐算法中，分别给出了不同的推荐策略。","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"Recommendation","slug":"Recommendation","permalink":"http://example.com/tags/Recommendation/"}]},{"title":"Python网站框架 Django","slug":"Python-Django","date":"2020-08-28T00:08:08.000Z","updated":"2022-09-30T08:25:04.000Z","comments":true,"path":"2020/08/28/Python-Django/","link":"","permalink":"http://example.com/2020/08/28/Python-Django/","excerpt":"","text":"项目开发常用复用的工具函数 DjangoDjango操作django-admin startapp APPname 创建APPproject.setting.DATABASES 项目数据库python manage.py makemigrations 创建迁移python manage.py migrate 迁移–将Model中创建的数据表同步到数据库中python manage.py startapp xxxx 创建文件夹django-admin startproject 项目名称python manage.py startapp 应用app名setting.py ———-&gt; 在APP列表中新增APP名 配置数据库地址Model.py ———-&gt; 定义项目使用的model在对应的APP中的views.py创建类及对应函数render 创建对应的html文件","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"Django","slug":"Django","permalink":"http://example.com/tags/Django/"}]},{"title":"基础操作 Python","slug":"Python-basic","date":"2020-08-28T00:08:08.000Z","updated":"2022-09-30T08:25:04.000Z","comments":true,"path":"2020/08/28/Python-basic/","link":"","permalink":"http://example.com/2020/08/28/Python-basic/","excerpt":"人类大脑中，大约有1000亿个神经元，每个神经元与大约10万个神经元相连。从本质上说，这就是我们想要创造的，在某种程度上，这对机器来说是可行的。深度学习的目的是模仿人类大脑的工作方式。这在神经元，轴突，树突等方面意味着什么？嗯，神经元有胞体，树突和轴突。来自一个神经元的信号沿着轴突传播并转移到下一个神经元的树突。传递信号的那个连接被称为突触。","text":"人类大脑中，大约有1000亿个神经元，每个神经元与大约10万个神经元相连。从本质上说，这就是我们想要创造的，在某种程度上，这对机器来说是可行的。深度学习的目的是模仿人类大脑的工作方式。这在神经元，轴突，树突等方面意味着什么？嗯，神经元有胞体，树突和轴突。来自一个神经元的信号沿着轴突传播并转移到下一个神经元的树突。传递信号的那个连接被称为突触。 字典 dictpython 字典中根据value获取key值 1list(a.keys())[list(a.values()).index(&#x27;a&#x27;)] python 保存字典为json文件 1234json_str = json.dumps(all_house,ensure_ascii=False)json_str = json.dumps(test_dict)with open(&#x27;test_data.json&#x27;, &#x27;w&#x27;) as json_file: json_file.write(json_str) 列表 listpython list去重并保持原顺序 12ids = list(set(x))ids.sort(key=x.index) python 转换list元素类型 1label_list = [int(i) for i in label_list] python list中每个int转换为str 在Python中，有时需要将list以字符串的形式输出，此时可以使用如下的形式： 1&quot;,&quot;.join(list_sample)1 其中，,表示的是分隔符 如需要将a_list = [&quot;h&quot;,&quot;e&quot;,&quot;l&quot;,&quot;l&quot;,&quot;o&quot;]转换成字符输出，可以使用如下的形式转换： 12a_list = [&quot;h&quot;,&quot;e&quot;,&quot;l&quot;,&quot;l&quot;,&quot;o&quot;]print &quot;,&quot;.join(a_list)123 如果list中不是字符串，而是数字，则不能使用如上的方法，会有如下的错误： TypeError: sequence item 0: expected string, int found 可以有以下的两种方法： 方法1 1234num_list = [0,1,2,3,4,5,6,7,8,9]num_list_new = [str(x) for x in num_list]print &quot;,&quot;.join(num_list_new)1234 方法2 1234num_list = [0,1,2,3,4,5,6,7,8,9]num_list_new = map(lambda x:str(x), num_list)print &quot;,&quot;.join(num_list_new) 字符串 python 字符串转大小写 12345str = &quot;www.runoob.com&quot;print(str.upper()) # 把所有字符中的小写字母转换成大写字母print(str.lower()) # 把所有字符中的大写字母转换成小写字母print(str.capitalize()) # 把第一个字母转化为大写字母，其余小写print(str.title()) # 把每个单词的第一个字母转化为大写，其余小写 数据结构123append() 在被选元素的结尾（仍在内部）插入指定内容push() 向数组的末尾添加一个或多个元素 并返回新的长度pop() 删除数组的最后一个元素 并返回 python特殊符小结12345678910111213141516171819% // 取模运算 // 格式化输出： print &#x27;it is a %s&#x27; %(a) （传递参数输出）!= // 不等== // 赋值&gt;&gt; // 位运算 对二进制数进行移位操作 &gt;&gt;1 右移 除以二&lt;&lt; // 位运算 对二进制数进行移位操作 &lt;&lt;1 左移 乘以二&amp; // 与运算符：参与运算的两个值,如果两个相应位都为1,则该位的结果为1,否则为0 (a &amp; b) 输出结果 12 ，二进制解释： 0000 1100| // 或运算符：只要对应的二个二进位有一个为1时，结果位就为1。 (a | b) 输出结果 61 ，二进制解释： 0011 1101^ // 异或运算符：当两对应的二进位相异时，结果为1 (a ^ b) 输出结果 49 ，二进制解释： 0011 0001~ // 取反运算符：对数据的每个二进制位取反,即把1变为0,把0变为1 。~x 类似于 -x-1 (~a ) 输出结果 -61 ，二进制解释： 1100 0011，在一个有符号二进制数的补码形式。&lt;&lt; // 左移动运算符：运算数的各二进位全部左移若干位，由 &lt;&lt; 右边的数字指定了移动的位数，高位丢弃，低位补0。 a &lt;&lt; 2 输出结果 240 ，二进制解释： 1111 0000&gt;&gt; // 右移动运算符：把&quot;&gt;&gt;&quot;左边的运算数的各二进位全部右移若干位，&gt;&gt; 右边的数字指定了移动的位数 a &gt;&gt; 2 输出结果 15 ，二进制解释： 0000 1111n%2==1 // 判断奇偶数(n&amp;1)==1 // 判断奇偶数bin() // 返回整数的二进制表达形式n&amp;(n-1) // 按位与--将n的二进制表示中的最低位为1的改为0: n &amp;= (n-1)(n&amp;0x1)==1 // 按位做与运算，判断一个数是奇数还是偶数，等于1为奇数。a^n 算法1 // 当n为偶数, a^n = a^(n/2) * a^(n/2)a^n 算法2 // 当n为奇数, a^n = a^((n-1)/2) * a^((n-1)/2)) * a&#x27;&#x27;/&quot;&quot; // 有’时 使用双引号 或者\\ 转译 python函数12345678910111213141516171819202122232425262728293031323334353637383940414243pow(2,3) // 计算乘方 2**3abs(-10) // 计算绝对值 10round(1.0/2.0) // 把浮点数四舍五入为最接近的整数值 1.0math.floor(32.9) // 向下取整 32math.ceil(32.1) // 向上取整 33int(math.floor(32.9)) // 转换为整数而不是浮点数long(math.floor(32.9)) // 转换为整数而不是浮点数float(math.floor(32.9)) // 转换为整数而不是浮点数form模块import函数 // 可以直接使用函数 不需要模块名.nan // not a numbersqrt // 计算算术平方根 返回浮点数#！/user/bin/python2 // 默认路径下的python2运行raw_input(&#x27;Press &lt;enter&gt;&#x27;) raw_input# 字符串# 拼接与拆分join &gt;&gt;&gt; a=&#x27;aaaaa&#x27; &gt;&gt;&gt; b=&#x27;bbbbb&#x27; &gt;&gt;&gt; &#x27;,&#x27;.join([a,b])format &gt;&gt;&gt;&#x27;&#123;&#125;,&#123;&#125;&#x27;.format(a,b) &gt;&gt;&gt;&#x27;&#123;1&#125;,&#123;0&#125;&#x27;.format(a,b) &gt;&gt;&gt;&#x27;&#123;1&#125;&#123;1&#125;&#123;1&#125;&#123;1&#125;,&#123;0&#125;&#x27;.format(a,b)split approve.split(&#x27;,&#x27;)# 列表# 列表操作 改变元素元素赋值 删除元素 分片赋值list(&#x27;Hello&#x27;) //[&#x27;H&#x27;,&#x27;e&#x27;,&#x27;l&#x27;,&#x27;l&#x27;,&#x27;o&#x27;] list 适用于所有类型的序列 不只是del // 改变列表 删除元素append // 在列表末尾追加新的对象count // 统计某个元素在列表中出现的次数extend // 在列表的末尾一次性追加另一个序列的多个值 --与链接不同点：改变了extend的x.index(&#x27;one&#x27;) // 找出列表中某一个值第一个匹配项的索引位置x.insert(3,four) // 将对象插入到列表中x.pop() // pop 移除列表的值 默认是最后一个 并且返回该元素的值remove // 移除列表中某个元素sort // 在原位置对列表进行排序reverse // 反转列表","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"常用函数 Python","slug":"Python-Function","date":"2020-08-28T00:08:08.000Z","updated":"2022-09-30T07:40:00.000Z","comments":true,"path":"2020/08/28/Python-Function/","link":"","permalink":"http://example.com/2020/08/28/Python-Function/","excerpt":"常用python函数 数学相关: abs / divmod / pow / round / min / max / sum 序列相关: len / range / next / filter / map / sorted / slice / reversed 类型转换: chr / ord / str / bool / int / float / complex / bin / oct / hex 数据结构: dict / list / set / tuple 其他函数: all / any / id / input / open / print / type","text":"常用python函数 数学相关: abs / divmod / pow / round / min / max / sum 序列相关: len / range / next / filter / map / sorted / slice / reversed 类型转换: chr / ord / str / bool / int / float / complex / bin / oct / hex 数据结构: dict / list / set / tuple 其他函数: all / any / id / input / open / print / type 数学相关 abs 计算绝对值1234l = [-1,5,-6,11,6,-19]print(sorted(l,key=abs)) #按绝对值排序for i in l: print(abs(i))#逐个打印绝对值 divmod 除几余几 1print(divmod(10,3))#返回一个元组 pow 幂运算 12print(pow(2,3))#2的3次幂 round 小数精确，精确到小数点后几位，可以精确到小数点前几位，前几位用负数表示，均四舍五入 123456a = 8115/4print(a.__round__(1))#变量a的内置方法print(a.__round__(-2))print(round(8115/4,1))#内置函数print(round(8115/4,-2)) min 返回给定参数的最小值，参数可以为序列。可以加入一个key的索引 1234l = [1,2,3,4,5,-5]print(min(l,key=abs))#绝对值最小print(min(l))#最小 max 返回给定参数的最大值，参数可以为序列。可以加入一个key的索引 1234l = [1,2,3,4,5,-5]print(max(l,key=abs))#绝对值最大print(max(l))#最大 sum 求和 ，传入一个可迭代对象求和,可以继续传入一个起始求和的参数，默认为0 1234l = [1,2,3,4,5,-5]print(sum(l))#10print(sum(l,2))#12 序列相关len 返回字符串、列表、字典、元组等长度 1234567891011121314151617# len(str)# str：要计算的字符串、列表、字典、元组等# a.计算字符串的长度：s = &quot;hello good boy doiido&quot;len(s)# b.计算列表的元素个数：l = [&#x27;h&#x27;,&#x27;e&#x27;,&#x27;l&#x27;,&#x27;l&#x27;,&#x27;o&#x27;]len(l)# c.计算字典的总长度(即键值对总数)d = &#123;&#x27;num&#x27;:123,&#x27;name&#x27;:&quot;doiido&quot;&#125;len(d)# d.计算元组元素个数：t = (&#x27;G&#x27;,&#x27;o&#x27;,&#x27;o&#x27;,&#x27;d&#x27;)len(t) range 返回一系列连续增加的整数，它的工作方式类似于分片，可以生成一个列表对象。range函数大多数时常出现在for循环中，在for循环中可做为索引使用。其实它也可以出现在任何需要整数列表的环境中，在python 3.0中range函数是一个迭代器 12345678910111213# range()函数内只有一个参数，则表示会产生从0开始计数的整数列表range(4) # [0, 1, 2, 3]# 传入两个参数时，则将第一个参数做为起始位，第二个参数为结束位range(0,5) # [0, 1, 2, 3, 4]# 填入三个参数，第三个参数是步进值（步进值默认为1）range(0,10,3) # [0, 3, 6, 9]# range函数的参数和结果也并非一定要是正数或是递增的range(-4,4) # [-4, -3, -2, -1, 0, 1, 2, 3]range(4,-4,-1) # [4, 3, 2, 1, 0, -1, -2, -3] next 123456789101112131415161718192021# next(iterable[, default])# next() 返回迭代器的下一个项目# next() 函数要和生成迭代器的 iter() 函数一起使用# iterable -- 可迭代对象# default -- 可选，用于设置在没有下一个元素时返回该默认值，如果不设置，又没有下一个元素则会触发 StopIteration 异常。#!/usr/bin/python# -*- coding: UTF-8 -*- # 首先获得Iterator对象:it = iter([1, 2, 3, 4, 5])# 循环:while True: try: # 获得下一个值: x = next(it) print(x) except StopIteration: # 遇到StopIteration就退出循环 break enumerate 将一个可遍历的数据对象 (如列表、元组或字符串) 组合为一个索引序列，同时列出数据和数据下标 12345678# enumerate(sequence, [start=0])# sequence – 一个序列、迭代器或其他支持迭代对象。# start – 下标起始位置。# 返回 enumerate(枚举) 对象the_str = &quot;Python.&quot;the_str = enumerate(the_str)print(list(the_str)) # [(0, &#x27;P&#x27;), (1, &#x27;y&#x27;), (2, &#x27;t&#x27;), (3, &#x27;h&#x27;), (4, &#x27;o&#x27;), (5, &#x27;n&#x27;)] filter 用于过滤序列，过滤掉不符合条件的元素，返回一个迭代器对象该接收两个参数，第一个为函数，第二个为序列，序列的每个元素作为参数传递给函数进行判，然后返回 True 或 False，最后将返回 True 的元素放到新列表中 1234567891011# filter(function, iterable)# function – 判断函数# iterable – 可迭代对象# 返回一个迭代器对象# eg.过滤出列表中所有的奇数lst = [i for i in range(20)]lst = filter(lambda x:x%2==1,lst)print(list(lst))# [1, 3, 5, 7, 9, 11, 13, 15, 17, 19] map 会根据提供的函数对指定序列做映射。第一个参数 function 以参数序列中的每一个元素调用 function 函数，返回包含每次 function 函数返回值的新列表。 123456789# map(function, iterable, ...)# function -- 函数# iterable -- 一个或多个序列def square(x) : # 计算平方数 return x ** 2map(square, [1,2,3,4,5]) # 计算列表各个元素的平方 # &lt;map object at 0x100d3d550&gt; # 返回迭代器list(map(square, [1,2,3,4,5])) # 使用 list() 转换为列表 # [1, 4, 9, 16, 25]list(map(lambda x: x ** 2, [1, 2, 3, 4, 5])) # 使用 lambda 匿名函数 # [1, 4, 9, 16, 25] sorted 对所有可迭代的对象进行排序操作 12345678910# sorted(iterable, key=None, reverse=False)# iterable – 可迭代对象。# key – 指定带有单个参数的函数，用于从 iterable 的每个元素中提取用于比较的键进行排序# reverse – 排序规则，reverse = True 降序 ， reverse = False 升序（默认）# 返回重新排序的列表# eg.根据文件名中的数字进行排序files_name = [&#x27;py1.py&#x27;,&#x27;py10.py&#x27;,&#x27;py2.py&#x27;,&#x27;py5.py&#x27;,&#x27;py14.py&#x27;]lst =sorted(files_name,key=lambda x:int(x[2:-3]))# [&#x27;py1.py&#x27;, &#x27;py2.py&#x27;, &#x27;py5.py&#x27;, &#x27;py10.py&#x27;, &#x27;py14.py&#x27;] slice 1234l3 = [1,2,3,4,5,1,2,3,4,5]sli = slice(0,4,2)#定义一个切片规则print(l3[sli])#[1, 3]print(l3[0:4:2])#[1, 3]效果一样 reversed 1234567891011# 列表中reverse() 起到反转列表的作用，替换原有的列表l = [1,2,3,4,5]l.reverse()print(l)#[5, 4, 3, 2, 1]# reversed 则是不替换原有序列，返回一个迭代器，更节省内存l1 = [11,22,33,44,55]l2 = reversed(l1)print(l1)#[11, 22, 33, 44, 55]原列表不变print(l2)#返回一个迭代器print(list(l2))#强转为列表打印出来[55, 44, 33, 22, 11] 类型转换chr 将整数转化成对应的字符 123456chr(65) # &#x27;A&#x27;chr(32) # &#x27; &#x27;chr(16) # &#x27;\\x10&#x27;chr(20) # &#x27;\\x14&#x27;chr(26) # &#x27;\\x1a&#x27;chr(35) # &#x27;#&#x27; ord 将字符转换成整数 12345ord(&#x27;#&#x27;) # 35ord(&#x27;\\x01&#x27;) # 1ord(&#x27;A&#x27;) # 65ord(&#x27;a&#x27;) # 97ord(&#x27; &#x27;) # 32 str 把数、字符、列表、元组、字典转换成字符串 12345str(5) #&#x27;5&#x27;str(&#x27;c&#x27;) #&#x27;c&#x27;str([1,2,3]) #&#x27;[1, 2, 3]&#x27;str((1,2)) #&#x27;(1, 2)&#x27;str(&#123;&#x27;1&#x27;:2&#125;) #&quot;&#123;&#x27;1&#x27;: 2&#125;&quot; bool 将一个值转化为布尔值，如果该值为假或省略返回False，否则返回True 123456a = [0, 0.0, False, None, &#x27;&#x27;, (), [], &#123;&#125;]for i in a: print(bool(i), end = &#x27; &#x27;) # False False False False False False False False b = [1, -1, 1.0, &#x27;#&#x27;, (2, 3), [&#x27;a&#x27;], &#123;&#x27;a&#x27;: 1&#125;, &#x27;b&#x27;]for i in b: print(bool(i), end = &#x27; &#x27;) # True True True True True True True True int 把一个数、字符转换成整形。如果未空，返回0,；如果是数，返回x.int();如果是浮点数，取整数部分int(x, base = 10)如果给出base, 依据base返回对应值 12345678int() # 0int(0.9) # 0int(-1) # -1int(&#x27;123&#x27;) # 123int (&#x27;123&#x27;, base = 10) # 123int(&#x27;123&#x27;, base = 16) # 291int(&#x27;0xEE&#x27;, base = 16) # 238int(&#x27;0b11111111&#x27;, base = 2) # 255 float 把字符串或者一个数转换成浮点数 1234float(1) #1.0float(&#x27;1.123&#x27;) #1.123float (&#x27; 1.1&#x27;) #1.1float(&#x27; -123&#x27;) #-123.0 complex 123456# class complex([real[, imag]])# real -- int, long, float或字符串；# imag -- int, long, float；# 返回一个复数complex(1, 2) # (1 + 2j)complex(1) # 数字 (1 + 0j) bin 1bin(0xa) # &#x27;0b1010&#x27; oct 二进制转八进制 1oct(0b1010) # &#x27;0o12&#x27; hex 十进制转十六进制： 1hex(10) # &#x27;0xa&#x27; 数据结构dictlistsettuple 其他函数all all() 函数用于判断给定的可迭代参数 iterable 中的所有元素是否都为 TRUE，如果是返回 True，否则返回 False。元素除了是 0、空、None、False 外都算 True。 1234567891011121314151617181920212223242526272829303132333435363738# 函数等价于：def all(iterable): for element in iterable: if not element: return False return True# all(iterable)# iterable -- 元组或列表all([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;]) # 列表list，元素都不为空或0 # Trueall([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;&#x27;, &#x27;d&#x27;]) # 列表list，存在一个为空的元素 # Falseall([0, 1，2, 3]) # 列表list，存在一个为0的元素 # Falseall((&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;)) # 元组tuple，元素都不为空或0 # Trueall((&#x27;a&#x27;, &#x27;b&#x27;, &#x27;&#x27;, &#x27;d&#x27;)) # 元组tuple，存在一个为空的元素 # Falseall((0, 1, 2, 3)) # 元组tuple，存在一个为0的元素 # Falseall([]) # 空列表 # Trueall(()) # 空元组 # True```````any any() 函数用于判断给定的可迭代参数 iterable 是否全部为 False，则返回 False，如果有一个为 True，则返回 True。元素除了是 0、空、FALSE 外都算 TRUE。```python# 函数等价于：def any(iterable): for element in iterable: if element: return True return False# any(iterable)# iterable -- 元组或列表。any([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;]) # 列表list，元素都不为空或0 # True any([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;&#x27;, &#x27;d&#x27;]) # 列表list，存在一个为空的元素 # True any([0, &#x27;&#x27;, False]) # 列表list,元素全为0,&#x27;&#x27;,false # False any((&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;)) # 元组tuple，元素都不为空或0 # True any((&#x27;a&#x27;, &#x27;b&#x27;, &#x27;&#x27;, &#x27;d&#x27;)) # 元组tuple，存在一个为空的元素 # True any((0, &#x27;&#x27;, False)) # 元组tuple，元素全为0,&#x27;&#x27;,false # False any([]) # 空列表 # False any(()) # 空元组 # False id 返回对象的唯一标识符，标识符是一个整数。CPython 中 id() 函数用于获取对象的内存地址。 1234a = &#x27;runoob&#x27;id(a) #4531887632b = 1id(b) #140588731085608 input Python3.x 中 input() 函数接受一个标准输入数据，返回为 string 类型。Python2.x 中 input() 相等于 eval(raw_input(prompt)) ，用来获取控制台的输入。raw_input() 将所有输入作为字符串看待，返回字符串类型。而 input() 在对待纯数字输入时具有自己的特性，它返回所输入的数字的类型（ int, float ）。 12345a = input(&quot;input:&quot;) # input:123 # 输入整数type(a) # &lt;type &#x27;int&#x27;&gt; # 整型a = input(&quot;input:&quot;) # input:&quot;runoob&quot; # 正确，字符串表达式type(a) # &lt;type &#x27;str&#x27;&gt; # 字符串a = input(&quot;input:&quot;) open 12345678910111213141516171819202122# open(name[, mode[, buffering]])# name : 一个包含了你要访问的文件名称的字符串值。# mode : mode 决定了打开文件的模式：只读，写入，追加等。所有可取值见如下的完全列表。这个参数是非强制的，默认文件访问模式为只读(r)。# buffering : 如果 buffering 的值被设为 0，就不会有寄存。如果 buffering 的值取 1，访问文件时会寄存行。如果将 buffering 的值设为大于 1 的整数，表明了这就是的寄存区的缓冲大小。如果取负值，寄存区的缓冲大小则为系统默认。# 模式 描述# t 文本模式 (默认)。# x 写模式，新建一个文件，如果该文件已存在则会报错。# b 二进制模式。# + 打开一个文件进行更新(可读可写)。# U 通用换行模式（不推荐）。# r 以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。# rb 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。一般用于非文本文件如图片等。# r+ 打开一个文件用于读写。文件指针将会放在文件的开头。# rb+ 以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。一般用于非文本文件如图片等。# w 打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。# wb 以二进制格式打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。# w+ 打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。# wb+ 以二进制格式打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。# a 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。# ab 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。# a+ 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。# ab+ 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。 file 对象方法 file.read([size])：size 未指定则返回整个文件，如果文件大小 &gt;2 倍内存则有问题，f.read()读到文件尾时返回””(空字串)。 file.readline()：返回一行。 file.readlines([size]) ：返回包含size行的列表, size 未指定则返回全部行。 for line in f: print line ：通过迭代器访问。 f.write(“hello\\n”)：如果要写入字符串以外的数据,先将他转换为字符串。 f.tell()：返回一个整数,表示当前文件指针的位置(就是到文件头的字节数)。 f.seek(偏移量,[起始位置])：用来移动文件指针 偏移量: 单位为字节，可正可负 起始位置: 0 - 文件头, 默认值; 1 - 当前位置; 2 - 文件尾 f.close() 关闭文件 print 方法用于打印输出，最常见的一个函数。 123456# print(*objects, sep=&#x27; &#x27;, end=&#x27;\\n&#x27;, file=sys.stdout, flush=False)# objects -- 复数，表示可以一次输出多个对象。输出多个对象时，需要用 , 分隔。# sep -- 用来间隔多个对象，默认值是一个空格。# end -- 用来设定以什么结尾。默认值是换行符 \\n，我们可以换成其他字符串。# file -- 要写入的文件对象。# flush -- 输出是否被缓存通常决定于 file，但如果 flush 关键字参数为 True，流会被强制刷新。 type 1234567891011121314151617181920# type(object)# type(name, bases, dict)# name -- 类的名称。# bases -- 基类的元组。# dict -- 字典，类内定义的命名空间变量# 一个参数实例type(1) # &lt;type &#x27;int&#x27;&gt;type(&#x27;runoob&#x27;) # &lt;type &#x27;str&#x27;&gt;type([2]) # &lt;type &#x27;list&#x27;&gt;type(&#123;0:&#x27;zero&#x27;&#125;) # &lt;type &#x27;dict&#x27;&gt;x = 1 type( x ) == int # 判断类型是否相等 # True # 三个参数class X(object): a = 1X = type(&#x27;X&#x27;, (object,), dict(a=1)) # 产生一个新的类型 XX # &lt;class &#x27;__main__.X&#x27;&gt; 参考链接：https://blog.csdn.net/qq_36078992/article/details/105174536https://www.cnblogs.com/aizhinong/p/11407695.htmlhttps://blog.csdn.net/qq_36357820/article/details/77850841","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"Function","slug":"Function","permalink":"http://example.com/tags/Function/"}]},{"title":"高阶使用 Python","slug":"Python-imp","date":"2020-08-28T00:08:08.000Z","updated":"2022-09-30T08:25:04.000Z","comments":true,"path":"2020/08/28/Python-imp/","link":"","permalink":"http://example.com/2020/08/28/Python-imp/","excerpt":"人类大脑中，大约有1000亿个神经元，每个神经元与大约10万个神经元相连。从本质上说，这就是我们想要创造的，在某种程度上，这对机器来说是可行的。深度学习的目的是模仿人类大脑的工作方式。这在神经元，轴突，树突等方面意味着什么？嗯，神经元有胞体，树突和轴突。来自一个神经元的信号沿着轴突传播并转移到下一个神经元的树突。传递信号的那个连接被称为突触。","text":"人类大脑中，大约有1000亿个神经元，每个神经元与大约10万个神经元相连。从本质上说，这就是我们想要创造的，在某种程度上，这对机器来说是可行的。深度学习的目的是模仿人类大脑的工作方式。这在神经元，轴突，树突等方面意味着什么？嗯，神经元有胞体，树突和轴突。来自一个神经元的信号沿着轴突传播并转移到下一个神经元的树突。传递信号的那个连接被称为突触。 原文地址: CSDN-兔兔RabbitMQ 原地交换Python 提供了一个直观的在一行代码中赋值与交换（变量值）的方法 12345678x, y = 10, 20print(x, y)x, y = y, xprint(x, y)#1 (10, 20)#2 (20, 10) 链状比较操作符Python不用很多条件一个一个写，比较操作符可以聚合 123456n = 10result = 1 &lt; n &lt; 20print(result) # Trueresult = 1 &gt; n &lt;= 9print(result) # False 三元操作符进行条件赋值三元操作符是 if-else 语句也就是条件操作符的一个快捷方式：[表达式为真的返回值] if [表达式] else [表达式为假的返回值] 123456789# 给出一个你可以用来使代码紧凑简洁的例子。下面的语句是说“如果 y 是 9，给 x 赋值 10，不然赋值为 20“x = 10 if (y==9) else 20# 在列表推导中[m**2 if m &gt; 10 else m**4 for m in range(50)]# 判断最小值def small(a, b, c): return a if a &lt;= b and a &lt;= c else (b if b &lt;= a and b &lt;= c else c)# 类中x = (classA if y == 1 else classB)(param1, param2) 多行字符串直接多行注释 12345a=&#x27;&#x27;&#x27;dvfssdfsdfdsfsddsdsfbfdfasfafasfaf&#x27;&#x27;&#x27;print(a) in判断可以直接用来判断某个变量是否在列表中 1234可以使用下面的方式来验证多个值：if m in [1,3,5,7]:# 而不是：if m==1 or m==3 or m==5 or m==7: 四种翻转字符串/列表的方式123456789101112131415161718192021# 翻转列表本身testList = [1, 3, 5]testList.reverse()print(testList)#-&gt; [5, 3, 1]# 在一个循环中翻转并迭代输出for element in reversed([1,3,5]): print(element)#1-&gt; 5#2-&gt; 3#3-&gt; 1# 一行代码翻转字符串&quot;Test Python&quot;[::-1]# 输出 “nohtyP tseT”# 使用切片翻转列表[1, 3, 5][::-1]#输出 [5,3,1] 一次初始化多个变量可以直接赋值 1a,b,c,d=1,2,3,4 可以利用列表 1234List = [1,2,3]x,y,z=Listprint(x, y, z)#-&gt; 1 2 3 打印模块路径123import socketprint(socket)#&lt;module &#x27;socket&#x27; from &#x27;/usr/lib/python2.7/socket.py&#x27;&gt; 字典推导python不光有列表推导式 字典/集合也有 12345678910111213#列表l=[[0 for i in range(4)] for i in range(4)]#生成二维列表print(l)# [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]#字典testDict = &#123;i: i * i for i in range(10)&#125;testSet = &#123;i * 2 for i in range(10)&#125;print(testSet)print(testDict)#set([0, 2, 4, 6, 8, 10, 12, 14, 16, 18])#&#123;0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81&#125; 拼接字符串python中字符串可以相加 1234a=&quot;i &quot;b=&quot;love &quot;c=&quot;you&quot;print(a+b+c) 拼接列表中的所有元素为一个字符串 123l=[&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;]print(&#x27;&#x27;join(l))#以join左边的字符做分割 循环枚举索引方便找到下标和对应元素 1234567list = [10, 20, 30]for i, value in enumerate(list): print(i, &#x27;: &#x27;, value)#1-&gt; 0 : 10#2-&gt; 1 : 20#3-&gt; 2 : 30 返回多个值并没有太多编程语言支持这个特性，然而 Python 中的方法确实（可以）返回多个值 12def a(): return 1,2,3,4,5 开启文件分享(这条还不是很理解 没具体用过)Python 允许运行一个 HTTP 服务器来从根路径共享文件，下面是开启服务器的命令： 1python3 -m http.server 上面的命令会在默认端口也就是 8000 开启一个服务器，你可以将一个自定义的端口号以最后一个参数的方式传递到上面的命令中。 调试脚本可以在 模块的帮助下在 Python 脚本中设置断点，例子： 12import pdbpdb.set_trace() 直接迭代序列元素对序列（str、list、tuple等），直接迭代序列元素，比迭代元素的索引速度要更快。 1234567&gt;&gt;&gt; l=[0,1,2,3,4,5]&gt;&gt;&gt; for i in l: print(i)#快&gt;&gt;&gt; for i in range(len(l)): print(l[i])#慢 巧用else语句（重要）python的else 子句不仅能在 if 语句中使用，还能在 for、while 和 try 等语句中使用，这个语言特性不是什么秘密，但却没有得到重视。 123456789101112131415161718192021222324252627282930313233# forl=[1,2,3,4,5]for i in l: if i==&#x27;6&#x27;: print(666) breakelse: print(999)# 如果不这么实现，只能设置一个变量来记录：l=[1,2,3,4,5]a = 1for i in l: if i==&#x27;6&#x27;: print(666) a = 0 breakif a: print(999)# while和for类似try: a()except OSError: #语句1else: #语句2# for: 仅当 for 循环运行完毕时（即 for 循环没有被 break 语句中止）才运行 else 块。# while: 仅当 while 循环因为条件为假值而退出时（即 while 循环没有被break 语句中止）才运行 else 块。# try:仅当 try 块中没有异常抛出时才运行 else 块。# 如果异常或者 return、break 或 continue 语句导致控制权跳到了复合语句的主块之外，那么else 子句也会被跳过。# 按正常的理解应该是“要么运行这个循环，要么做那件事”。可是，在循环中，else 的语义恰好相反：“运行这个循环，然后做那件事。” except的用法和作用12345678try/except: 捕捉由PYTHON自身或写程序过程中引发的异常并恢复except: 捕捉所有其他异常except name: 只捕捉特定的异常except name, value: 捕捉异常及格外的数据(实例)except (name1,name2) 捕捉列出来的异常except (name1,name2),value: 捕捉任何列出的异常，并取得额外数据else: 如果没有引发异常就运行finally: 总是会运行此处代码 python自省123这个也是python彪悍的特性.自省就是面向对象的语言所写的程序在运行时,所能知道对象的类型.简单一句就是运行时能够获得对象的类型.比如type(),dir(),getattr(),hasattr(),isinstance(). python容器1234列表：元素可变（任何数据类型），有序（可索引），append/insert/pop；元组：元素不可变，但元素中的可变元素是可变的；有序（可索引）；而且元组可以被散列，例如作为字典的键。集合：无序（不可被索引）、互异字典：无序，键值对（key：value），key唯一不可重复 map()map()函数接收两个参数，一个是函数，一个是Iterable，map将传入的函数依次作用到序列的每个元素，并把结果作为新的Iterator返回。（重点理解）比如有一个函数f(x)=x2，要把这个函数作用在一个list [1, 2, 3, 4, 5, 6, 7, 8, 9]上，就可以用map()实现如下： 123456def f(x): return x * xr = map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9])list(r)[1, 4, 9, 16, 25, 36, 49, 64, 81] map()作为高阶函数，事实上它把运算规则抽象了，因此，我们不但可以计算简单的f(x)=x2，还可以计算任意复杂的函数，比如，把这个list所有数字转为字符串： 12list(map(str, [1, 2, 3, 4, 5, 6, 7, 8, 9]))[&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;] reducereduce把一个函数作用在一个序列[x1, x2, x3, …]上，这个函数必须接收两个参数，reduce把结果继续和序列的下一个元素做累积计算 123456from functools import reducedef fn(x,y): return x * 10 +yreduce(fn,[1,3,5,7,9])13579 结合一下，我们可以自己写出int（）函数 123456789from functools import reducea=&#123;&#x27;0&#x27;: 0, &#x27;1&#x27;: 1, &#x27;2&#x27;: 2, &#x27;3&#x27;: 3, &#x27;4&#x27;: 4, &#x27;5&#x27;: 5, &#x27;6&#x27;: 6, &#x27;7&#x27;: 7, &#x27;8&#x27;: 8, &#x27;9&#x27;: 9&#125;def charnum(s): return a[s]def strint(s): return reduce(lambda x, y: x * 10 + y, map(charnum, s)) splitPython split() 通过指定分隔符对字符串进行切片，如果参数 num 有指定值，则仅分隔 num 个子字符串。 123str.split(str=&quot;&quot;, num=string.count(str))str.split(&quot;&quot;) filterPython内建的filter()函数用于过滤序列。 和map()类似，filter()也接收一个函数和一个序列。和map()不同的是，filter()把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素 简单例子，删掉偶数： 12345def is_odd(n): return n % 2 == 1list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15]))# 结果: [1, 5, 9, 15] 利用filter()不断产生筛选后的新的序列Iterator是惰性计算的序列，所以我们可以用Python表示“全体自然数”，“全体素数”这样的序列，而代码非常简洁。 12345678910111213141516171819#先构造一个从3开始的奇数序列：def _odd_iter(): n = 1 while True: n = n + 2 yield n#这是一个生成器，并且是一个无限序列。#筛选函数def _not_divisible(n): return lambda x: x % n &gt; 0#生成器def primes(): yield 2 it = _odd_iter() # 初始序列 while True: n = next(it) # 返回序列的第一个数 yield n it = filter(_not_divisible(n), it) # 构造新序列 sorted123456sorted([36, 5, -12, 9, -21])#[-21, -12, 5, 9, 36]#可以接收一个key函数来实现自定义的排序，例如按绝对值大小排序：sorted([36, 5, -12, 9, -21], key=abs)#[5, 9, -12, -21, 36] 再看一个字符串排序的例子： 12orted([&#x27;bob&#x27;, &#x27;about&#x27;, &#x27;Zoo&#x27;, &#x27;Credit&#x27;])# [&#x27;Credit&#x27;, &#x27;Zoo&#x27;, &#x27;about&#x27;, &#x27;bob&#x27;] 默认情况下，对字符串排序，是按照ASCII的大小比较的，由于’Z’ &lt; ‘a’，结果，大写字母Z会排在小写字母a的前面。 现在，我们提出排序应该忽略大小写，按照字母序排序。要实现这个算法，不必对现有代码大加改动，只要我们能用一个key函数把字符串映射为忽略大小写排序即可。忽略大小写来比较两个字符串，实际上就是先把字符串都变成大写（或者都变成小写），再比较。 这样，我们给sorted传入key函数，即可实现忽略大小写的排序： 12sorted([&#x27;bob&#x27;, &#x27;about&#x27;, &#x27;Zoo&#x27;, &#x27;Credit&#x27;], key=str.lower)#[&#x27;about&#x27;, &#x27;bob&#x27;, &#x27;Credit&#x27;, &#x27;Zoo&#x27; 要进行反向排序，不必改动key函数，可以传入第三个参数reverse=True： 12sorted([&#x27;bob&#x27;, &#x27;about&#x27;, &#x27;Zoo&#x27;, &#x27;Credit&#x27;], key=str.lower, reverse=True)[&#x27;Zoo&#x27;, &#x27;Credit&#x27;, &#x27;bob&#x27;, &#x27;about&#x27; 从上述例子可以看出，高阶函数的抽象能力是非常强大的，而且，核心代码可以保持得非常简洁。 sorted()也是一个高阶函数。用sorted()排序的关键在于实现一个映射函数。","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"Function","slug":"Function","permalink":"http://example.com/tags/Function/"}]},{"title":"数据处理 python pandas","slug":"Python-pands","date":"2020-08-28T00:08:08.000Z","updated":"2022-09-30T08:25:04.000Z","comments":true,"path":"2020/08/28/Python-pands/","link":"","permalink":"http://example.com/2020/08/28/Python-pands/","excerpt":"通往机器学习算法工程师的进阶之路是崎岖险阻的。《线性代数》 《统计学习方法》《机器学习》《模式识别》《深度学习》，以及《颈椎病康复指南》，这些书籍将长久地伴随着你的工作生涯。除了拥有全面、有条理的知识储备，想成为一名优秀的算法工程师，更重要的是对算法模型有着发自心底的热忱，对研究工作有一种匠心精神。这种匠心精神，直白来讲，可以概括为：发现问题的眼光、解决问题的探索精神，以及对问题究原竟委的执着追求","text":"通往机器学习算法工程师的进阶之路是崎岖险阻的。《线性代数》 《统计学习方法》《机器学习》《模式识别》《深度学习》，以及《颈椎病康复指南》，这些书籍将长久地伴随着你的工作生涯。除了拥有全面、有条理的知识储备，想成为一名优秀的算法工程师，更重要的是对算法模型有着发自心底的热忱，对研究工作有一种匠心精神。这种匠心精神，直白来讲，可以概括为：发现问题的眼光、解决问题的探索精神，以及对问题究原竟委的执着追求 12# 在使用之前，需要导入pandas库import pandas as pd 导入数据12345678import pandas as pdpd.DataFrame() # 自己创建数据框，用于练习pd.read_csv(filename) # 从CSV⽂件导⼊数据pd.read_table(filename) # 从限定分隔符的⽂本⽂件导⼊数据pd.read_excel(filename) # 从Excel⽂件导⼊数据pd.read_sql(query,connection_object) # 从SQL表/库导⼊数据pd.read_json(json_string) # 从JSON格式的字符串导⼊数据pd.read_html(url) # 解析URL、字符串或者HTML⽂件，抽取其中的tables表格 导出数据1234567df.to_csv(filename) #导出数据到CSV⽂件df.to_excel(filename) #导出数据到Excel⽂件df.to_sql(table_name,connection_object) #导出数据到SQL表df.to_json(filename) #以Json格式导出数据到⽂本⽂件writer=pd.ExcelWriter(&#x27;test.xlsx&#x27;,index=False)df1.to_excel(writer,sheet_name=&#x27;单位&#x27;)和writer.save()，将多个数据帧写⼊同⼀个⼯作簿的多个sheet(⼯作表) 查看数据123456789101112df.head(n) # 查看DataFrame对象的前n⾏df.tail(n) # 查看DataFrame对象的最后n⾏df.shape() # 查看⾏数和列数df.info() # 查看索引、数据类型和内存信息df.columns() # 查看字段（⾸⾏）名称df.describe() # 查看数值型列的汇总统计s.value_counts(dropna=False) # 查看Series对象的唯⼀值和计数df.apply(pd.Series.value_counts) # 查看DataFrame对象中每⼀列的唯⼀值和计数df.isnull().any() # 查看是否有缺失值df[df[column_name].duplicated()] # 查看column_name字段数据重复的数据信息df[df[column_name].duplicated()].count() # 查看column_name字段数据重复的个数 数据选取12345678910111213df[col] # 根据列名，并以Series的形式返回列df[[col1,col2]] # 以DataFrame形式返回多列s.iloc[0] # 按位置选取数据s.loc[&#x27;index_one&#x27;] # 按索引选取数据df.iloc[0,:] # 返回第⼀⾏df.iloc[0,0] # 返回第⼀列的第⼀个元素df.loc[0,:] # 返回第⼀⾏（索引为默认的数字时，⽤法同df.iloc），但需要注意的是loc是按索引,iloc参数只接受数字参数df.ix[[:5],[&quot;col1&quot;,&quot;col2&quot;]] # 返回字段为col1和col2的前5条数据，可以理解为loc和iloc的结合体。df.at[5,&quot;col1&quot;] # 选择索引名称为5，字段名称为col1的数据df.iat[5,0] # 选择索引排序为5，字段排序为0的数据 数据处理1234567891011121314151617df.columns= [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;] # 重命名列名（需要将所有列名列出，否则会报错）pd.isnull() # 检查DataFrame对象中的空值，并返回⼀个Boolean数组pd.notnull() # 检查DataFrame对象中的⾮空值，并返回⼀个Boolean数组df.dropna() # 删除所有包含空值的⾏df.dropna(axis=1) # 删除所有包含空值的列df.dropna(axis=1,thresh=n) # 删除所有⼩于n个⾮空值的⾏df.fillna(value=x) # ⽤x替换DataFrame对象中所有的空值，⽀持df[column_name].fillna(x)s.astype(float) # 将Series中的数据类型更改为float类型s.replace(1,&#x27;one&#x27;) # ⽤‘one’代替所有等于1的值s.replace([1,3],[&#x27;one&#x27;,&#x27;three&#x27;]) # ⽤&#x27;one&#x27;代替1，⽤&#x27;three&#x27;代替3df.rename(columns=lambdax:x+1) # 批量更改列名df.rename(columns=&#123;&#x27;old_name&#x27;:&#x27;new_ name&#x27;&#125;) # 选择性更改列名df.set_index(&#x27;column_one&#x27;) # 将某个字段设为索引，可接受列表参数，即设置多个索引df.reset_index(&quot;col1&quot;) # 将索引设置为col1字段，并将索引新设置为0,1,2...df.rename(index=lambdax:x+1) # 批量重命名索引 数据分组、排序、透视1234567891011121314df.sort_index().loc[:5] # 对前5条数据进⾏索引排序df.sort_values(col1) # 按照列col1排序数据，默认升序排列df.sort_values(col2,ascending=False) # 按照列col1降序排列数据df.sort_values([col1,col2],ascending=[True,False]) # 先按列col1升序排列，后按col2降序排列数据df.groupby(col) # 返回⼀个按列col进⾏分组的Groupby对象df.groupby([col1,col2]) # 返回⼀个按多列进⾏分组的Groupby对象df.groupby(col1)[col2].agg(mean) # 返回按列col1进⾏分组后，列col2的均值,agg可以接受列表参数，agg([len,np.mean])df.pivot_table(index=col1,values=[col2,col3],aggfunc=&#123;col2:max,col3:[ma,min]&#125;) # 创建⼀个按列col1进⾏分组，计算col2的最⼤值和col3的最⼤值、最⼩值的数据透视表df.groupby(col1).agg(np.mean) # 返回按列col1分组的所有列的均值,⽀持df.groupby(col1).col2.agg([&#x27;min&#x27;,&#x27;max&#x27;])data.apply(np.mean) # 对DataFrame中的每⼀列应⽤函数np.meandata.apply(np.max,axis=1) # 对DataFrame中的每⼀⾏应⽤函数np.maxdf.groupby(col1).col2.transform(&quot;sum&quot;) # 通常与groupby连⽤，避免索引更改 数据合并12345df1.append(df2) # 将df2中的⾏添加到df1的尾部df.concat([df1,df2],axis=1,join=&#x27;inner&#x27;) # 将df2中的列添加到df1的尾部,值为空的对应⾏与对应列都不要df1.join(df2.set_index(col1),on=col1,how=&#x27;inner&#x27;) # 对df1的列和df2的列执⾏SQL形式的join，默认按照索引来进⾏合并，如果df1和df2有共同字段时，会报错，可通过设置lsuffix,rsuffix来进⾏解决，如果需要按照共同列进⾏合并，就要⽤到set_index(col1)pd.merge(df1,df2,on=&#x27;col1&#x27;,how=&#x27;outer&#x27;) # 对df1和df2合并，按照col1，⽅式为outerpd.merge(df1,df2,left_index=True,right_index=True,how=&#x27;outer&#x27;) #与 df1.join(df2, how=&#x27;outer&#x27;)效果相同 参考链接 [https://blog.csdn.net/weixin_41261833/article/details/115598697]","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"Function","slug":"Function","permalink":"http://example.com/tags/Function/"},{"name":"Pandas","slug":"Pandas","permalink":"http://example.com/tags/Pandas/"}]},{"title":"常用工具 Python","slug":"Python-utils","date":"2020-08-28T00:08:08.000Z","updated":"2022-09-30T08:27:08.000Z","comments":true,"path":"2020/08/28/Python-utils/","link":"","permalink":"http://example.com/2020/08/28/Python-utils/","excerpt":"项目开发常用复用的工具函数","text":"项目开发常用复用的工具函数 时间相关获取两个日期之间的所有日期 返回list12345678910import datetimedef getEveryDay(begin_date,end_date): date_list = [] begin_date = datetime.datetime.strptime(begin_date, &quot;%Y-%m-%d&quot;) end_date = datetime.datetime.strptime(end_date,&quot;%Y-%m-%d&quot;) while begin_date &lt;= end_date: date_str = begin_date.strftime(&quot;%Y-%m-%d&quot;) date_list.append(date_str) begin_date += datetime.timedelta(days=1) return date_list 根据时间差获取日期12345import datetimedef get_date_by_gap(start_date,day_gap): start_date = datetime.datetime.strftime( datetime.datetime.strptime(start_date,&#x27;%Y-%m-%d&#x27;)+ datetime.timedelta(days=day_gap),&#x27;%Y-%m-%d&#x27;) return start_date 数据操作相关对某些列做四舍五入操作12345def round_df_col(df, col_list=qty_list): col_list.extend([&#x27;ben_&#x27;+str(i) for i in col_list]) for col in list(df): if col in col_list: df[col]= df[col].round(0) python 生成row number()123def row_number(dataset, partionby, orderby, asc): return dataset[orderby].groupby(dataset[partionby]).rank(ascending=asc, method=&#x27;first&#x27;) python行转列辅助函数123456789101112import pandas as pddef flatten_multi_index(multi_index, join_str=&#x27;_&#x27;): label0 = multi_index.get_level_values(0) label1 = multi_index.get_level_values(1) index = [i + join_str + j for i,j in zip(label0, label1)] return pd.Index(index)# 使用样例post_bs_temp5 = pd.pivot_table(post_bs_temp4,index=[&#x27;article_1&#x27;,&#x27;launch_date&#x27;],columns=&quot;cn_ecom_store&quot;)post_bs_temp5.columns = flatten_multi_index(post_bs_temp5.columns)post_bs_temp5 = post_bs_temp5.reset_index() 字典操作 123456789import jsondef dump_json(obj, fn, encoding=&#x27;utf-8&#x27;): with open(fn, &#x27;w&#x27;, encoding=encoding) as fout: json.dump(obj, fout, ensure_ascii=False, indent=4)def load_json(fn, encoding=&#x27;utf-8&#x27;): with open(fn, &#x27;r&#x27;, encoding=encoding) as fin: return json.load(fin) 文件操作 1234567891011121314151617181920import osimport shutildef make_path(file_path): if not os.path.exists(file_path): os.makedirs(file_path)def file_copy(file_path, target_path): make_path(target_path) shutil.copy(file_path, target_path)def folder_copy(from_folder, to_folder): pathDir = os.listdir(from_folder) for filename in pathDir: from_path = os.path.join(from_folder, filename) to_path = to_folder file_copy(from_path, to_path)","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"Function","slug":"Function","permalink":"http://example.com/tags/Function/"}]},{"title":"基础操作 Shell","slug":"Tools-Shell","date":"2020-08-28T00:08:08.000Z","updated":"2022-09-30T09:41:40.000Z","comments":true,"path":"2020/08/28/Tools-Shell/","link":"","permalink":"http://example.com/2020/08/28/Tools-Shell/","excerpt":"人类大脑中，大约有1000亿个神经元，每个神经元与大约10万个神经元相连。从本质上说，这就是我们想要创造的，在某种程度上，这对机器来说是可行的。深度学习的目的是模仿人类大脑的工作方式。这在神经元，轴突，树突等方面意味着什么？嗯，神经元有胞体，树突和轴突。来自一个神经元的信号沿着轴突传播并转移到下一个神经元的树突。传递信号的那个连接被称为突触。","text":"人类大脑中，大约有1000亿个神经元，每个神经元与大约10万个神经元相连。从本质上说，这就是我们想要创造的，在某种程度上，这对机器来说是可行的。深度学习的目的是模仿人类大脑的工作方式。这在神经元，轴突，树突等方面意味着什么？嗯，神经元有胞体，树突和轴突。来自一个神经元的信号沿着轴突传播并转移到下一个神经元的树突。传递信号的那个连接被称为突触。 Shellshell脚本123456shell:shell脚本加密：https://blog.csdn.net/qq_35603331/article/details/83793475用一个SHELL保存多台SSH账号密码，一个参数就能登录指定服务器 ：https://blog.csdn.net/daisho/details/89467916 关联多个shell脚本文件：https://jingyan.baidu.com/a17d5285fd05d88098c8f2df.html shell菜鸟教程：https://www.runoob.com/linux/linux-shell-array.htmlshell读取文件某行内容：https://blog.csdn.net/sxf_123456/article/details/70739127shell脚本之间的变量传递：https://blog.csdn.net/dreamcoding/article/details/8519708 shell echo1234567891011-n 输出之后不换行 -e 对于转义字符按相应的方式处理\\b 表示删除前面的空格\\n 表示换行\\t 表示水平制表符\\v 表示垂直制表符\\c \\c后面的字符将不会输出，同时，输出完成后也不会换行\\r 输出回车符（但是你会发现\\r前面的字符没有了）\\a 表示输出一个警告声音&gt; echo &quot;hello world!&quot; &gt; test1.tmp 把内容输出到文件中而不是标准输出echo &quot;&quot; 打印空行 shell $12345678910111213141516171819$&#123;变量名&#125; 调用定义过的变量$# 传给脚本的参数个数$0 脚本本身的名字$1 传递给该shell脚本的第1个参数$2 传递给该shell脚本的第2个参数$@ 传给脚本的所有参数的列表$* 以一个单字符串显示所有向脚本传递的参数，与位置变量不同，参数可超过9个$$ 脚本运行的当前进程ID号$? 命令执行结果反馈，0表示执行成功，其余数字表示执行不成功$() 做命令替换用(commandsubstitution) ———— 并不是所有shell都支持` ` 做命令替换用(commandsubstitution) ———— 基本上可用在全部的 unix shell 中使用$&#123; &#125; 用于变量替换 $var 与$&#123;var&#125;一样$[] 进行数学运算 支持+ - * / %：分别为 “加、减、乘、除、取模”$(()) 进行数学运算 支持+ - * / %：分别为 “加、减、乘、除、取模”$((16#2a)) 结果为 42 (16进位转十进制) 作不同进位(如二进制、八进位、十六进制)作运算 输出结果皆为十进制$&#123;&#125; 参数替换$*,$@ 位置参数$? 退出状态$$ 进程ID shell 符号123456789101112131415161718192021222324252627282930313233343536# 注释 #！除外echo $&#123;PATH#*:&#125; 这里不表示注释, 数制转换, 不表示注释echo $((2#101011)) [] test命令的另一种形式 // 数组元素, 例如 array[1]=abc // 字符范围, 在正则表达式中使用(( )) [ ]的针对数学比较表达式的加强版[[ ]] [ ]的针对字符串表达式的加强版 test 表达式本身放在[] 里; 命令行分隔符, 可以在一行中写多个命令. echo hello; echo there;; 终止 case 选项. 隐藏文件前缀 // .命令等价于source // . 表示当前目录 .. 表示上一级目录 // 正则表达式中作为单个字符匹配&quot;&quot; 组织特殊字符 双引号中可以引用变量&#x27;&#x27; 组织特殊字符 单引号中不能引用变量\\ 转义字符/ 文件名分隔符 // 除法` 后置引用 命令替换: 空命令 等价于 “NOP” // 也可被认为是 shell 内建命令 true 作用相同, 例如: 死循环 //在 if/then 语句中做占位符! 取反操作符 != 不等于? 测试操作 // 正则表达式中, ? 匹配任意单个字符 * 万能匹配符, 正则表达式中 数学乘法 // ** 幂运算$ 变量符号 // 正则表达式中 行结束符() &#123;xxx,yyy,zzz&#125; cat &#123;file1,file2,file3&#125; &gt; combined_file 将file1,file2,file3合并在一起并重定向到commbined_file中. 大括号中不能有空格&#123;&#125; &#123;&#125;\\; 路径名, 一般都是在 find 命令中使用, 注意; 用来结束find 命令序列的 –exec&gt;&amp; &gt;&gt;&amp; &gt;&gt; &lt; 重定向scriptname &gt; filename 重定向脚本的输出到文件中, 覆盖原有内容command &amp;&gt; filename 重定向 stdout 和 stderr 到文件中command &gt;&amp;2 重定向 stdout 和 stderrscriptname &gt;&gt; filename 重定向脚本输出到文件中, 添加到文件尾端, 如果没有文件, 则创建这个文件.&lt;&lt; &lt;&lt;&lt; 重定向, &lt;&lt; 用在“here document”, &lt;&lt;&lt; 用在“here string”\\&lt;, \\&gt; 正则表达式中的单词边界 grep ‘\\&#x27; testfile| 管道, 分析前边命令的输出, 并将输出作为后边命令的输入&gt;| 强制重定向|| 逻辑或&amp; 后台运行命令, 一个命令后边跟一个&amp;, 将表示在后台运行&amp;&amp; 逻辑与 shell 运算符1234567891011-eq //equal 等于-ne //no equal 不等于-gt //great than 大于-lt // low than 小于ge // great and equal 大于等于，注意没有&quot;-&quot;le //low and equal 小于等于，注意没有“-”case ... esacexportpre_check查看用户群组： echo $(ssh -n cmadmin@review.source.unisoc.com -p29418 gerrit ls-groups --user luna.xiong) shell if123456789101112131415161718if fi 定义判断https://www.cnblogs.com/myitm/archive/2012/07/05/2577416.htmlif [ -f file ] 如果文件存在if [ -d ... ] 如果目录存在if [ -s file ] 如果文件存在且非空if [ -r file ] 如果文件存在且可读if [ -w file ] 如果文件存在且可写if [ -x file ] 如果文件存在且可执行if [ int1 -eq int2 ] 如果int1等于int2 if [ int1 -ne int2 ] 如果不等于 if [ int1 -ge int2 ] 如果&gt;=if [ int1 -gt int2 ] 如果&gt;if [ int1 -le int2 ] 如果&lt;=if [ int1 -lt int2 ] 如果&lt;If [ $a = $b ] 如果string1等于string2 字符串允许使用赋值号做等号if [ $string1 != $string2 ] 如果string1不等于string2 if [ -n $string ] 如果string 非空(非0），返回0(true) if [ -z $string ] 如果string 为空if [ $sting ] 如果string 非空，返回0 (和-n类似)","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Shell","slug":"Shell","permalink":"http://example.com/tags/Shell/"}]},{"title":"数据处理 DataFrame","slug":"Python-Dataframe","date":"2019-09-20T07:09:12.000Z","updated":"2023-02-16T12:14:34.000Z","comments":true,"path":"2019/09/20/Python-Dataframe/","link":"","permalink":"http://example.com/2019/09/20/Python-Dataframe/","excerpt":"数据帧(DataFrame)是二维数据结构，即数据以行和列的表格方式排列。","text":"数据帧(DataFrame)是二维数据结构，即数据以行和列的表格方式排列。 数据帧(DataFrame)的功能特点： 潜在的列是不同的类型大小可变标记轴(行和列)可以对行和列执行算术运算https://www.yiibai.com/pandas/python_pandas_dataframe.html ssssDataFrame 某一列字母转大写 1df[&#x27;列名&#x27;] = df[&#x27;列名&#x27;].str.upper() DataFrame 按指定字符串拼接两列：df.concat 1df3 = pd.concat([df1[&#x27;cosine&#x27;],df1[&#x27;couple_product_id&#x27;].str.split(&#x27;_&#x27;, expand=True)], axis=1) DataFrame 对列重命名 ：df.rename 1df3.rename(columns=&#123;0:&#x27;product_id_a&#x27;, 1:&#x27;product_id_b&#x27;&#125;, inplace=True) DataFrame 取某些列 1df5 = df2[df2[&#x27;product_id&#x27;].isin(random_sample_b)] DataFrame 删除某些列 1df4 = df4.drop(columns=[&#x27;sku_code&#x27;, &#x27;bundleproduct_main_sku&#x27;]) DataFrame 按条件取行 选取等于某些值的行记录 用 == 1df.loc[df[‘column_name’] == some_value] 选取某列是否是某一类型的数值 用 isin 1df.loc[df[‘column_name’].isin(some_values)] 多种条件的选取 用 &amp; 1df.loc[(df[‘column’] == some_value) &amp; df[‘other_column’].isin(some_values)] 选取不等于某些值的行记录 用 ！= 1df.loc[df[‘column_name’] != some_value] isin返回一系列的数值,如果要选择不符合这个条件的数值使用~ 1df.loc[~df[‘column_name’].isin(some_values) DataFrame 横向对应拼接 1df389 = pd.merge(df38, df9, how=&#x27;left&#x27;, on=&#x27;product_b&#x27;) DataFrame 求某列均值 1df[col].mean()) DataFrame 筛选某列为指定值的数据 123Df1 = df1[df1[&#x27;A&#x27;].isin([1])]df1[df1[&#x27;A&#x27;].isin([1])] 选取df1中A列包含数字1的行 DataFrame 前一个和后一个词组成元组 1[(word[i],word[i+1]) for I in range(len(words)-1)] DataFrame merge报错 不同类型不能merge 1base_df[&#x27;article_id&#x27;] = base_df[&#x27;article_id&#x27;].apply(int) DataFrame drop_duplicates()删除重复行 1df389_Lancome = df389_Lancome.drop_duplicates() DataFrame 直接新增列 12345data[&#x27;d&#x27;] = [5,6]append 新增行res = pd.DataFrame(columns=(&#x27;lib&#x27;, &#x27;qty1&#x27;, &#x27;qty2&#x27;))res = res.append([&#123;&#x27;qty1&#x27;:10.0&#125;], ignore_index=True)items_a = df9[&#x27;product_id_a&#x27;].to_list() DataFrame 读取csv 设置数据类型 1df = pd.read_csv(&quot;somefile.csv&quot;, dtype = &#123;&#x27;column_name&#x27; : str&#125;) DataFrame 筛选多项条件 1some = all_data[(all_data[&#x27;User_id&#x27;] == 1439408) &amp; (all_data[&#x27;Date&#x27;].isna())] DataFrame 取某行某列的value 12[pd.at][i,‘j’]pd.loc[i,j] = value DataFrame 填充空值的方法 123df3_sum_MakeUp_Fragrance_Oil.fillna(value=0)df.fillna(method=&#x27;pad&#x27;,axis=0) # 用前一行的值填充df.fillna(method=&#x27;backfill&#x27;,axis=1) # 用后一列的值填充 DataFrame 根据某列排序 1df.sort_values(by=[&#x27;col1&#x27;],na_position=&#x27;first&#x27;)) DataFrame 计算pd每一列的均值 12for col in df.columns:print(&quot;该列数据的均值位%.2f&quot; %df[col].mean()) #计算每列均值 DataFrame 取dataframe特定行/列 (https://www.cnblogs.com/nxf-rabbit75/p/10105271.html) DataFrame 设置某列数据保留两位小数 1data[u&#x27;线损率&#x27;] = data[u&#x27;线损率&#x27;].apply(lambda x: format(x, &#x27;.2%&#x27;)) DataFrame 统计某一列中各值出现的次数 1df_train.loc[:,&#x27;label&#x27;].value_counts() DataFrame 对象列的最大值、最小值、平均值、标准差、中位数 123456df.sum() 求和Df.max() 最大值Df.mix() 最小值Df.std() 标准差Df.decribe() 数据的详细信息25%，50%，75%就是将列内的数值由小到大排列并分成四等份，处于25%、50%、75%三个分割点位置的数值 DateFrame新增一列 1data[&#x27;c&#x27;] = &#x27;&#x27; DataFrame 删除指定列空值的行 1df1 = df1.dropna(subset=[&quot;豆瓣评分&quot;,&quot;评分人数&quot;]) DataFrame 字符串拼接 123df_session01[&#x27;user_id&#x27;] = df_session01[&#x27;user_id&#x27;].apply(str)df_session01[&#x27;session_id&#x27;] = df_session01[&#x27;session_id&#x27;].apply(str)df_session01[&#x27;user_id_session&#x27;] = df_session01[&#x27;user_id&#x27;].str.cat(df_session01[&#x27;session_id&#x27;],sep=&quot;_&quot;)","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"DataFrame","slug":"DataFrame","permalink":"http://example.com/tags/DataFrame/"}]},{"title":"数据库操作 Hive / sql sever","slug":"SQL-Database","date":"2019-09-18T07:21:12.000Z","updated":"2023-02-16T15:40:20.000Z","comments":true,"path":"2019/09/18/SQL-Database/","link":"","permalink":"http://example.com/2019/09/18/SQL-Database/","excerpt":"数据库在磁盘上就是一个文件；数据库管理系统是管理数据库的一个软件； 数据库：存放数据的仓库；Databsae,简称DB模型训练需要使用大量的数据 使用python读取数据库再用 pandas 进行操作 占用时间/内存资源 并且处理大量数据时效率较低实际使用时直接在数据库里进行简单的字符串操作/数据简单的加减乘除等 最后把处理后的数据结果表拉近python用于模型训练等操作","text":"数据库在磁盘上就是一个文件；数据库管理系统是管理数据库的一个软件； 数据库：存放数据的仓库；Databsae,简称DB模型训练需要使用大量的数据 使用python读取数据库再用 pandas 进行操作 占用时间/内存资源 并且处理大量数据时效率较低实际使用时直接在数据库里进行简单的字符串操作/数据简单的加减乘除等 最后把处理后的数据结果表拉近python用于模型训练等操作 数据库基础 数据表：在数据库(database)中,可以创建很多张表(table) ；通常情况下,一张表用于保存一类数据,例如网站中的所有用户信息会保存在一张表中,所有商品信息会保存在另一张表中 表记录：数据表中(table)中,可以插入很多条记录；数据表往往保存一类数据,对应java中的一个类；而一条记录往往对应java中的一个具体的实例 （即表中的一行数据） 数据库管理系统：对数据库进行统一地管理和控制，以保证数据库地安全性和完整性； 数据库系统：包括了数据库、数据库管理系统、应用系统、数据库管理员 即软件+人。 数据库服务器：数据库服务器其实就是一个软件,比如我们安装的mysql软件(或者mariadb软件)mysql服务器软件需要安装在服务器硬件上(就是一台计算机)才可以让外界来访问在mysql服务器中,可以创建很多的数据库(database 数据库查询：select * from isupport_customer order by id desc（查询数据表中的相应数据） 数据库的分类：数据库根据句存储采用的数据结构的不同可以分为许多种,其中包含 早期的数据库类型：*层次式数据库*网络式数据库 目前占市场主流的是*关系型数据库*非关系型数据库*键值对数据库,例如:MongDB,Redis 关系型数据库：底层是以二维表的及其之间的关系所组成的数据库. 常见关系型数据库：SQL Server 微软提供(收费.java中使用不多)Oracle 甲骨文公司(收费,功能强大,性能优异,java中使用者很多)DB2 IBM(收费,中型/大型,银行/电信等企业) 瑞典MySQL AB(免费,小型,性能较优异,适用于中小型项目,可集群) SQLite 迷你数据库 SQL语言：Structured Query Language：结构化的查询语言; SQL是操作所有关系型数据库的通用的语言 SQL语言的分类: DDL - - 数据库定义语言,指Create,Allter,Drop等操作(即创建,删除,修改数据库和数据表) DML - - 数据库操作语言,指Insert.Update.Delete等操作(即数据表中数据的增删改操作) DQL - - 数据查询语言(指Selete操作,即数据表中数据的查询操作)其中DQL,也就是数据查询操作是在开发中使用最多的操作,也是我们关注的重点. SQL增删改查： 增：insert 表的名称 values 新增的内容例子：insert SQ_Academe(Academe,Specialty.Grade,Class)values(‘信息技术学院’，’计算机’,’2019’,’1班’) 改：update 表的名称 set 要改的内容 where 条件例子：update SQ_Academeset Academe = ‘药数学院’where AcademeID =1010 查：# select 查询的内容 from 表的名称例子：select * from SQ_Academeselect * from pm_customer order by id desc;select * from isupport_customer where id =621 order by id desc;select * from isupport_customer_property where isupport_customer_id=621 删：delete 表的名称 where 条件 —&gt;相应行变成 NULL例子：delete SQ_Academewhere AcademeID = 1010 hive 创建表/新增数据/删除表 123456789DROP TABLE IF EXISTS 库名.表名;CREATE TABLE 库名.表名( 字段1 bigint, 字段2 int, 字段3 string, 字段4 timestamp ...);insert into 库名.表名 删除表中某一部分数据 12INSERT OVERWRITE TABLE table_name SELECT * FROM table_name WHERE year&gt;2018;#WHERE后的条件是需要保留的数据的查询结果,即删除2018年及以前的数据 Quantile 123分析函数：用于等级、百分点、n分片等 Ntile 是Hive很强大的一个分析函数。ntile (num) over ([partition_clause] order_by_clause) as your_bucket_num然后可以根据桶号，选取前或后 n分之几的数据 ROW_NUMBERhive的分组和组内排序—语法 12345row_number() over (partition by 字段a order by 计算项b desc ) rankrank是排序的别名partition by：类似hive的建表，分区的意思；order by ：排序，默认是升序，加desc降序；这里按字段a分区，对计算项b进行降序排序 LAG 12LAG(col,n,DEFAULT) 用于统计窗口内往上第n行值第一个参数为列名，第二个参数为往上第n行（可选，默认为1），第三个参数为默认值（当往上第n行为NULL时候，取默认值，如不指定，则为NULL） 时间数据格式化操作hive 常用日期格式转换 固定日期转换成时间戳select unix_timestamp(‘2016-08-16’,’yyyy-MM-dd’) –1471276800select unix_timestamp(‘20160816’,’yyyyMMdd’) –1471276800select unix_timestamp(‘2016-08-16T10:02:41Z’, “yyyy-MM-dd’T’HH:mm:ss’Z’”) –1471312961 16/Mar/2017:12:25:01 +0800 转成正常格式（yyyy-MM-dd hh:mm:ss）select from_unixtime(to_unix_timestamp(‘16/Mar/2017:12:25:01 +0800’, ‘dd/MMM/yyy:HH:mm:ss Z’)) 时间戳转换程固定日期select from_unixtime(1471276800,’yyyy-MM-dd’) –2016-08-16select from_unixtime(1471276800,’yyyyMMdd’) –20160816select from_unixtime(1471312961) – 2016-08-16 10:02:41select from_unixtime( unix_timestamp(‘20160816’,’yyyyMMdd’),’yyyy-MM-dd’) –2016-08-16select date_format(‘2016-08-16’,’yyyyMMdd’) –20160816 取当前时间select from_unixtime(unix_timestamp(),’yyyy-MM-dd HH:mm:ss’)select from_unixtime(unix_timestamp(),’yyyy-MM-dd’) 返回日期时间字段中的日期部分 select to_date(‘2016-08-16 10:03:01’) –2016-08-16返回日期中的年 select year(‘2016-08-16 10:03:01’) –2016返回日期中的月 select month(‘2016-08-16 10:03:01’) –8返回日期中的日 select day(‘2016-08-16 10:03:01’) –16返回日期中的时 select hour(‘2016-08-16 10:03:01’) –10返回日期中的分 select minute(‘2016-08-16 10:03:01’) –3返回日期中的秒 select second(‘2016-08-16 10:03:01’) –1 返回日期在当前的周数 select weekofyear(‘2016-08-16 10:03:01’) –33返回结束日期减去开始日期的天数 select datediff(‘2016-08-16’,’2016-08-11’) 返回开始日期startdate增加days天后的日期 select date_add(‘2016-08-16’,10)返回开始日期startdate减少days天后的日期 select date_sub(‘2016-08-16’,10) 返回当天三种方式SELECT CURRENT_DATE; –2017-06-15SELECT CURRENT_TIMESTAMP;–返回时分秒 –2017-06-15 19:54:44SELECT from_unixtime(unix_timestamp()); –2017-06-15 19:55:04 返回当前时间戳 select current_timestamp–2018-06-18 10:37:53.278返回当月的第一天 select trunc(‘2016-08-16’,’MM’) –2016-08-01返回当年的第一天 select trunc(‘2016-08-16’,’YEAR’) –2016-01-01 从时间数据中提取年/月/天等 12345678910select to_date(’2011-12-08 10:03:01′) from dual; -----返回日期时间字段中的日期部分:2011-12-08select year(‘2011-12-08 10:03:01’) ----返回日期中的年:2011select month(‘2011-12-08 10:03:01’) from iteblog; ----返回日期中的月份:12select day(‘2011-12-08 10:03:01’) from iteblog; -----返回日期中的天:8select hour(‘2011-12-08 10:03:01’) from iteblog; -----返回日期中的小时:10select second(‘2011-12-08 10:03:01’) from iteblog; -----返回日期中的秒:1select weekofyear(‘2011-12-08 10:03:01’) from iteblog; ----返回日期在当前的周数:49select datediff(‘2012-12-08’,‘2012-05-09’) from iteblog; -----返回结束日期减去开始日期的天数:213select date_add(‘2012-12-08’,10) from iteblog; ----返回开始日期startdate增加days天后的日期:2012-12-18select date_sub(‘2012-12-08’,10) from iteblog; -----返回开始日期startdate减少days天后的日期:2012-11-28 sql sever 字符串操作字符串类型的数据切词提取有效信息：substring(字符串字段名,开始位置,结束位置) 123select substring(字符串字段名,charindex(&#x27;abc&#x27;,字符串字段名)+11,ABS(charindex(&#x27;bjsa&#x27;,字符串字段名)-charindex(&#x27;abc&#x27;,字符串字段名)-14))FROM 库名.表名 获取某个字符串在字段中的位置：charindex(字符串,字段名) 1charindex(&#x27;mainBody&#x27;,content)+11 排序规则不同导致join失败 123无法改变数据库的情况下：1.在 on 后的字段后加上 collate Chinese_PRC_CS_AI_WS 指定排序规则2.在建表时给字符串类型的字段后面加上 collate Chinese_PRC_CS_AI_WS","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"}]},{"title":"数据处理 Sql Basic","slug":"SQL-basic","date":"2019-09-18T07:20:12.000Z","updated":"2023-02-16T15:40:10.000Z","comments":true,"path":"2019/09/18/SQL-basic/","link":"","permalink":"http://example.com/2019/09/18/SQL-basic/","excerpt":"SQL（Structured Query Language）==是“结构化查询语言”，它是对关系型数据库的操作语言。它可以应用到所有关系型数据库中，例如：MySQL、Oracle、SQL虽然 SQL 可以用在所有关系型数据库中，但很多数据库还都有标准之后的一些语法，我们可以称之为“方言”。例如 MySQL 中的 LIMIT 语句就是 MySQL 独有的方言，其它数据库都不支持！当然，Oracle 或 SQL Server 都有自己的方言。模型训练需要使用大量的数据 使用python读取数据库再用 pandas 进行操作 占用时间/内存资源 并且处理大量数据时效率较低实际使用时直接在数据库里进行简单的字符串操作/数据简单的加减乘除等 最后把处理后的数据结果表拉近python用于模型训练等操作","text":"SQL（Structured Query Language）==是“结构化查询语言”，它是对关系型数据库的操作语言。它可以应用到所有关系型数据库中，例如：MySQL、Oracle、SQL虽然 SQL 可以用在所有关系型数据库中，但很多数据库还都有标准之后的一些语法，我们可以称之为“方言”。例如 MySQL 中的 LIMIT 语句就是 MySQL 独有的方言，其它数据库都不支持！当然，Oracle 或 SQL Server 都有自己的方言。模型训练需要使用大量的数据 使用python读取数据库再用 pandas 进行操作 占用时间/内存资源 并且处理大量数据时效率较低实际使用时直接在数据库里进行简单的字符串操作/数据简单的加减乘除等 最后把处理后的数据结果表拉近python用于模型训练等操作 sql正则 查找123456SELECT name FROM person_tbl WHERE name REGEXP &#x27;^st&#x27; 查找name字段中以&#x27;st&#x27;为开头的所有数据SELECT name FROM person_tbl WHERE name REGEXP &#x27;ok$&#x27; 查找name字段中以&#x27;ok&#x27;为结尾的所有数据SELECT name FROM person_tbl WHERE name REGEXP &#x27;mar&#x27; 查找name字段中包含&#x27;mar&#x27;字符串的所有数据SELECT name FROM person_tbl WHERE name REGEXP &#x27;^[aeiou]|ok$&#x27; 查找name字段中以元音字符开头或以&#x27;ok&#x27;字符串结尾的所有数据SELECT DISTINCT TABLE_NAME FROM information_schema.COLUMNS WHERE COLUMN_NAME = &#x27;description&#x27; AND TABLE_SCHEMA=&#x27;bugs&#x27; ; 从整个数据库查找某个字段 基本条件查找1234567891011121314151617181920212223242526272829303132333435363738394041/*一般性where语句*/SELECT population FROM world WHERE name = &#x27;France&#x27;；SELECT name, population FROM world WHERE name IN (&#x27;Brazil&#x27;, &#x27;Russia&#x27;, &#x27;India&#x27;, &#x27;China&#x27;);SELECT name, area FROM world WHERE area BETWEEN 250000 AND 300000/*字符串模式匹配*/SELECT name FROM world WHERE name LIKE &#x27;Y%&#x27; /*以y开头*/SELECT name FROM world WHERE name LIKE &#x27;C%ia&#x27; /*以C开头ia结尾*/SELECT name FROM world WHERE name LIKE &#x27;_n%&#x27; ORDER BY name /*第二个字符是n，下划线是字母通配符*/SELECT name FROM world WHERE name LIKE &#x27;%a%&#x27; AND name LIKE &#x27;%e%&#x27; AND name LIKE &#x27;%i%&#x27; AND name LIKE &#x27;%o%&#x27; AND name LIKE &#x27;%u%&#x27; AND name NOT LIKE &#x27;% %&#x27;/*ROUND(*, n), n为正则精确到小数点位数，n为负则精确到相应位数*/SELECT name, ROUND(population/1000000,2) FROM world WHERE continent=&#x27;South America&#x27;SELECT name, ROUND(gdp/population,-3) FROM world WHERE gdp&gt;1000000000000/* LENGTH()*/SELECT name, capital FROM world WHERE LENGTH(name)=LENGTH(capital)/* LEFT(*,n)前n个字符，&lt;&gt;,或!=不等于*/SELECT name,capital FROM world WHERE LEFT(name,1)=LEFT(capital,1) AND name&lt;&gt;capital/* SUBSTR(str, -2) str最后两个字符 */select first_name from employees order by substr(first_name, -2)/*LIMIT n从0开始取n个数据，LIMIT m,n从m开始取n个数据*/select * from employees order by hire_date desc limit 2,1 /*取第三个数据*//* ||连接符 */select last_name || &#x27; &#x27; || first_name from employees/* distinct去重，常用去重计算和去重得到值唯一表 */SELECT title, COUNT(DISTINCT emp_no) AS t FROM titlesGROUP BY title HAVING t &gt;= 2/* CAST()改变数据类型 */SELECT CAST(f.population AS FLOAT)SELECT CONCAT(&#x27;王&#x27;,&#x27;(&#x27;,&#x27;ni&#x27;,&#x27;)&#x27;)FROM hr.ods_employee_delta_1d AS eSELECT CONCAT(name,&#x27;(&#x27;,ename,&#x27;)&#x27;)FROM user_list join 语句1234567891011121314151617181920212223242526select s.*, d.dept_no from salaries as sinner join dept_manager as d on d.emp_no=s.emp_nowhere d.to_date=&#x27;9999-01-01&#x27; and s.to_date=&#x27;9999-01-01&#x27;/* ，号也可以查询两张表，效果同inner join连接两张表*/SELECT e.emp_no, s.salary FROM employees AS e, salaries AS sWHERE e.emp_no = s.emp_no AND e.hire_date = s.from_dateORDER BY e.emp_no DESC/* GROUP BY聚合后MAX(), MIN(), AVG()，SUM(), COUNT() 等操作*/select de.dept_no, de.emp_no, max(s.salary)from dept_emp as deinner join salaries as son s.emp_no = de.emp_nowhere de.to_date = &#x27;9999-01-01&#x27;group by de.dept_no/*多层连接*/select e.emp_no, (s1.salary-s2.salary) growthfrom employees as einner join salaries as s1on e.emp_no = s1.emp_no and s1.to_date = &#x27;9999-01-01&#x27;inner join salaries as s2on e.emp_no = s2.emp_no and e.hire_date = s2.from_dateorder by growth asc","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"}]},{"title":"高等数学 Mathematics","slug":"Mathematics","date":"2019-09-18T07:09:12.000Z","updated":"2022-09-30T08:25:04.000Z","comments":true,"path":"2019/09/18/Mathematics/","link":"","permalink":"http://example.com/2019/09/18/Mathematics/","excerpt":"数学是一切高级运算的基础","text":"数学是一切高级运算的基础 1.3 数学基础1.3.1 函数 常见函数：常函数 一次函数 二次函数 指数函数 对数函数 幂函数 导数、梯度（求导的方式、导数/二阶导数/偏导数/梯度的含义/作用） Taylor公式 1.3.2 概率 古典概率、联合概率、条件概率、全概率公式、贝叶斯公式 期望、方差、协方差（ Cov(X,Y) &gt;=&lt;0） 大数定理、中心极限定理 最大似然估计(MLE) 1.3.3 向量 向量、矩阵的运算 向量、矩阵的求导 SVD、QR分解","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://example.com/tags/Mathematics/"}]},{"title":"数据处理 Athena","slug":"SQL-Athena","date":"2019-09-18T07:09:12.000Z","updated":"2023-02-16T15:40:10.000Z","comments":true,"path":"2019/09/18/SQL-Athena/","link":"","permalink":"http://example.com/2019/09/18/SQL-Athena/","excerpt":"AWS数据查询工具-AthenaAmazon Athena 是一种交互式查询服务，让您能够轻松使用标准 SQL 直接分析 Amazon Simple Storage Service (Amazon S3) 中的数据。只需在 AWS Management Console 中执行几项操作，即可将 Athena 指向 Amazon S3 中存储的数据，并开始使用标准 SQL 运行临时查询，然后在几秒钟内获得结果。Amazon Athena 还可使用 Apache Spark 以交互方式轻松运行数据分析，无需规划、配置或管理资源。在 Athena 上运行 Apache Spark 应用程序时，您需要提交 Spark 代码以进行处理并直接接收结果。使用 Amazon Athena 控制台中简化的笔记本体验，以通过 Python 或 Athena 笔记本 API 开发 Apache Spark 应用程序。Athena SQL 和 Amazon Athena 上的 Apache Spark 无服务器，因此您无需设置或管理任何基础设施，只需为运行的查询付费。Athena 可自动扩展（并行执行查询），因此，即使在数据集很大、查询很复杂的情况下也能很快获得结果。官方文档地址: https://docs.aws.amazon.com/zh_cn/athena/latest/ug/using-athena-sql.html","text":"AWS数据查询工具-AthenaAmazon Athena 是一种交互式查询服务，让您能够轻松使用标准 SQL 直接分析 Amazon Simple Storage Service (Amazon S3) 中的数据。只需在 AWS Management Console 中执行几项操作，即可将 Athena 指向 Amazon S3 中存储的数据，并开始使用标准 SQL 运行临时查询，然后在几秒钟内获得结果。Amazon Athena 还可使用 Apache Spark 以交互方式轻松运行数据分析，无需规划、配置或管理资源。在 Athena 上运行 Apache Spark 应用程序时，您需要提交 Spark 代码以进行处理并直接接收结果。使用 Amazon Athena 控制台中简化的笔记本体验，以通过 Python 或 Athena 笔记本 API 开发 Apache Spark 应用程序。Athena SQL 和 Amazon Athena 上的 Apache Spark 无服务器，因此您无需设置或管理任何基础设施，只需为运行的查询付费。Athena 可自动扩展（并行执行查询），因此，即使在数据集很大、查询很复杂的情况下也能很快获得结果。官方文档地址: https://docs.aws.amazon.com/zh_cn/athena/latest/ug/using-athena-sql.html 备份分区表12345CREATE table xxx.testWITH (external_location =&#x27;s3://xxx/xxx/test&#x27;,partitioned_by = ARRAY[&#x27;dt&#x27;])asSELECT * FROM xxx 查询字符串字段 endwith ‘ ‘12select distinct product_type from prodwhere substring(product_type,-1,1)=&#x27; &#x27; 替换字符串前后空格1trim(article_promo_main_catg, &#x27; &#x27;) 拼接时间字符串 yyyymmdd -&gt; yyyy-mm-dd1concat(SUBSTRING(DATE,1,4),&#x27;-&#x27;,SUBSTRING(DATE,5,2),&#x27;-&#x27;,SUBSTRING(DATE,7,2)) as biz_date python操作Athena数据库 将df上传到数据表1234567891011121314151617181920212223242526272829import datetimeimport awswrangler as wrdef datetime_beijing(datetime_): beijing_time = datetime_ + datetime.timedelta(hours=8) return beijing_timedef gen_part_parquet(df: str,path: str,part: list,table: str,dtype: dict): if len(df)&gt;0: print(datetime_beijing(datetime.datetime.now()), &#x27;###### generate &#123;type&#125; parquet start...&#x27;.format(type=table)) wr.s3.to_parquet( df = df, path= path, dataset=True, mode=&quot;overwrite_partitions&quot;, partition_cols=part, sanitize_columns=True, database=&quot;xxx&quot;, table=table, dtype=dtype ) print(datetime_beijing(datetime.datetime.now()), &#x27;###### generate &#123;type&#125; parquet end...&#x27;.format(type=table)) else: print(df,&quot; is empty....&quot;)def gen_s3_parquet(df: str,path: str,table: str, dtype=None): if len(df)&gt;0: print(datetime_beijing(datetime.datetime.now()), &#x27;###### generate &#123;type&#125; start...&#x27;.format(type=table)) wr.s3.to_parquet( df = df, path= path, dataset=True, mode=&quot;overwrite&quot;, sanitize_columns=True, database=&quot;xxx&quot;, table=table, dtype=dtype ) print(datetime_beijing(datetime.datetime.now()), &#x27;###### generate &#123;type&#125; end...&#x27;.format(type=table)) else: print(df,&quot; is empty....&quot;)","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"},{"name":"Athena","slug":"Athena","permalink":"http://example.com/tags/Athena/"}]},{"title":"数据处理 EXASOL","slug":"SQL-EXASOL","date":"2019-09-18T07:09:12.000Z","updated":"2023-02-16T15:40:10.000Z","comments":true,"path":"2019/09/18/SQL-EXASOL/","link":"","permalink":"http://example.com/2019/09/18/SQL-EXASOL/","excerpt":"数据库语言-EXASQL“The fastest in-memory database how you want it. Deployed on premise, in the cloud, or in hybrid environments.”官方文档: https://docs.exasol.com/db/latest/sql_reference.htm","text":"数据库语言-EXASQL“The fastest in-memory database how you want it. Deployed on premise, in the cloud, or in hybrid environments.”官方文档: https://docs.exasol.com/db/latest/sql_reference.htm – Exasql判断某个字段为空的话置为0 1ifnull(col_name, 0)","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"},{"name":"EXASOL","slug":"EXASOL","permalink":"http://example.com/tags/EXASOL/"}]},{"title":"数据处理 MySql","slug":"SQL-MySql","date":"2019-09-18T07:09:12.000Z","updated":"2023-02-16T15:40:08.000Z","comments":true,"path":"2019/09/18/SQL-MySql/","link":"","permalink":"http://example.com/2019/09/18/SQL-MySql/","excerpt":"MySQL是一个开放源码的小型关联式数据库管理系统，开发者为瑞典MySQL AB公司。目前MySQL被广泛地应用在Internet上的中小型网站中。由于其体积小、速度快、总体拥有成本低，尤其是开放源码这一特点，许多中小型网站为了降低网站总体拥有成本而选择了MySQL作为网站数据库。MySQL这个名字是怎么来的已经不清楚了。基本指南和大量的库和工具带有前缀“my”已经有10年以上，而且不管怎样，MySQL AB创始人之一的的女儿也叫My。这两个到底是哪一个给出了MySQL这个名字至今依然是个迷，包括开发者在内也不知道。MySQL的海豚标志的名字叫“sakila”，它是由MySQL AB的创始人从用户在“海豚命名”的竞赛中建议的大量的名字表中选出的。获胜的名字是由来自非洲斯威士兰的开源软件开发者Ambrose Twebaze提供。根据Ambrose所说，Sakila来自一种叫SiSwati的斯威士兰方言，也是在Ambrose的家乡乌干达附近的坦桑尼亚的Arusha的一个小镇的名字。2008年1月16日MySQL AB被Sun公司收购。而2009年，SUN又被Oracle收购。就这样如同一个轮回，MySQL成为了Oracle公司的另一个数据库项目。MySQL是数据库的一种，具有数据库的通用特征，同时，比起其他类型的数据库，它还具有自己鲜明的特点。","text":"MySQL是一个开放源码的小型关联式数据库管理系统，开发者为瑞典MySQL AB公司。目前MySQL被广泛地应用在Internet上的中小型网站中。由于其体积小、速度快、总体拥有成本低，尤其是开放源码这一特点，许多中小型网站为了降低网站总体拥有成本而选择了MySQL作为网站数据库。MySQL这个名字是怎么来的已经不清楚了。基本指南和大量的库和工具带有前缀“my”已经有10年以上，而且不管怎样，MySQL AB创始人之一的的女儿也叫My。这两个到底是哪一个给出了MySQL这个名字至今依然是个迷，包括开发者在内也不知道。MySQL的海豚标志的名字叫“sakila”，它是由MySQL AB的创始人从用户在“海豚命名”的竞赛中建议的大量的名字表中选出的。获胜的名字是由来自非洲斯威士兰的开源软件开发者Ambrose Twebaze提供。根据Ambrose所说，Sakila来自一种叫SiSwati的斯威士兰方言，也是在Ambrose的家乡乌干达附近的坦桑尼亚的Arusha的一个小镇的名字。2008年1月16日MySQL AB被Sun公司收购。而2009年，SUN又被Oracle收购。就这样如同一个轮回，MySQL成为了Oracle公司的另一个数据库项目。MySQL是数据库的一种，具有数据库的通用特征，同时，比起其他类型的数据库，它还具有自己鲜明的特点。 MySql实现 row_number()123456789select distinct source,source_typefrom( select (@i :=case when @source= source then @i + 1 else 1 end ) as rn ,t1.*, (@source:= source) FROM ( select distinct source_type, source from daily_traffic_source )t1, (select @i := 0 )t2 GROUP BY source order by source_type)t where rn=1 and source_type is not null and source_type&lt;&gt;&#x27;&#x27; and source_type&lt;&gt;&#x27;null&#x27;","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"},{"name":"MySql","slug":"MySql","permalink":"http://example.com/tags/MySql/"}]},{"title":"数据处理 PostgreSQL","slug":"SQL-PostgreSQL","date":"2019-09-18T07:09:12.000Z","updated":"2023-02-16T15:40:06.000Z","comments":true,"path":"2019/09/18/SQL-PostgreSQL/","link":"","permalink":"http://example.com/2019/09/18/SQL-PostgreSQL/","excerpt":"PostgreSQL是一个功能强大的开源对象关系型数据库系统，他使用和扩展了SQL语言，并结合了许多安全存储和扩展最复杂数据工作负载的功能。PostgreSQL的起源可以追溯到1986年，作为加州大学伯克利分校POSTGRES项目的一部分，并且在核心平台上进行了30多年的积极开发。PostgresSQL凭借其经过验证的架构，可靠性，数据完整性，强大的功能集，可扩展性以及软件背后的开源社区的奉献精神赢得了良好的声誉，以始终如一地提供高性能和创新的解决方案。PostgreSQL在所有主要操作系统开始使用PostgreSQL从未如此简单。","text":"PostgreSQL是一个功能强大的开源对象关系型数据库系统，他使用和扩展了SQL语言，并结合了许多安全存储和扩展最复杂数据工作负载的功能。PostgreSQL的起源可以追溯到1986年，作为加州大学伯克利分校POSTGRES项目的一部分，并且在核心平台上进行了30多年的积极开发。PostgresSQL凭借其经过验证的架构，可靠性，数据完整性，强大的功能集，可扩展性以及软件背后的开源社区的奉献精神赢得了良好的声誉，以始终如一地提供高性能和创新的解决方案。PostgreSQL在所有主要操作系统开始使用PostgreSQL从未如此简单。 解析json格式1JSON_EXTRACT_PATH_TEXT(properties, &#x27;product_list&#x27;) as article_list 判断字符串中包含某字符1position(&#x27;product_list&#x27; in properties) 转换为日期格式1to_date(biz_date,&#x27;yyyyMMDD&#x27;)","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://example.com/tags/PostgreSQL/"}]},{"title":"数据处理 Redis","slug":"SQL-Redis","date":"2019-09-18T07:09:12.000Z","updated":"2023-02-16T15:40:06.000Z","comments":true,"path":"2019/09/18/SQL-Redis/","link":"","permalink":"http://example.com/2019/09/18/SQL-Redis/","excerpt":"一种NoSQL数据库：开源、包含多种数据结构、支持网络、基于内存、可选持久性的键值对存储数据库应用场景 缓存系统（热点数据 高频读 低频写），相对其他数据库语言的特点：C/S通讯模型，单进程单线程模型，丰富的数据类型，操作具有原子性，持久化，高并发读写，支持lua脚本","text":"一种NoSQL数据库：开源、包含多种数据结构、支持网络、基于内存、可选持久性的键值对存储数据库应用场景 缓存系统（热点数据 高频读 低频写），相对其他数据库语言的特点：C/S通讯模型，单进程单线程模型，丰富的数据类型，操作具有原子性，持久化，高并发读写，支持lua脚本 RedisString–整数 字符串列表 – 双端链表 压缩列表哈希 – 压缩列表 字典集合 – 字典 整数集合顺序集合 – 压缩列表 跳跃表","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"数据处理 Hive Sql","slug":"SQL-Hive","date":"2019-09-18T07:09:12.000Z","updated":"2023-02-16T15:40:12.000Z","comments":true,"path":"2019/09/18/SQL-Hive/","link":"","permalink":"http://example.com/2019/09/18/SQL-Hive/","excerpt":"Hive SqlHive是一个在Hadoop中用来处理结构化数据的数据仓库基础工具。它架构在Hadoop之上，用来进行数据提取、转化、加载，这是一种可以存储、查询和分析存储在Hadoop中的大规模数据的机制。hive数据仓库工具能将结构化的数据文件映射为一张数据库表，并提供SQL查询功能，能将SQL语句转变成MapReduce任务来执行。术语“大数据”是大型数据集，其中包括体积庞大，高速，以及各种由与日俱增的数据的集合。使用传统的数据管理系统难以加工大型数据。因此，Apache软件基金会推出了一款名为Hadoop的解决大数据管理和处理难题的框架。 官方文档: https://www.docs4dev.com/docs/zh/apache-hive/3.1.1/reference/LanguageManual_DML.html","text":"Hive SqlHive是一个在Hadoop中用来处理结构化数据的数据仓库基础工具。它架构在Hadoop之上，用来进行数据提取、转化、加载，这是一种可以存储、查询和分析存储在Hadoop中的大规模数据的机制。hive数据仓库工具能将结构化的数据文件映射为一张数据库表，并提供SQL查询功能，能将SQL语句转变成MapReduce任务来执行。术语“大数据”是大型数据集，其中包括体积庞大，高速，以及各种由与日俱增的数据的集合。使用传统的数据管理系统难以加工大型数据。因此，Apache软件基金会推出了一款名为Hadoop的解决大数据管理和处理难题的框架。 官方文档: https://www.docs4dev.com/docs/zh/apache-hive/3.1.1/reference/LanguageManual_DML.html 建表语句样例12345678DROP TABLE IF EXISTS dev.trans_temp;CREATE TABLE dev.trans_temp( account_id bigint, trans_id int, product_id string, sales float);insert into dev.trans_temp 时间格式化12year(place_time) as order_yearmonth(place_time) as order_month 计算两时间之间的时间差1datediff(current_date,last_purchase_date) 求recency1datediff(current_date,max(to_date(place_time))) as recency 时间筛选1234-- 最近5天where to_date(sap_time) between date_sub(current_date,5) and date_sub(current_date,1)-- 最近30天where to_date(dt) &gt;= date_sub(current_date,30) 判断某订单是否在大促期间购买123456789-- 即订单发生时间在大促开始之后 大促结束之前case when ((unix_timestamp(place_time)-unix_timestamp(promotion_start_time))/3600) &lt;= promotion_hoursand ((unix_timestamp(place_time)-unix_timestamp(promotion_start_time))/3600) &gt;=0 then &#x27;大促时购买&#x27; else null end as promotion_behavior,case when array_contains(collect_set(promotion_behavior) over (partition by sales_member_id,sales_order_number),&#x27;大促时购买&#x27;) then &#x27;private&#x27; else &#x27;normal&#x27; end as promotion_behavior,case when array_contains(collect_set(promotion_behavior),&#x27;private&#x27;) and !array_contains(collect_set(promotion_behavior),&#x27;normal&#x27;) then &#x27;只在大促购买&#x27; when array_contains(collect_set(promotion_behavior),&#x27;normal&#x27;) and !array_contains(collect_set(promotion_behavior),&#x27;private&#x27;) then &#x27;只在非大促购买&#x27; else &#x27;大促及非大促都购买&#x27; end as private_sale_sensitivity 节日1234where to_date(place_time) between date_sub(concat(year(current_date),&#x27;-&#x27;,&#x27;01-01&#x27;),7) and date_add(concat(year(current_date),&#x27;-&#x27;,&#x27;01-01&#x27;),7)--New Year or to_date(place_time) between date_sub(concat(year(current_date),&#x27;-&#x27;,&#x27;02-14&#x27;),7) and date_add(concat(year(current_date),&#x27;-&#x27;,&#x27;02-14&#x27;),7)--Valentine or to_date(place_time) between date_sub(concat(year(current_date),&#x27;-&#x27;,&#x27;&#123;Qixi&#125;&#x27;),7) and date_add(concat(year(current_date),&#x27;-&#x27;,&#x27;&#123;Qixi&#125;&#x27;),7)--Qixi or to_date(place_time) between date_sub(concat(year(current_date)-1,&#x27;-&#x27;,&#x27;12-25&#x27;),7) and date_add(concat(year(current_date)-1,&#x27;-&#x27;,&#x27;12-25&#x27;),7)--Christmas case when 判断时间12345case hour(sap_time) when 0 then &#x27;[0-1)&#x27; when 1 then &#x27;[1-2)&#x27; when 2 then &#x27;[2-3)&#x27; when 3 then &#x27;[3-4)&#x27; when 4 then &#x27;[4-5)&#x27; when 5 then &#x27;[5-6)&#x27; when 6 then &#x27;[6-7)&#x27; when 7 then &#x27;[7-8)&#x27; when 8 then &#x27;[8-9)&#x27; when 9 then &#x27;[9-10)&#x27; when 10 then &#x27;[10-11)&#x27; when 11 then &#x27;[11-12)&#x27; when 12 then &#x27;[12-13)&#x27; when 13 then &#x27;[13-14)&#x27; when 14 then &#x27;[14-15)&#x27; when 15 then &#x27;[15-16)&#x27; when 16 then &#x27;[16-17)&#x27; when 17 then &#x27;[17-18)&#x27; when 18 then &#x27;[18-19)&#x27; when 19 then &#x27;[19-20)&#x27; when 20 then &#x27;[20-21)&#x27; when 21 then &#x27;[21-22)&#x27; when 22 then &#x27;[22-23)&#x27; when 23 then &#x27;[23-0)&#x27; end as hour_name hive 判断星期几1234567case when pmod(datediff(place_time, &#x27;1920-01-01&#x27;) - 3, 7) = 1 then &#x27;Monday&#x27; when pmod(datediff(place_time, &#x27;1920-01-01&#x27;) - 3, 7) = 2 then &#x27;Tuesday&#x27; when pmod(datediff(place_time, &#x27;1920-01-01&#x27;) - 3, 7) = 3 then &#x27;Wednesday&#x27; when pmod(datediff(place_time, &#x27;1920-01-01&#x27;) - 3, 7) = 4 then &#x27;Thursday&#x27; when pmod(datediff(place_time, &#x27;1920-01-01&#x27;) - 3, 7) = 5 then &#x27;Friday&#x27; when pmod(datediff(place_time, &#x27;1920-01-01&#x27;) - 3, 7) = 6 then &#x27;Saturday&#x27; else &#x27;Sunday&#x27; end as wd_name 排序1234,row_number() over(partition by account_id order by sap_time desc) as rn,row_number() over(partition by account_id order by sales desc) as rn,case when casales=max(casales) over(partition by sales_member_id) then category else null end preferred_category --偏好,sort_array(array(seasonal_share,festival_share,promotion_share,gifting_share,exclusive_share)) as sort_arr 返回第一个非空值1,COALESCE(preferred_Subcategory,LAST_VALUE(preferred_Subcategory,true) over(partition by sales_member_id order by preferred_subcategory desc )) preferred_Subcategory 数学运算12345sum()avg()std()max()min() 分位数1percentile_approx(price_sensitivity,0.3) 百分比1234567891011select sku_cd,category,sap_price,case when rn&gt;=0 and rn&lt;0.3 then N&#x27;低价&#x27;when rn&gt;=0.3 and rn&lt;0.7 then N&#x27;中价&#x27;when rn&gt;=0.7 and rn&lt;=1 then N&#x27;高价&#x27; else null end as price_tier_typeinto #sku_price_tierfrom( select sku_cd,category,sap_price ,round(PERCENT_RANK() OVER( partition by category ORDER BY sap_price), 5) as rn from #sku_price where category is not null)t1 取下一行1,lead(channel,1,null) over(partition by account_id order by sap_time) as next_channel 取上一行1,lag(channel,1,null) over(partition by account_id order by sap_time) as next_channel like1case when XX like &#x27;%礼盒%&#x27; then 1 else 0 end as if_gift 转数字类型+ 文本格式化1cast(regexp_replace(member_card,&#x27;JD&#x27;,&#x27;&#x27;) as bigint) as member_card hive 首字母大写123,case when member_card_grade in (&#x27;PINK&#x27;,&#x27;WHITE&#x27;,&#x27;BLACK&#x27;,&#x27;GOLD&#x27;)then concat(substr(member_card_grade, 1, 1), lower(substr(member_card_grade, 2)))else null end as member_card_grade 文本筛选 判断是数字并且不为空12where (user_id rlike &#x27;^\\\\d+$&#x27; or user_id is null or user_id in (&#x27;null&#x27;,&#x27;NULL&#x27;,&#x27; &#x27;,&#x27;&#x27;))and (card_no rlike &#x27;^\\\\d+$&#x27; or card_no is null or card_no in (&#x27;null&#x27;,&#x27;NULL&#x27;,&#x27; &#x27;,&#x27;&#x27;)) 字符串拼接12345,case when chcnt = 1 then concat(store,&#x27;新客&#x27;) when chcnt &gt; 1 then concat(store,&#x27;老客&#x27;) else concat(store,&#x27;未购买过&#x27;) end as channel_status,CONCAT(t3.brand_name collate Chinese_PRC_CS_AI_WS,&#x27; &#x27; collate Chinese_PRC_CS_AI_WS ,t1.item_product_id collate Chinese_PRC_CS_AI_WS,&#x27; &#x27; collate Chinese_PRC_CS_AI_WS ,t3.product_name_cn collate Chinese_PRC_CS_AI_WS) as prod hive 行转列1234567891011121314select sales_member_id ,max(case when item_brand_name = &#x27;Lancome&#x27; then sales else 0 end) as lancome_sales ,max(case when item_brand_name = &#x27;Lauder&#x27; then sales else 0 end) as lauder_sales ,max(case when item_brand_name = &#x27;Guerlain&#x27; then sales else 0 end) as guerlain_sales ,max(case when item_brand_name = &#x27;Skii&#x27; then sales else 0 end) as skll_sales ,max(case when item_brand_name = &#x27;Shiseido&#x27; then sales else 0 end) as shiseido_sales from ( select sales_member_id,item_brand_name ,sum(item_apportion_amount) as sales from da_dev.tagging_system_sales_order_vb_temp group by sales_member_id,item_brand_name ) t1 group by sales_member_id 分组 列拼接12345678910select sales_member_id,concat_ws(&#x27;,&#x27;,collect_set(item_category)) as dragon_registered_categoryfrom( select sales_member_id,item_category from ( select sales_member_id,sales_order_number,item_category ,row_number() over(partition by sales_member_id,sales_order_number order by place_time) as rn from DA.tagging_system_sales_order_basic_temp where store=&#x27;丝芙兰官网&#x27; ) t1 where rn=1) tt1 group by sales_member_id Hivehive 不能用 update 123456-- insert overwrite (aaa, bbb, ccc, ddd)select aaa,null as bbb,null as ccc,null as dddfrom Table 服务器 hive sql 常用语句开启服务器jupyternohup jupyter notebook –ip=xx.xx.xxx.xxx –port=8888 &amp;(现已开不用运行) 打开hive环境：hive 数据库里有哪些Schema：show databases; 使用xxSchema：use u_analysis_app 显示这个Schema里有哪些表：show tables; 显示xx信息：desc tagging_daily; 按符号拆分字符串split_part(product_articleid,’&amp;’,1)","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"},{"name":"Hive","slug":"Hive","permalink":"http://example.com/tags/Hive/"}]},{"title":"数据处理 Sql Server","slug":"SQL-SqlServer","date":"2019-09-18T07:09:12.000Z","updated":"2023-02-16T15:40:02.000Z","comments":true,"path":"2019/09/18/SQL-SqlServer/","link":"","permalink":"http://example.com/2019/09/18/SQL-SqlServer/","excerpt":"SQL Server数据库是Microsoft开发设计的一个关系数据库智能管理系统(RDBMS)，现在是全世界主流数据库之一；SQL Server数据库具备方便使用、可伸缩性好、相关软件集成程度高等优势，能够从单一的笔记本上运行或以高倍云服务器集群为基础，或在这两者之间任何东西上运行。尽管说成“任何东西”，可是依然要考虑有关的软件和硬件配置；SQL Server应用集成化的商务智能(BI)专用工具提供了企业级的数据管理服务。Microsoft SQL Server数据库引擎为关系型数据和结构化数据提供了更可靠安全的存储功能，使用户能够搭建和管理用于业务流程的高可用性和性能卓越的程序。SQL Server1.0在1989年公布，迄今SQL Server已变成一个企业级的信息化平台。SQL Server2014包含内嵌的商业智能专用工具，以及一系列的分析和报告工具，能够建立数据库、备份数据、拷贝，为数据安全提供了更强的保障。","text":"SQL Server数据库是Microsoft开发设计的一个关系数据库智能管理系统(RDBMS)，现在是全世界主流数据库之一；SQL Server数据库具备方便使用、可伸缩性好、相关软件集成程度高等优势，能够从单一的笔记本上运行或以高倍云服务器集群为基础，或在这两者之间任何东西上运行。尽管说成“任何东西”，可是依然要考虑有关的软件和硬件配置；SQL Server应用集成化的商务智能(BI)专用工具提供了企业级的数据管理服务。Microsoft SQL Server数据库引擎为关系型数据和结构化数据提供了更可靠安全的存储功能，使用户能够搭建和管理用于业务流程的高可用性和性能卓越的程序。SQL Server1.0在1989年公布，迄今SQL Server已变成一个企业级的信息化平台。SQL Server2014包含内嵌的商业智能专用工具，以及一系列的分析和报告工具，能够建立数据库、备份数据、拷贝，为数据安全提供了更强的保障。 分位数PERCENTILE_CONT和PERCENTILE_DISC都是为了计算百分位的数值，比如计算在某个百分位时某个栏位的数值是多少。他们的区别就是前者是连续型，后者是离散型。CONT代表continuous，DISC代表discrete。PERCENTILE_CONT是连续型意味它考虑的是区间，所以值是绝对的中间值。而PERCENTILE_DISC是离散型，所以它更多考虑向上或者向下取舍，而不会考虑区间 123456789101112131415161718192021222324252627282930313233343536SELECT purchase_monetary ,PERCENTILE_CONT(0.3) WITHIN GROUP (ORDER BY purchase_monetary) OVER () AS num_30q ,PERCENTILE_CONT(0.7) WITHIN GROUP (ORDER BY purchase_monetary) OVER () AS num_70q from( SELECT purchase_monetary from online_purchase where master_id in (10133982217,10123311972))tt-- 3分位数select purchase_monetary, purchase_monetary_perfrom( select purchase_monetary, purchase_monetary_per ,row_number() over(partition by purchase_monetary_per order by purchase_monetary) rn from ( select purchase_monetary ,convert( decimal(18, 2) ,PERCENT_RANK() over (order by purchase_monetary)) as purchase_monetary_per from online_purchase where master_id in (10133982217,10123311972) )tt where purchase_monetary_per&gt;=0.3 and purchase_monetary_per &lt;0.4)ttt where rn=1--7分位数select purchase_monetary, purchase_monetary_perfrom( select purchase_monetary, purchase_monetary_per ,row_number() over(partition by purchase_monetary_per order by purchase_monetary) rn from ( select purchase_monetary ,convert( decimal(18, 1) ,PERCENT_RANK() over (order by purchase_monetary)) as purchase_monetary_per from online_purchase where master_id in (10133982217,10123311972) )tt where purchase_monetary_per&gt;=0.6 and purchase_monetary_per &lt;=0.7)ttt where rn=1 清空表1truncate table kpi_tracking_bylist bigint转时间：1SELECT convert(date,DATEADD(S,1613628270481/1000 + 8 * 3600,&#x27;1970-01-01 00:00:00&#x27;)) 查某张表的所有列名1select name from syscolumns where id = object_id(&#x27;table_name&#x27;); Sql server print1print( CONVERT(varchar(100), DATEADD(hour,8,getdate()), 21) + &#x27; oms_v_sales_order_newdata Start...&#x27;) 表操作12345678-- 删列：alter table 表名 DROP COLUMN 列名-- 加列：alter table 表名 ADD 列名 列类型-- 修改列名EXEC sp_rename &#x27;表名.[字段旧名]&#x27;, &#x27;字段新名&#x27; , &#x27;COLUMN&#x27;;-- 修改列类型alter table 表名 alter column 字段名 decimal(18, 2) null; 加列：1alter table DA.tagging_system_memdia ADD media_id BIGINT identity(1,1) 改列名:1EXEC sp_rename &#x27;DA_TopRanking.kpi_tracking_bylist.plp2pdp_uv1&#x27;, &#x27;plp2pdp_pv1&#x27;, &#x27;COLUMN&#x27; 查表名对应字段和字段类型12345678select t1.name , CONCAT(t2.name ,&#x27;(&#x27; ,t1.prec,&#x27;)&#x27;) as datetypefrom( select * from syscolumns where id = object_id(&#x27;DA_Tagging.media&#x27;))t1 left join systypes t2 on t1.xtype = t2.xtype where t2.[status]=0 sql server删除表里的重复数据123456789101112131415-- 方法一（某些数据库不支持）delete t1from ( select *, row_number() over (partition by dt,platform_type order by dt,platform_type ) rn from DA_TopRanking.kpi_tracking_totalV2) as t1 where rn&gt;1-- 方法2select distinct *into #temp2from table_nametruncate table table_nameinsert into table_nameselect * from #temp2 sql server 单词首字母大写1STUFF( name,1,1,UPPER(SUBSTRING(name,1,1))) 格式化输出时间1print (CONVERT(varchar(100), GETDATE(), 21)) 按指定分隔符拆解字符变成列1234SELECT [post_id],value FROM INFORMATION_SCHEMA.TABLESOUTER APPLY String_Split([topics], &#x27;,&#x27;)where post_id=&#x27;9ed8c860-a79e-11ea-ac76-036f1ddfe6d3&#x27; 幂函数 用于按时间降权投票分数12case when monthdiff &lt;= 6 then post_score else power(0.95, (monthdiff-6)) * post_score end 系统操作查询数据库中对应的schema名及对应的表名 以及表类型12SELECT * FROM INFORMATION_SCHEMA.TABLESorder by table_catalog, table_schema, table_name 调用存储过程1234declare @cou_num NVARCHAR(max)declare @masteridlist NVARCHAR(max)= (select &#x27;10133982217,10123311972,10135981103&#x27;)print(@masteridlist)exec [DA_Tagging].[SP_Look_Alike] @masteridlist,10000 向存储过程传入列表参数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859CREATE FUNCTION FNC_SPLIT(@MYSTR VARCHAR(500), @DELIMITER CHAR(1))RETURNS @MYTBL TABLE (idx smallint, value varchar(8000))ASBEGIN DECLARE @RET VARCHAR(500) DECLARE @INDEX INT DECLARE @COUNTER smallint --Get the first position of delimiter in the main string SET @INDEX = CHARINDEX(@DELIMITER,@MYSTR) SET @COUNTER = 0 --Loop if delimiter exists in the main string WHILE @INDEX &gt; 0 BEGIN --extract the result substring before the delimiter found SET @RET = SUBSTRING(@MYSTR,1, @INDEX-1 ) --set mainstring right part after the delimiter found SET @MYSTR = SUBSTRING(@MYSTR,@INDEX+1 , LEN(@MYSTR) - @INDEX ) --increase the counter SET @COUNTER = @COUNTER + 1 --add the result substring to the table INSERT INTO @MYTBL (idx, value) VALUES (@COUNTER, @RET) --Get the next position of delimiter in the main string SET @INDEX = CHARINDEX(@DELIMITER,@MYSTR) END --if no delimiter is found then simply add the mainstring to the table IF @INDEX = 0 BEGIN SET @COUNTER = @COUNTER + 1 INSERT INTO @MYTBL (idx, value) VALUES (@COUNTER, @MYSTR) END RETURN ENDGOSELECT value FROM FNC_SPLIT(&#x27;10133982217,10123311972,10116946693&#x27;,&#x27;,&#x27;)GODROP FUNCTION FNC_SPLIT----传入master_id select master_id,preferred_brand --,count(distinct master_id) as id_cnt from INFORMATION_SCHEMA.TABLES where master_id in (select v.value as user_id from String_Split(&#x27;10133982217,10123311972,10116946693&#x27;,&#x27;,&#x27;)v )if not object_id(N&#x27;Tempdb..#T&#x27;) is nulldrop table #Tcreate table #T(user_id bigint)insert #Tselect user_idfrom( select value as user_id from String_Split(@masteridlist , &#x27;,&#x27;))t 列类别拼接 首单购买大类1234567891011121314151617181920select sales_member_id, STUFF(coalesce(&#x27;,&#x27;+Fragrance,&#x27;&#x27;)+coalesce(&#x27;,&#x27;+Makeup,&#x27;&#x27;)+ coalesce(&#x27;,&#x27;+Skincare,&#x27;&#x27;)+coalesce(&#x27;,&#x27;+Wellness,&#x27;&#x27;),1,1,&#x27;&#x27;) as dragon_registered_category from ( select sales_member_id, max (case item_category when &#x27;Fragrance&#x27; then &#x27;Fragrance&#x27; else null end ) Fragrance, max (case item_category when &#x27;Makeup&#x27; then &#x27;Makeup&#x27; else null end ) Makeup, max (case item_category when &#x27;Skincare&#x27; then &#x27;Skincare&#x27; else null end ) Skincare, max (case item_category when &#x27;Wellness&#x27; then &#x27;Wellness&#x27; else null end ) Wellness from( select sales_member_id,item_category from ( select sales_member_id,sales_order_number,item_category ,row_number() over(partition by sales_member_id,sales_order_number order by place_time) as rn from INFORMATION_SCHEMA.TABLES where store=N&#x27;丝芙兰官网&#x27; ) t1 where rn=1 )tt group by sales_member_id )ttt","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"}]},{"title":"面试题之数据结构 interview-dataStructure","slug":"Interview_dataStructure","date":"2018-12-21T16:00:22.000Z","updated":"2023-05-25T09:35:15.284Z","comments":true,"path":"2018/12/22/Interview_dataStructure/","link":"","permalink":"http://example.com/2018/12/22/Interview_dataStructure/","excerpt":"","text":"红黑树1234红黑树与AVL的比较：AVL是严格平衡树，因此在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多；红黑是用非严格的平衡来换取增删节点时候旋转次数的降低；所以简单说，如果你的应用中，搜索的次数远远大于插入和删除，那么选择AVL，如果搜索，插入删除次数几乎差不多，应该选择RB。","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Interview","slug":"Interview","permalink":"http://example.com/tags/Interview/"}]},{"title":"面试题之Python interview-python","slug":"Interview_python","date":"2018-12-21T16:00:22.000Z","updated":"2023-05-25T09:38:03.888Z","comments":true,"path":"2018/12/22/Interview_python/","link":"","permalink":"http://example.com/2018/12/22/Interview_python/","excerpt":"","text":"1. Python的函数参数传递123456789101112131415161718192021看两个如下例子，分析运行结果:代码一：a = 1def fun(a): a = 2fun(a)print(a) # 1代码二：a = []def fun(a):a.append(1)fun(a)print(a) # [1]所有的变量都可以理解是内存中一个对象的“引用”，或者，也可以看似c中void*的感觉。这里记住的是类型是属于对象的，而不是变量。而对象有两种,“可更改”（mutable）与“不可更改”（immutable）对象。在python中，strings, tuples, 和numbers是不可更改的对象，而list,dict等则是可以修改的对象。(这就是这个问题的重点)当一个引用传递给函数的时候,函数自动复制一份引用,这个函数里的引用和外边的引用没有半毛关系了.所以第一个例子里函数把引用指向了一个不可变对象,当函数返回的时候,外面的引用没半毛感觉.而第二个例子就不一样了,函数内的引用指向的是可变对象,对它的操作就和定位了指针地址一样,在内存里进行修改. Python中的元类(metaclass) 12元类就是用来创建类的“东西”。你创建类就是为了创建类的实例对象，但是我们已经学习到了Python中的类也是对象。好吧，元类就是用来创建这些类（对象）的，元类就是类的类这个非常的不常用,详情请看：《深刻理解Python中的元类(metaclass)》 @staticmethod和@classmethod 1234567891011121314151617181920Python其实有3个方法,即静态方法(staticmethod),类方法(classmethod)和实例方法,如下:class A(object): def foo(self,x): print &quot;executing foo(%s,%s)&quot;%(self,x) @classmethod def class_foo(cls,x): print( &quot;executing class_foo(%s,%s)&quot;%(cls,x)) @staticmethod def static_foo(x): print (&quot;executing static_foo(%s)&quot;%x)a=A()这里先理解下函数参数里面的self和cls.这个self和cls是对类或者实例的绑定.对于实例方法,我们知道在类里每次定义方法的时候都需要绑定这个实例,就是foo(self, x),为什么要这么做呢?因为实例方法的调用离不开实例,我们需要把实例自己传给函数,调用的时候是这样的a.foo(x)(其实是foo(a, x)).类方法一样,只不过它传递的是类而不是实例,A.class_foo(x).注意这里的self和cls可以替换别的参数,但是python的约定是这俩,还是不要改的好.对于静态方法其实和普通的方法一样,不需要对谁进行绑定,唯一的区别是调用的时候需要使用a.static_foo(x)或者A.static_foo(x)来调用.\\ 实例方法 类方法 静态方法a = A() a.foo(x) a.class_foo(x) a.static_foo(x)A 不可用 A.class_foo(x) A.static_foo(x) 类变量和实例变量 123456789101112131415161718192021222324 class Person: name=&quot;aaa&quot;p1=Person()p2=Person()p1.name=&quot;bbb&quot;print(p1.name) # bbbprint(p2.name) # aaaprint(Person.name) # aaa类变量就是供类使用的变量,实例变量就是供实例使用的.这里p1.name=&quot;bbb&quot;是实例调用了类变量,这其实和上面第一个问题一样,就是函数传参的问题,p1.name一开始是指向的类变量name=&quot;aaa&quot;,但是在实例的作用域里把类变量的引用改变了,就变成了一个实例变量,self.name不再引用Person的类变量name了.可以看看下面的例子: class Person: name=[]p1=Person()p2=Person()p1.name.append(1)print(p1.name) # [1]print(p2.name) # [1]print(Person.name) # [1] Python自省 123这个也是python彪悍的特性.自省就是面向对象的语言所写的程序在运行时,所能知道对象的类型.简单一句就是运行时能够获得对象的类型.比如type(),dir(),getattr(),hasattr(),isinstance(). 字典推导式 12可能你见过列表推导时,却没有见过字典推导式,在2.7中才加入的: d = &#123;key: value for (key, value) in iterable&#125; Python中单下划线和双下划线 123456789101112131415161718192021class MyClass():... def __init__(self):... self.__superprivate = &quot;Hello&quot;... self._semiprivate = &quot;, world!&quot;...mc = MyClass()&gt;&gt;&gt; print(mc.__superprivate)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;AttributeError: myClass instance has no attribute &#x27;__superprivate&#x27;&gt;&gt;&gt; print(mc._semiprivate), world!&gt;&gt;&gt; print mc.__dict__&#123;&#x27;_MyClass__superprivate&#x27;: &#x27;Hello&#x27;, &#x27;_semiprivate&#x27;: &#x27;, world!&#x27;&#125;__foo__:一种约定,Python内部的名字,用来区别其他用户自定义的命名,以防冲突._foo:一种约定,用来指定变量私有.程序员用来指定私有变量的一种方式.__foo:这个有真正的意义:解析器用_classname__foo来代替这个名字,以区别和其他类相同的命名.详情见:http://www.zhihu.com/question/19754941 字符串格式化:%和.format 123456.format在许多方面看起来更便利.对于%最烦人的是它无法同时传递一个变量和元组.你可能会想下面的代码不会有什么问题:Python: &quot;hi there %s&quot; % name但是,如果name恰好是(1,2,3),它将会抛出一个TypeError异常.为了保证它总是正确的,你必须这样做: &quot;hi there %s&quot; % (name,) # 提供一个单元素的数组而不是一个参数 迭代器和生成器 12345在Python中，这种一边循环一边计算的机制，称为生成器：generator。可以被next()函数调用并不断返回下一个值的对象称为迭代器：Iterator。这个是stackoverflow里python排名第一的问题,值得一看: http://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do-in-python *args and **kwargs 1234567891011121314151617181920212223242526272829303132333435用*args和**kwargs只是为了方便并没有强制使用它们.当你不确定你的函数里将要传递多少参数时你可以用*args.例如,它可以传递任意数量的参数:def print_everything(*args): for count, thing in enumerate(args):... print &#x27;&#123;0&#125;. &#123;1&#125;&#x27;.format(count, thing)...&gt;&gt;&gt; print_everything(&#x27;apple&#x27;, &#x27;banana&#x27;, &#x27;cabbage&#x27;)0. apple1. banana2. cabbage相似的,**kwargs允许你使用没有事先定义的参数名:def table_things(**kwargs):... for name, value in kwargs.items():... print &#x27;&#123;0&#125; = &#123;1&#125;&#x27;.format(name, value)...&gt;&gt;&gt; table_things(apple = &#x27;fruit&#x27;, cabbage = &#x27;vegetable&#x27;)cabbage = vegetableapple = fruit你也可以混着用.命名参数首先获得参数值然后所有的其他参数都传递给*args和**kwargs.命名参数在列表的最前端.例如:1 def table_things(titlestring, **kwargs)*args和**kwargs可以同时在函数的定义中,但是*args必须在**kwargs前面.当调用函数时你也可以用*和**语法.例如: def print_three_things(a, b, c):... print &#x27;a = &#123;0&#125;, b = &#123;1&#125;, c = &#123;2&#125;&#x27;.format(a,b,c)...&gt;&gt;&gt; mylist = [&#x27;aardvark&#x27;, &#x27;baboon&#x27;, &#x27;cat&#x27;]&gt;&gt;&gt; print_three_things(*mylist)a = aardvark, b = baboon, c = cat就像你看到的一样,它可以传递列表(或者元组)的每一项并把它们解包.注意必须与它们在函数里的参数相吻合.当然,你也可以在函数定义或者函数调用时用*.http://stackoverflow.com/questions/3394835/args-and-kwargs 面向切面编程AOP和装饰器 12345这个AOP一听起来有点懵,同学面试的时候就被问懵了…装饰器是一个很著名的设计模式，经常被用于有切面需求的场景，较为经典的有插入日志、性能测试、事务处理等。装饰器是解决这类问题的绝佳设计，有了装饰器，我们就可以抽离出大量函数中与函数功能本身无关的雷同代码并继续重用。概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能。这个问题比较大,推荐: http://stackoverflow.com/questions/739654/how-can-i-make-a-chain-of-function-decorators-in-python中文: http://taizilongxu.gitbooks.io/stackoverflow-about-python/content/3/README.html 鸭子类型 123456“当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。”我们并不关心对象是什么类型，到底是不是鸭子，只关心行为。比如在python中，有很多file-like的东西，比如StringIO,GzipFile,socket。它们有很多相同的方法，我们把它们当作文件使用。又比如list.extend()方法中,我们并不关心它的参数是不是list,只要它是可迭代的,所以它的参数可以是list/tuple/dict/字符串/生成器等.鸭子类型在动态语言中经常使用，非常灵活，使得python不想java那样专门去弄一大堆的设计模式。 Python中重载 123456789引自知乎:http://www.zhihu.com/question/20053359函数重载主要是为了解决两个问题。1. 可变参数类型。2. 可变参数个数。另外，一个基本的设计原则是，仅仅当两个函数除了参数类型和参数个数不同以外，其功能是完全相同的，此时才使用函数重载，如果两个函数的功能其实不同，那么不应当使用重载，而应当使用一个名字不同的函数。好吧，那么对于情况 1 ，函数功能相同，但是参数类型不同，python 如何处理？答案是根本不需要处理，因为 python 可以接受任何类型的参数，如果函数的功能相同，那么不同的参数类型在 python 中很可能是相同的代码，没有必要做成两个不同函数。那么对于情况 2 ，函数功能相同，但参数个数不同，python 如何处理？大家知道，答案就是缺省参数。对那些缺少的参数设定为缺省参数即可解决问题。因为你假设函数功能相同，那么那些缺少的参数终归是需要用的。好了，鉴于情况 1 跟 情况 2 都有了解决方案，python 自然就不需要函数重载了。 新式类和旧式类 1234这个面试官问了,我说了老半天,不知道他问的真正意图是什么.这篇文章很好的介绍了新式类的特性: http://www.cnblogs.com/btchenguang/archive/2012/09/17/2689146.html新式类很早在2.2就出现了,所以旧式类完全是兼容的问题,Python3里的类全部都是新式类.这里有一个MRO问题可以了解下(新式类是广度优先,旧式类是深度优先),&lt;Python核心编程&gt;里讲的也很多. __new__和__init__的区别 1234567这个__new__确实很少见到,先做了解吧.1. __new__是一个静态方法,而__init__是一个实例方法.2. __new__方法会返回一个创建的实例,而__init__什么都不返回.3. 只有在__new__返回一个cls的实例时后面的__init__才能被调用.4. 当创建一个新实例时调用__new__,初始化一个实例时用__init__.ps: __metaclass__是创建类时起作用.所以我们可以分别使用__metaclass__,__new__和__init__来分别在类创建,实例创建和实例初始化的时候做一些小手脚. 单例模式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 这个绝对常考啊.绝对要记住1~2个方法,当时面试官是让手写的.# 1 使用__new__方法 class Singleton(object): def __new__(cls, *args, **kw): if not hasattr(cls, &#x27;_instance&#x27;): orig = super(Singleton, cls) cls._instance = orig.__new__(cls, *args, **kw) return cls._instanceclass MyClass(Singleton): a = 1# 2 共享属性创建实例时把所有实例的__dict__指向同一个字典,这样它们具有相同的属性和方法.class Borg(object): _state = &#123;&#125; def __new__(cls, *args, **kw): ob = super(Borg, cls).__new__(cls, *args, **kw) ob.__dict__ = cls._state return obclass MyClass2(Borg): a = 1# 3 装饰器版本def singleton(cls, *args, **kw): instances = &#123;&#125; def getinstance(): if cls not in instances: instances[cls] = cls(*args, **kw) return instances[cls] return getinstance@singletonclass MyClass:# 4 import方法作为python的模块是天然的单例模式 # mysingleton.pyclass My_Singleton(object): def foo(self): passmy_singleton = My_Singleton()# to usefrom mysingleton import my_singletonmy_singleton.foo() Python中的作用域 1234Python 中，一个变量的作用域总是由在代码中被赋值的地方所决定的。当 Python 遇到一个变量的话他会按照这样的顺序进行搜索：本地作用域（Local）→当前作用域被嵌入的本地作用域（Enclosing locals）→全局/模块作用域（Global）→内置作用域（Built-in） GIL线程全局锁 123线程全局锁(Global Interpreter Lock),即Python为了保证线程安全而采取的独立线程运行的限制,说白了就是一个核只能在同一时间运行一个线程.解决办法就是多进程和下面的协程(协程也只是单CPU,但是能减小切换代价提升性能). 协程 12简单点说协程是进程和线程的升级版,进程和线程都面临着内核态和用户态的切换问题而耗费许多切换时间,而协程就是用户自己控制切换的时机,不再需要陷入系统的内核态.Python里最常见的yield就是协程的思想!可以查看第九个问题. 闭包 123456789闭包(closure)是函数式编程的重要的语法结构。闭包也是一种组织代码的结构，它同样提高了代码的可重复使用性。当一个内嵌函数引用其外部作作用域的变量,我们就会得到一个闭包. 总结一下,创建一个闭包必须满足以下几点:1. 必须有一个内嵌函数2. 内嵌函数必须引用外部函数中的变量3. 外部函数的返回值必须是内嵌函数感觉闭包还是有难度的,几句话是说不明白的,还是查查相关资料.重点是函数运行后并不会被撤销,就像16题的instance字典一样,当函数运行完后,instance并不被销毁,而是继续留在内存空间里.这个功能类似类里的类变量,只不过迁移到了函数上.闭包就像个空心球一样,你知道外面和里面,但你不知道中间是什么样. lambda函数 1其实就是一个匿名函数,为什么叫lambda?因为和后面的函数式编程有关. Python函数式编程 12345678910111213141516171819这个需要适当的了解一下吧,毕竟函数式编程在Python中也做了引用.python中函数式编程支持:filter 函数的功能相当于过滤器。调用一个布尔函数bool_func来迭代遍历每个seq中的元素；返回一个使bool_seq返回值为true的元素的序列。 &gt;&gt;&gt;a = [1,2,3,4,5,6,7]&gt;&gt;&gt;b = filter(lambda x: x &gt; 5, a)&gt;&gt;&gt;print b&gt;&gt;&gt;[6,7]map函数是对一个序列的每个项依次执行函数，下面是对一个序列每个项都乘以2： &gt;&gt;&gt; a = map(lambda x:x*2,[1,2,3])&gt;&gt;&gt; list(a)[2, 4, 6]reduce函数是对一个序列的每个项迭代调用函数，下面是求3的阶乘： &gt;&gt;&gt; reduce(lambda x,y:x*y,range(1,4))6 Python里的拷贝 12345678910111213141516171819202122引用和copy(),deepcopy()的区别import copya = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;]] #原始对象b = a #赋值，传对象的引用c = copy.copy(a) #对象拷贝，浅拷贝d = copy.deepcopy(a) #对象拷贝，深拷贝a.append(5) #修改对象aa[4].append(&#x27;c&#x27;) #修改对象a中的[&#x27;a&#x27;, &#x27;b&#x27;]数组对象print &#x27;a = &#x27;, aprint &#x27;b = &#x27;, bprint &#x27;c = &#x27;, cprint &#x27;d = &#x27;, d输出结果：a = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], 5]b = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], 5]c = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]]d = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;]] Python垃圾回收机制 1234567891011121314151617Python GC主要使用引用计数（reference counting）来跟踪和回收垃圾。在引用计数的基础上，通过“标记-清除”（mark and sweep）解决容器对象可能产生的循环引用问题，通过“分代回收”（generation collection）以空间换时间的方法提高垃圾回收效率。1 引用计数PyObject是每个对象必有的内容，其中ob_refcnt就是做为引用计数。当一个对象有新的引用时，它的ob_refcnt就会增加，当引用它的对象被删除，它的ob_refcnt就会减少.引用计数为0时，该对象生命就结束了。优点:1. 简单2. 实时性缺点:1. 维护引用计数消耗资源2. 循环引用2 标记-清除机制基本思路是先按需分配，等到没有空闲内存的时候从寄存器和程序栈上的引用出发，遍历以对象为节点、以引用为边构成的图，把所有可以访问到的对象打上标记，然后清扫一遍内存空间，把所有没标记的对象释放。3 分代技术分代回收的整体思想是：将系统中的所有内存块根据其存活时间划分为不同的集合，每个集合就成为一个“代”，垃圾收集频率随着“代”的存活时间的增大而减小，存活时间通常利用经过几次垃圾回收来度量。Python默认定义了三代对象集合，索引数越大，对象存活时间越长。举例：当某些内存块M经过了3次垃圾收集的清洗之后还存活时，我们就将内存块M划到一个集合A中去，而新分配的内存都划分到集合B中去。当垃圾收集开始工作时，大多数情况都只对集合B进行垃圾回收，而对集合A进行垃圾回收要隔相当长一段时间后才进行，这就使得垃圾收集机制需要处理的内存少了，效率自然就提高了。在这个过程中，集合B中的某些内存块由于存活时间长而会被转移到集合A中，当然，集合A中实际上也存在一些垃圾，这些垃圾的回收会因为这种分代的机制而被延迟。 Python里面如何实现tuple和list的转换？ 123456789答：tuple，可以说是不可变的list，访问方式还是通过索引下标的方式。当你明确定义个tuple是，如果仅有一个元素，必须带有,例如：(1,)。当然，在2.7以后的版，python里还增加了命名式的tuple！至于有什么用，首先第一点，楼主玩过python都知道，python的函数可以有多返回值的，而python里，多返回值，就是用tuple来表示，这是用的最广的了，比如说，你需要定义一个常量的列表，但你又不想使用list，那也可以是要你管tuple，例如：if a in (&#x27;A&#x27;,&#x27;B&#x27;,&#x27;C&#x27;):pass Python的is 1is是对比地址,==是对比值 read,readline和readlines 1234• read 读取整个文件• readline 读取下一行,使用生成器方法• readlines 读取整个文件到一个迭代器以供我们遍历 Python2和3的区别 1234567891011121314大部分Python库都同时支持Python 2.7.x和3.x版本的，所以不论选择哪个版本都是可以的。但为了在使用Python时避开某些版本中一些常见的陷阱，或需要移植某个Python项目使用__future__模块print函数整数除法Unicodexrange触发异常处理异常next()函数和.next()方法For循环变量与全局命名空间泄漏比较无序类型使用input()解析输入内容返回可迭代对象，而不是列表http://python.jobbole.com/80006/ 到底什么是Python？你可以在回答中与其他技术进行对比 1234567891011下面是一些关键点：• Python是一种解释型语言。这就是说，与C语言和C的衍生语言不同，Python代码在运行之前不需要编译。其他解释型语言还包括PHP和Ruby。• Python是动态类型语言，指的是你在声明变量时，不需要说明变量的类型。你可以直接编写类似x=111和x=&quot;I&#x27;m a string&quot;这样的代码，程序不会报错。• Python非常适合面向对象的编程（OOP），因为它支持通过组合（composition）与继承（inheritance）的方式定义类（class）。Python中没有访问说明符（access specifier，类似C++中的public和private），这么设计的依据是“大家都是成年人了”。• 在Python语言中，函数是第一类对象（first-class objects）。这指的是它们可以被指定给变量，函数既能返回函数类型，也可以接受函数作为输入。类（class）也是第一类对象。• Python代码编写快，但是运行速度比编译语言通常要慢。好在Python允许加入基于C语言编写的扩展，因此我们能够优化代码，消除瓶颈，这点通常是可以实现的。numpy就是一个很好地例子，它的运行速度真的非常快，因为很多算术运算其实并不是通过Python实现的。• Python用途非常广泛——网络应用，自动化，科学建模，大数据应用，等等。它也常被用作“胶水语言”，帮助其他语言和组件改善运行状况。• Python让困难的事情变得容易，因此程序员可以专注于算法和数据结构的设计，而不用处理底层的细节。为什么提这个问题：如果你应聘的是一个Python开发岗位，你就应该知道这是门什么样的语言，以及它为什么这么酷。以及它哪里不好。 “猴子补丁”（monkey patching）指的是什么？这种做法好吗？ 123456789“猴子补丁”就是指，在函数或对象已经定义之后，再去改变它们的行为。举个例子：import datetimedatetime.datetime.now = lambda: datetime.datetime(2012, 12, 12)大部分情况下，这是种很不好的做法 - 因为函数在代码库中的行为最好是都保持一致。打“猴子补丁”的原因可能是为了测试。mock包对实现这个目的很有帮助。为什么提这个问题？答对这个问题说明你对单元测试的方法有一定了解。你如果提到要避免“猴子补丁”，可以说明你不是那种喜欢花里胡哨代码的程序员（公司里就有这种人，跟他们共事真是糟糕透了），而是更注重可维护性。还记得KISS原则码？答对这个问题还说明你明白一些Python底层运作的方式，函数实际是如何存储、调用等等。另外：如果你没读过mock模块的话，真的值得花时间读一读。这个模块非常有用。 介绍一下except的用法和作用？ 1234try…except…except…[else…][finally…]执行try下的语句，如果引发异常，则执行过程会跳到except语句。对每个except分支顺序尝试执行，如果引发的异常与except中的异常组匹配，执行相应的语句。如果所有的except都不匹配，则异常会传递到下一个调用本代码的最高层try代码中。try下的语句正常执行，则执行else块代码。如果发生异常，就不会执行如果存在finally语句，最后总是会执行。 37.Python中pass语句的作用是什么？ 1答：pass语句不会执行任何操作，一般作为占位符或者创建占位程序，whileFalse:pass 38.介绍一下Python下range()函数的用法？ 1列出一组数据，经常用在for in range()循环中 如何用Python来进行查询和替换一个文本字符串？12345678910# 可以使用re模块中的sub()函数或者subn()函数来进行查询和替换，# 格式：sub(replacement, string[,count=0])（replacement是被替换成的文本，string是需要被替换的文本，count是一个可选参数，指最大被替换的数量）import rep=re.compile(‘blue|white|red’)print(p.sub(‘colour’,&#x27;blue socks and red shoes’))# colour socks and colourshoesprint(p.sub(‘colour’,&#x27;blue socks and red shoes’,count=1))# colour socks and redshoes# subn()方法执行的效果跟sub()一样，不过它会返回一个二维数组，包括替换后的新的字符串和总共替换的数量 用Python匹配HTML tag的时候，&lt;.*&gt;和&lt;.*?&gt;有什么区别？123456术语叫贪婪匹配( &lt;.*&gt; )和非贪婪匹配(&lt;.*?&gt; )例如:test&lt;.*&gt; :test&lt;.*?&gt; : 42.Python里面如何生成随机数？ 12345random模块随机整数：random.randint(a,b)：返回随机整数x,a&lt;=x&lt;=brandom.randrange(start,stop,[,step])：返回一个范围在(start,stop,step)之间的随机整数，不包括结束值。随机实数：random.random( ):返回0到1之间的浮点数random.uniform(a,b):返回指定范围内的浮点数。 43.有没有一个工具可以帮助查找python的bug和进行静态的代码分析？ 12PyChecker是一个python代码的静态分析工具，它可以帮助查找python代码的bug, 会对代码的复杂度和格式提出警告Pylint是另外一个工具可以进行codingstandard检查 44.如何在一个function里面设置一个全局的变量？ 123答：解决方法是在function的开始插入一个global声明：def f() global x 45.单引号，双引号，三引号的区别 123456答：单引号和双引号是等效的，如果要换行，需要符号(\\),三引号则可以直接换行，并且可以包含注释如果要表示Let’s go 这个字符串单引号：s4 = ‘Let\\’s go’双引号：s5 = “Let’s go”s6 = ‘I realy like“python”!’这就是单引号和双引号都可以表示字符串的原因了 46 Python和多线程（multi-threading）。这是个好主意码？列举一些让Python代码以并行方式运行的方法。 1234Python并不支持真正意义上的多线程。Python中提供了多线程包，但是如果你想通过多线程提高代码的速度，使用多线程包并不是个好主意。Python中有一个被称为Global Interpreter Lock（GIL）的东西，它会确保任何时候你的多个线程中，只有一个被执行。线程的执行速度非常之快，会让你误以为线程是并行执行的，但是实际上都是轮流执行。经过GIL这一道关卡处理，会增加执行的开销。这意味着，如果你想提高代码的运行速度，使用threading包并不是一个很好的方法。不过还是有很多理由促使我们使用threading包的。如果你想同时执行一些任务，而且不考虑效率问题，那么使用这个包是完全没问题的，而且也很方便。但是大部分情况下，并不是这么一回事，你会希望把多线程的部分外包给操作系统完成（通过开启多个进程），或者是某些调用你的Python代码的外部程序（例如Spark或Hadoop），又或者是你的Python代码调用的其他代码（例如，你可以在Python中调用C函数，用于处理开销较大的多线程工作）。为什么提这个问题因为GIL就是个混账东西（A-hole）。很多人花费大量的时间，试图寻找自己多线程代码中的瓶颈，直到他们明白GIL的存在。","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Interview","slug":"Interview","permalink":"http://example.com/tags/Interview/"}]},{"title":"收藏从未停止 复习从未开始 Collect","slug":"Collect","date":"2018-09-18T07:09:12.000Z","updated":"2022-09-30T09:41:40.000Z","comments":true,"path":"2018/09/18/Collect/","link":"","permalink":"http://example.com/2018/09/18/Collect/","excerpt":"Perlperl操作12system(&quot;python xxx.py arg1 arg2&quot;) perl调用python脚本$output=`python xxx.py arg1 arg2` perl调用python脚本","text":"Perlperl操作12system(&quot;python xxx.py arg1 arg2&quot;) perl调用python脚本$output=`python xxx.py arg1 arg2` perl调用python脚本 AI 人工智能AI面试必备AI 常用算法[blog-2allfirst_rank_v2rank_v25-2)[sult.none-task-blog-2allfirst_rank_v2rank_v25-1) 机器人链表[ibute.pc_search_result.none-task-blog-2allsobaiduweb~default-0-88853533)perl:Perl 教程 django: Django数据库–事务及事务回滚 Django Q 对象TemplateView , ListView ，DetailView三种常用类视图用法Django 教程 6: 通用列表和详细信息视图 django中写form表单时csrf_token的作用 XSS和CSRF的原理Django 模板 linux:Linux 中 fg、bg、jobs 等指令每天一个linux命令（15）：tail 命令shell:shell脚本加密Java画图 流程图 HTML前端学习笔记123456style=&quot;background:url(https://img.tukuppt.com//ad_preview/00/03/30/5c98a556e3a89.jpg!/fw/980)&quot;左边栏固定： &lt;div id=&quot;pageHeader&quot; style=&quot;position: fixed; top: 0px; left: 0px; z-index: 9999; width: 100%;&quot;&gt;顶栏固定：&lt;div class=&quot;row border-bottom&quot; style=&quot;position: fixed; z-index: 9999; width: 100%;&quot;&gt;设置页面背景图片或颜色background-image: url(bgimage.gif); background-color: #000000;s SVG 123456意为可缩放矢量图形（Scalable Vector Graphics）。使用 XML 格式定义图像。art原背景色设置style=&quot;background-color: #ffffff深蓝色背景颜色#00162D HTML1234567891011121314151617&lt;div class=&quot;col-md-4&quot; style=&quot;border-left: 2px solid #eee;font-size: 13px;margin-top: 10px&quot;&gt;style=&quot;VISIBILITY: hidden&quot; 隐藏&#123;% if isadmin %&#125; &#123;% endif %&#125; 判断符合条件才展示&lt;style type=&quot;text/css&quot;&gt;div&#123;margin:5px;border:0;padding:0;&#125;&lt;/style&gt; &lt;span style=&quot;display:none;&quot;&gt;&amp;nbsp;获取中&lt;/span&gt; 隐藏不占空间&lt;span style=&quot;visibility:hidden;&quot;&gt;&amp;nbsp;获取中&lt;/span&gt; 隐藏占用空间approve&lt;input type=&quot;checkbox&quot; class=&quot;mycheck&quot; &#123;% if approved %&#125; checked readonly&#123;% endif %&#125; id=&quot;approve_check&quot; &gt;&lt;button type=&quot;button&quot; class=&quot;btn btn-default&quot;&gt;默认按钮&lt;/button&gt; &lt;!-- 标准的按钮 --&gt;&lt;button type=&quot;button&quot; class=&quot;btn btn-primary&quot;&gt;原始按钮&lt;/button&gt; &lt;!-- 提供额外的视觉效果，标识一组按钮中的原始动作 --&gt;&lt;button type=&quot;button&quot; class=&quot;btn btn-success&quot;&gt;成功按钮&lt;/button&gt; &lt;!-- 表示一个成功的或积极的动作 --&gt;&lt;button type=&quot;button&quot; class=&quot;btn btn-info&quot;&gt;信息按钮&lt;/button&gt; &lt;!-- 信息警告消息的上下文按钮 --&gt;&lt;button type=&quot;button&quot; class=&quot;btn btn-warning&quot;&gt;警告按钮&lt;/button&gt; &lt;!-- 表示应谨慎采取的动作 --&gt;&lt;button type=&quot;button&quot; class=&quot;btn btn-danger&quot;&gt;危险按钮&lt;/button&gt; &lt;!-- 表示一个危险的或潜在的负面动作 --&gt;&lt;button type=&quot;button&quot; class=&quot;btn btn-link&quot;&gt;链接按钮&lt;/button&gt; &lt;!-- 并不强调是一个按钮，看起来像一个链接，但同时保持按钮的行为&gt;class=&quot;col-md-4&quot; 定义 列 占用4个像素margin-top:15px&quot; 距离上方空出15个像素&lt;div class=&quot;col-md-4&quot; style=&quot;border-left: 2px solid #eee ;font-size: 13px ;margin-top:15px&quot; &gt; bootstrap 栅栏系统12345678col 列xs-maxsmall， 超小sm-small， 小md-medium， 中等-* 表示占列，即占自动每行row分12列栅格系统比；col-xs-* 超小屏幕 手机 (&lt;768px),col-sm-* 小屏幕 平板 (≥768px),col-md-* 中等屏幕 桌面显示器 (≥992px)(栅格参数). 震惊于刚入行时的学习热情","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"数据处理 Excel","slug":"Excel-Function","date":"2018-09-18T07:09:12.000Z","updated":"2022-09-30T07:40:00.000Z","comments":true,"path":"2018/09/18/Excel-Function/","link":"","permalink":"http://example.com/2018/09/18/Excel-Function/","excerpt":"Excel常用数据处理的函数/工具","text":"Excel常用数据处理的函数/工具 excel随机填充汉字1=CHOOSE(RANDBETWEEN(1,4),&quot;男性&quot;,&quot;未知&quot;,&quot;女性&quot;,&quot;&quot;) excel随机填充数字1=RANDBETWEEN(60,100) – excel设置如果vlookup不到就置为空值 1=IFERROR(VLOOKUP(C9,S:W,5,FALSE),&quot;&quot;) excel计算两个时间之间的小时数1Hour () 时间加若干小时1E5+time(1,0,0) 快捷键1234Ctrl + Shift + L 筛选Ctrl + &quot;+&quot; 加列Ctrl + &quot;-&quot; 减列Ctrl + D 向下填充 excel单元格内所有单词首字母大写1=PROPER(E71) 123456789101112DAVERAGE // 对列表或数据库中满足指定条件的记录字段（列）中的数值求平均值DCOUNT // 返回列表或数据库中满足指定条件的记录字段（列）中包含数字的单元格的个数DCOUNTA // 返回列表或数据库中满足指定条件的记录字段（列）中的非空单元格的个数DGET // 从列表或数据库的列中提取符合指定条件的单个值DMAX // 返回列表或数据库中满足指定条件的记录字段（列）中的最大数字DMIN // 返回列表或数据库中满足指定条件的记录字段（列）中的最小数字DPRODUCT // 返回列表或数据库中满足指定条件的记录字段（列）中的数值的乘积DSTDEV // 返回利用列表或数据库中满足指定条件的记录字段（列）中的数字作为一个样本估算出的总体标准偏差DSTDEVP // 返回利用列表或数据库中满足指定条件的记录字段（列）中的数字作为样本总体计算出的总体标准偏差DSUM // 返回列表或数据库中满足指定条件的记录字段（列）中的数字之和DVAR // 返回利用列表或数据库中满足指定条件的记录字段（列）中的数字作为一个样本估算出的总体方差DVARP // 通过使用列表或数据库中满足指定条件的记录字段（列）中的数字计算样本总体的样本总体方差 文本函数文本函数 123456789101112131415161718192021222324252627282930313233ASC // 对于双字节字符集 (DBCS) 语言，该函数将全角（双字节）字符转换成半角（单字节）字符BAHTTEXT // 将数字转换为泰语文本并添加后缀“泰铢”CHAR // 返回对应于数字代码的字符CLEAN // 删除文本中所有不能打印的字符CODE // 返回文本字符串中第一个字符的数字代码CONCAT // CONCAT 函数将多个区域和/或字符串的文本组合起来，但不提供分隔符或 IgnoreEmpty 参数CONCATENATE // 要在 Excel 中使用这些示例，请复制下表中的数据，然后将其粘贴进新工作表的 A1 单元格中DBCS // 本“帮助”主题中描述的函数将字符串中的半角（单字节）字母转换为全角（双字节）字符DOLLAR // DOLLAR函数，其中一个文本函数将数字转EXACT // 比较两个文本字符串，如果它们完全相同，则返回 TRUE，否则返回 FALSEFIND、FINDBFIXED // 将数字舍入到指定的小数位数，使用句点和逗号，以十进制数格式对该数进行格式设置，并以文本形式返回结果JIS // 本“帮助”主题中描述的函数将字符串中的半角（单字节）字母转换为全角（双字节）字符LEFT、LEFTBLEN、LENBLOWER // 将一个文本字符串中的所有大写字母转换为小写字母MID、MIDBNUMBERVALUE // 以与区域设置无关的方式将文本转换为数字PHONETIC // 提取文本字符串中的拼音 (furigana) 字符PROPER // 将文本字符串的首字母以及文字中任何非字母字符之后的任何其他字母转换成大写REPLACE、REPLACEBREPT // 将文本重复一定次数RIGHT、RIGHTBSEARCH、SEARCHBSUBSTITUTE // 在文本字符串中用 new_text 替换 old_textT // 返回值引用的文字TEXT // TEXT函数最简单的形式表示： =TEXT(Value you want to format, &quot;Format code you want to apply&quot;)TEXTJOIN // TEXTJOIN(分隔符, ignore_empty, text1, [text2], …)TRIM // 除了单词之间的单个空格之外，移除文本中的所有空格UNICHAR // 返回给定数值引用的 Unicode 字符UNICODE // 返回对应于文本的第一个字符的数字（代码点）UPPER // 将文本转换为大写字母VALUE // 将表示数字的文本字符串转换为数字","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"Excel","slug":"Excel","permalink":"http://example.com/tags/Excel/"}]},{"title":"标注工具 LabelImg","slug":"Tools-LabelImg","date":"2018-09-18T07:09:12.000Z","updated":"2022-09-30T07:42:24.000Z","comments":true,"path":"2018/09/18/Tools-LabelImg/","link":"","permalink":"http://example.com/2018/09/18/Tools-LabelImg/","excerpt":"“””filename ：图片名称size：width，heights 图片尺寸object：图片中标注的目标，可能含有多个目标，这个xml就有2个标注目标name：标注目标 类别标签 labelsbndbox ：标注目标框xmin ,ymin ,xmax ,ymax （左上角，右下角坐标）“””","text":"“””filename ：图片名称size：width，heights 图片尺寸object：图片中标注的目标，可能含有多个目标，这个xml就有2个标注目标name：标注目标 类别标签 labelsbndbox ：标注目标框xmin ,ymin ,xmax ,ymax （左上角，右下角坐标）“”” 快捷键+————+——————————————–+| Ctrl + s | 保存 |+————+——————————————–+| Ctrl + d | Copy the current label and rect box |+————+——————————————–+| Space | 标记当前图片已标记 |+————+——————————————–+| w | 创建一个矩形 |+————+——————————————–+| d | 下一张图片 |+————+——————————————–+| a | 上一张图片 |+————+——————————————–+","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"CV","slug":"CV","permalink":"http://example.com/tags/CV/"},{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"LabelImg","slug":"LabelImg","permalink":"http://example.com/tags/LabelImg/"}]},{"title":"版本管理工具 Git","slug":"Tools-Git","date":"2018-09-18T07:09:12.000Z","updated":"2022-09-30T09:48:42.000Z","comments":true,"path":"2018/09/18/Tools-Git/","link":"","permalink":"http://example.com/2018/09/18/Tools-Git/","excerpt":"一切开始的地方作为目前最流行的分布式版本管理工具，git从诞生伊始就备受关注。虽然这与它的作者Linus（大名鼎鼎的Linux操作系统的作者）的个人影响力有一定的关系，但更重要的是，git无论是在设计理念、性能、安全性还是易用性等方面都有着传统的版本管理工具无可比拟的优势。除此之外，它还是完全开源和免费的。很多对Git完全不了解的同学可能会误以为Git和Github是一个概念，但其实两者有着本质的区别：前者是一个版本管理工具，而后者是一个项目托管平台。在英文中hub的意思是“中心，核心”，所以Github意为它是以Git作为版本管理工具的项目托管平台","text":"一切开始的地方作为目前最流行的分布式版本管理工具，git从诞生伊始就备受关注。虽然这与它的作者Linus（大名鼎鼎的Linux操作系统的作者）的个人影响力有一定的关系，但更重要的是，git无论是在设计理念、性能、安全性还是易用性等方面都有着传统的版本管理工具无可比拟的优势。除此之外，它还是完全开源和免费的。很多对Git完全不了解的同学可能会误以为Git和Github是一个概念，但其实两者有着本质的区别：前者是一个版本管理工具，而后者是一个项目托管平台。在英文中hub的意思是“中心，核心”，所以Github意为它是以Git作为版本管理工具的项目托管平台 git Basic12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 1.获得git仓库git init:执行之后 仅仅在项目目录多出了一个.git目录，关于版本等的所有信息都在这个目录里面git clone &lt;url&gt;:克隆远程目录，由于是将远程服务器上的仓库完全镜像一份至本地，而不是取某一个特定版本，所以用clone而不是checkout # 2.git中版本的保存:记录版本信息的方式主要有两种:记录文件每个版本的快照/记录文件每个版本之间的差异:Subversion和Perforce等版本控制系统都是记录文件每个版本之间的差异，这就需要对比文件两版本之间的具体差异记录文件每个版本的快照:git:不关心文件两个版本之间的具体差别，而是关心文件的整体是否有改变，若文件被改变，在添加提交时就生成文件新版本的快照，(实现方法:而判断文件整体是否改变的方法就是用SHA-1算法计算文件的校验和)(实现原理:当一个文件被改变时，它的校验和一定会被改变（理论上存在两个文件校验和相同，但机率小到可以忽略不计），GIT就以此判断文件是否被修改，及以些记录不同版本(文件状态概念的引入：在工作目录的文件可以处于不同的状态，比如说新添加了一个文件，GIT发觉了这个文件，但这个文件是否要纳入GIT的版本控制还是要由我们自己决定，比如编译生成的中间文件，不想纳入版本控制 所以引入文件状态# 3.1 git 的三个工作区：git directory::本地数据（仓库）目录:就是我们的本地仓库.git目录，里面保存了所有的版本信息等内容working driectory::工作目录:就是我们的工作目录，其中包括未跟踪文件及已跟踪文件，而已跟踪文件都是从git directory取出来的文件的某一个版本或新跟踪的文件。staging area::暂存区:不对应一个具体目录，其时只是git directory中的一个特殊文件当我们修改了一些文件后，要将其放入暂存区然后才能提交，每次提交时其实都是提交暂存区的文件--&gt;git仓库，然后清除暂存区。而checkout某一版本时，这一版本的文件就从git仓库取出来--&gt;我们的工作目录。3.2 git文件操作版本控制就是对文件的版本控制，对于Linux来说，设备，目录等全是文件，要对文件进行修改、提交等操作，首先要知道文件当前在什么状态，不然可能会提交了现在还不想提交的文件，或者要提交的文件没提交上工作目录中的文件被分为两种状态，一种是已跟踪状态(tracked)，另一种是未跟踪状态(untracked):只有处于已跟踪状态的文件才被纳入GIT的版本控制git add &lt;file&gt; : 跟踪文件::当我们往工作目录添加一个文件的时候，这个文件默认是未跟踪状态的，不希望编译生成的一大堆临时文件默认被跟踪每次手动将这些文件清除出去。staged状态:在输出每个文件状态的同时还说明了怎么操作，像上图就有怎么暂存、怎么跟踪文件、怎么取消暂存的说明。git status : 文档状态查看::当前工作目录中所有文件目前的状态::哪些文件已被暂存::有哪些未跟踪的文件::哪些文件被修改了::changes to be committed:已被暂存Untracked files:未跟踪changes not staged for commit:暂存此文件时，暂存的是那一文件当时的版本，当暂存后再次修改了这个文件后就会提示这个文件暂存后的修改是未被暂存的git add &lt;file&gt;... :暂存文件:use &quot;git add &lt;file&gt;...&quot; to update what will be committed (可以使用glob模式匹配，比如&quot;file[ab]&quot;，也可以使用&quot;git add .&quot;添加当前目录下的所有文件。)git reset HEAD &lt;file&gt;... :取消暂存文件git checkout -- &lt;file&gt;... :修改了一个文件想还原修改git diff : ---a表示修改之前的文件，+++b表示修改后的文件 ::显示的是文件修改后还没有暂存起来的内容git diff --cached:---/dev/null:之前没有提交过这一个文件，这是将是第一次提交:比较暂存区的文件与之前已经提交过的文件:提交的是暂存区的内容git diff --staged:与上面操作等效(GIT的版本要大于1.6.1)再次执行&quot;git add&quot;将覆盖暂存区的内容----------??? # 4.git提交和提交历史：提交：git commit:第一行填简单说明，隔一行填写详细说明git commit -a:跳过暂存区直接提交修改的文件，可以使用&quot;-a&quot;参数，但要慎重，别一不小心提交了不想提交的文件git commit -m &#x27;commit message&#x27;:需要快捷地填写提交说明可使用&quot;-m&quot;参数查看提交历史：git log:显示commit的哈希编码/作者ID/时间Date/第几次提交git log -1:显示最新的一次提交git log -n:git log --pretty=oneline --addrev-commit: 显示简单的SHA-1值与简单提交说明 (oneline仅显示提交的第一行)git log --graph:以图形化的方式显示提交历史的关系，这就可以方便地查看提交历史的分支信息，当然是控制台用字符画出来的图形 git 操作123456789101112131415161718192021git status 查看事实文件的状态--是否修改git diff 打印修改的内容git add xxx.sh 把修改后的文件暂存到仓库git add . 把当前目录修改后的所有文件暂存到仓库git commit -m &#x27;modify hook&#x27; 记录修改的内容git commit --amend 提交到上次的修改 / 修改上次提交的注释git commit --amend -C HEADgit push origin HEAD:refs/for/develop 提交最新版本 develop:分支名git branch 在哪个分支git log 历史修改记录git reflog 几乎所有本地仓库的改变git checkout:git HEAD:git reset --hard HEAD~1 返回上一个HEADgit reset --hard origin/develop Your branch and &#x27;origin/develop&#x27; have diverged, and have 2 and 2 different commits each, respectively.解决方式git clone ssh://luna.xiong@review.source.unisoc.com:29418/scm/bin/jen -b develop 克隆某个仓库的某个分支到本地当前文件夹gitdir=$(git rev-parse --git-dir); scp -p -P 29418 luna.xiong@rev iew.source.unisoc.com:hooks/commit-msg $&#123;gitdir&#125;/hooks/commit-msggit commit --amend 删除所有hook后---缺少change-ID 时的解决方案git pull --rebase 与服务器上的最新版本自动合并git rebase --abort 取消当前合并操作 repo sync123更新服务器最新版本的文件到本地chmod g=rx hello.sh 设置 同组人权限chmod 0755 hello.sh 设置文件可执行权限","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Git","slug":"Git","permalink":"http://example.com/tags/Git/"}]},{"title":"超好用的编辑工具 Sublime","slug":"Tools-Sublime","date":"2018-09-18T07:09:12.000Z","updated":"2022-09-30T09:41:40.000Z","comments":true,"path":"2018/09/18/Tools-Sublime/","link":"","permalink":"http://example.com/2018/09/18/Tools-Sublime/","excerpt":"Sublime","text":"Sublime Sublime操作12345678910111213141516171819202122232425262728293031323334353637383940F11 切换普通全屏Shift+F11 切换无干扰全屏Ctrl+Shift+N 创建一个新窗口Ctrl+Tab 切换标签页Ctrl+Shift+T 恢复刚刚关闭的标签Ctrl+W 关闭当前标签，当窗口内没有标签时会关闭该窗口Ctrl+Space 代码提示Ctrl+H 替换Ctrl+F (查找的元素间的跳转:Enter间或Shift+Enter键)Ctrl+L 选择当前光标所在位置的行。连续使用时，继续选中下一行Ctrl+Shift+L 在多行选中后，在所有选中的行后产生游标Ctrl+K、Ctrl+B 显示/隐藏侧边栏Alt+Shift+2 左右分屏，Alt+Shift+8 上下分屏，Alt+Shift+5 上下左右分屏（即分为四屏）双击 选中光标所在单词三击 选中光标所在行(等同于Ctrl＋L)Home和End 移动至行尾和行首Ctrl + ←/→ 进行逐词移动Ctrl+Shift+ ←/→ 进行逐词选择Alt + ←/→ 进行逐词选择，但是选择的粒度比Ctrl + ←/→小，进行是分词级别的移动Alt+Shift+ ←/→ 进行分词级别的选择Ctrl+Z 撤销Ctrl+Y 恢复撤销Ctrl+Shift+ ↑/↓ 移动当前行Ctrl+Shift+du 复制当前行Ctrl+Shift+K 删除当前行Ctrl+K，Ctrl+K 删除至行末Ctrl+K，Ctrl+Backspace 删除至行首Ctrl+Enter 在当前行下添加新行Ctrl+Shift+Enter 在当前行上添加新行Ctrl+/ 行注释Ctrl+Shift+/ 块注释Shift+鼠标右键 向下拖动，产生多个光标Ctrl+D 选中当前光标所在位置的单词。连续使用时，进行多光标选择，选中下一个同名单词。Ctrl+K 配合Ctrl+D可以跳过下一个同名单词。使用Ctrl+U进行回退，使用Esc退出多重编辑Ctrl + [ 向左缩进Ctrl + ] 向右缩进Ctrl+Shift+V 可以以当前缩进粘贴代码Shift+Tab 当前位置向左缩进","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Sublime","slug":"Sublime","permalink":"http://example.com/tags/Sublime/"}]},{"title":"常用开发环境 Linux","slug":"Tools-Linux","date":"2018-09-18T07:09:12.000Z","updated":"2022-09-30T09:41:40.000Z","comments":true,"path":"2018/09/18/Tools-Linux/","link":"","permalink":"http://example.com/2018/09/18/Tools-Linux/","excerpt":"使用最多的开发环境 linux基础 Linux是一个网络操作系统（Network Operating System，NOS）网络操作系统则在一般操作系统的功能上增加了网络功能，具体包括：（1）实现网络中各计算机之间的通信和资源共享；（2）提供多种网络服务软件；（3）提供网络用户的应用程序接口；（4）它是由以Linus Torvalds为首的一批Internet上的志愿者开发的，完全免费，并与著名的网络操作系统UNIX完全兼容，是一个具有很高性能价格比的网络操作系统；（5）由于开放源代码与良好的模块化设计，从而使嵌入式应用成为可能；","text":"使用最多的开发环境 linux基础 Linux是一个网络操作系统（Network Operating System，NOS）网络操作系统则在一般操作系统的功能上增加了网络功能，具体包括：（1）实现网络中各计算机之间的通信和资源共享；（2）提供多种网络服务软件；（3）提供网络用户的应用程序接口；（4）它是由以Linus Torvalds为首的一批Internet上的志愿者开发的，完全免费，并与著名的网络操作系统UNIX完全兼容，是一个具有很高性能价格比的网络操作系统；（5）由于开放源代码与良好的模块化设计，从而使嵌入式应用成为可能； linux目录配置linux目录配置 12345678910111213141516171819202122232425262728/bin ：存放用户一般使用程序，如ls，mv，rm等常用执行文件，有时内容与/usr/bin一样（使用链接文件）/boot ：在这个目录下存放的都是系统启动时要用到的程序。在使用grub或lilo引导linux的时候，会用到这里的一些信息/lost+found：系统产生异常错误时，会将一些遗失的片段放在该目录下/dev：dev 是设备（device）的英文缩写，这个目录对所有的用户都十分重要，因为在这个目录中包含了所有linux系统中使用的外部设备，但是这里并不是放的外部设备的驱动程序/etc ：etc这个目录是linux系统中最重要的目录之一。在这个目录下存放了系统管理时要用到的各种配置文件和子目录。我们要用到的网络配置文件，文件系统，x系统配置文件，设备配置信息，设置用户信息等都在这个目录下/etc/rc.d：这个路径主要在记录一些开关机过程中的 scripts 档案， scripts 有点像是DOS 下的批次档（.bat檔名）/etc/rc.d/init.d：所以服务预设的启动 scripts 都是放在这里的，例如要启动与关闭iptables 可以：/etc/rc.d/init.d/iptables start/etc/rc.d/init.d/iptables stop/etc/X11：这是与 X windows 有关的设定文件所在的目录，如XF86Config-4/sbin ：这个目录是用来存放系统管理员的系统管理程序，如fdisk，mke2fs，fsck等/home ：如果建立一个用户，用户名是“jl”,那么在/home目录下就有一个对应的/home/jl路径，用来存放用户的主目录/lib ：lib是库（library）英文缩写。这个目录是用来存放系统动态连接共享库的，几乎所有的应用程序都会用到这个目录下的共享库/mnt ：这个目录在一般情况下也是空的，可以临时将别的文件系统挂在这个目录下/proc ：可以在这个目录下获取系统信息，这些信息是在内存中，由系统自己产生的。/root ：如果用户是以超级用户的身份登录的，这个就是超级用户的主目录，设置成较高安全等级700/tmp ：用来存放不同程序执行时产生的临时文件。/usr ：这是linux系统中占用硬盘空间最大的目录，相当于windows下的program files目录/usr/bin：放置可执行程序，这个目录的档案与 /bin 几乎是相同的/usr/sbin：放置管理者使用程序，与 /sbin 类似的功能/usr/include：一些套件的头文件，以源代码形式安装程序时通常会用到/usr/lib：许多程序与子程序所需的函数库/usr/local：软件升级后常用的安装目录，可执行文件通常放在/usr/local/bin/usr/share/doc：系统说明文档/usr/share/man：man工具文档放在路径/usr/src：编译系统时，源代码存放的位置/var：系统中的可变文档的存放位置，例如日志文件，未读邮件等 linux权限1234567891011121314151617181920212223chown：改变文件拥有者chgrp：改变文件所属群组chmod：改变文件属性umask：改变预设的建立文件或目录属性chattr：改变文件的特殊属性lsattr：显示文件的特殊属性666: 用户建立文件时的默认属性为666（可读，可写不能执行）777: 用户建立目录的默认属性为777（可读，可执行）chattr 设置文件或目录的特殊属性-chattr [+-=] [ASacdistu] [文件或目录名]-+-=：增加、去除、设置属性-A：文件或目录的存取时间不能被修改-S：将数据同步写入到磁盘中，避免数据丢失-a：文件只能增加数据，不能被删除，限root使用-c：自动对文件使用压缩存储功能-d：使文件具有dump功能-i：使文件不能被删除、更名、设定硬链接，写入数据-j：当使用ext3时，使文件在写入时先记录在日志中-s：文件会被完全移出硬盘-u：与s相反，可以取消删除操作lsattr [-aR] 显示文件的特殊属性-a：将隐藏文件的属性显示-R：连同子目录的数据一同显示 搜索文件或目录123whereis：查看文件的位置locate：配合数据库查看文件位置find：实际搜寻硬盘查询文件名称 linux操作12345678910111213141516171819202122d: 剪切p: 粘贴^C 输入中断mkdir 创建文件夹cd 打开文件夹cd ~ 回到根目录cd xx/xx 打开xx 下的xxx文件夹cd ../.. 返回两层文件夹cd .. 返回一层文件夹df -h 列出当前磁盘占用情况ln -s /home9/luna.xiong/test/jen/ /home9/luna.xiong/cmtool/aaa..doc 创建软连接ln -s&lt;空格&gt;目标文件夹&lt;空格&gt;快捷方式文件名 创建软连接cp abc abc.sh 把abc 拷贝为abc.sh文件cat abc.sh 打开查看abc.sh文件vi abc.sh 编辑abc.sh文件touch text1.pl 在本目录下创建名为 test1 的perl文件echo aaaa 打印aaaaecho bbb &gt;&gt;/tmp/abc 重定向 输入grep a &lt;/tmp/abc fg 将后台任务进程调至前台继续运行，如果后台中有多个任务进程，可以用 fg %num 将选中的任务进程调至前台tail -f ~/test.log 从指定点开始将文件写到标准输出.使用tail命令的-f选项可以方便的查阅正在改变的日志文件,tail -f filename会把filename里最尾部的内容显示在屏幕上,并且不但刷新,使你看到最新的文件内容.deactivate 退出虚拟python环境 linux-ls123456ls -l 列出文件夹目录ls -ls 列出当前目录下的所有文件和子目录，包括隐藏文文件 (.git文件)ls -la 列出当前目录下的所有文件和子目录，不包括隐藏文文件ls -l |grep &quot;^-&quot;|wc -l或find ./company -type f | wc -l 查看某文件夹下文件的个数，包括子文件夹里的。ls -lR|grep &quot;^-&quot;|wc -l 查看某文件夹下文件夹的个数，包括子文件夹里的。ls -lR|grep &quot;^d&quot;|wc -l 将长列表输出信息过滤一部分只保留目录就是 ^d linux-du123456789101112131415161718-a 显示目录中个别文件的大小，每个文件或目录的大小都要显示出来，目录的大小是指的该目录下文件和子目录的总和；-S 显示目录大小的时候，不包含子目录的大小，只包含该目录下文件的总和；-s 仅显示该目录或者文件的总计，不显示其他子目录信息；-h 输出的大小按照人类可读的方式，例如K M G-t 设置阈值，+20M大于20M的文件，-20M小于20M的文件；du [-abcDhHklmsSx] file_pathdf -lh 查看当前磁盘的使用情况du -sh 显示当前文件夹总计内存占用情况du -sh xxxx/ xxxx文件夹的内存占用情况du -lh --max-depth=1 查看当前目录下一级子文件和子目录占用的磁盘容量。du -sh 查看当前目录总共占的容量。而不单独列出各子项占用的容量du -sh * | sort -n 统计当前文件夹(目录)大小，并按文件大小排序du -s * | sort -nr | head 选出排在前面的10个du -s * | sort -nr | tail 选出排在后面的10个du -sk filename 查看指定文件大小du --max-depth=1 -h 查看当前目录下文件大小du -ahS test_dir 显示test_dir文件夹下的文件（包含目录）的大小；du -aS -t -4K file_path linux-sort1234567-r 以相反的顺序进行排序；（默认是升序）-n 按照数值的大小进行排序；（默认是ASCII码值）-u 忽略相同的行；-h 按照人类可读的方式排序，例如100K &lt; 2M &lt; 1Gsort [-bcdfimMnr] filesort testfilesort -rnu testfile 按照数值大小逆序且去重复项输出 linux-find1234567891011121314151617181920212223242526272829find path -option [-print ] [ -exec -ok command ] &#123;&#125; [\\]find . -print 列出给定目录下所有的文件和子目录-print选项使用\\n（换行符）分隔输出的每个文件或目录名。-print0选项则使用空字符’\\0’来分隔。find / &#x27;*.txt&#x27; -print 查找所有扩展名为txt的文件find . -type f -atime -3 -print 打印出在最近3天内被访问过的所有文件find . -type f -atime 3 -print 打印出恰好在3天前被访问过的所有文件。find . -type f -atime +3 -print 打印出访问时间超过3天的所有文件find . -name &quot;*.c&quot; 查找当前目录及其子目录下所有延伸的文件名称是 c 的文件find . -name &quot;tmp_pack_*&quot; 查找当前及子目录下以tmp_pack_开头的文件find . -type f -name &quot;tmp_*&quot; | cut -c3- | xargs du -sh 查找当前文件夹下及子文件夹内某个名字的文件名及路径及大小find . -type f -name &quot;tmp_*&quot; | cut -c3- | xargs du -sh | sort -nr 查找当前文件夹下及子文件夹内文件名及路径及大小 按数字排序find . -type f -name &quot;tmp_*&quot; | cut -c3- | xargs du -s | sort -nr 查找当前文件夹下及子文件夹内文件名及路径及大小 按大小排序 大到小find . -type f -name &quot;tmp_*&quot; | cut -c3- | xargs du -s | sort -n 查找当前文件夹下及子文件夹内文件名及路径及大小 按大小排序 小到大find ./ -name &quot;*.so&quot; -exec ls -l &#123;&#125; \\ 实现在当前目录以及所有子目录下找出后缀名为so的文件，并显示其详细信息find /root -size -5557c -size +5555c -exec ls -ld &#123;&#125; \\; 查找大于5555字节小于5557字节的文件，以上查找的是/root 目录find /root -size -500k -size +50k -exec ls -ld &#123;&#125; \\; 查找 小于500K，大于50K的文件find . -type f|xargs du -ahS 2&gt;/dev/null|sort -rh|head -1 找到当前文件夹下最大的文件find . -name builds -prune -o -name &#x27;config.xml&#x27; -print | xargs grep -nr --color &quot;UpdateKey.sh&quot; 查找文件UpdateKey.sh在jenkins里面哪个job用到了find ./ -type d -ok ls &#123;&#125; \\ 查找目录并列出目录下的文件 为找到的每一个目录单独执行ls命令,执行命令前需要确认find . -ctime -20 将目前目录及其子目录下所有最近 20 天内更新过的文件列出find . -type f -size +10M -exec ls -l &#123;&#125; \\ 查找当前目录以及子目录中所有文件大于10M的普通文件，并列出它们的完整路径find /var/logs -type f -mtime +7 -ok rm &#123;&#125; \\ 查找/var/logs目录中更改时间在7日以前的普通文件，并在删除之前询问它们find . -type f -name &quot;*.log&quot; -print0 | xargs -0 rm -f rm 删除太多的文件时候 解决/bin/rm Argument list too long.find . -type f -name &quot;*.php&quot; -print0 | xargs -0 wc -l 统计一个源代码目录中所有php文件的行数find . -type f -name &quot;*.jpg&quot; -print | xargs tar -czvf images.tar.gz 查找所有的jpg 文件，并且压缩它们find . -type f|xargs du -ahS 2&gt;/dev/null|sort -rh|head -1 找到当前文件夹下最大的文件find . -name &quot;*.log&quot;|xargs grep -o Exception|wc -l 统计当前文件夹下面的所有日志文件（.log文件）中Exception出现的次数 linux-xargs12345678xargs -0 将\\0作为定界符。cat test.txt | xargs 将多行的test.txt文件转换为单行输出cat test.txt | xargs -n3 将多行的test.txt文件转换为3列多行输出echo &quot;nameXnameXnameXname&quot; | xargs -dX 定义界定符号X 输出 name name name name echo &quot;nameXnameXnameXname&quot; | xargs -dX -n2 定义界定符号X 2列多行输出 name name name name cat arg.txt | xargs -I &#123;&#125; ./sk.sh -p &#123;&#125; -l ---------ls *.jpg | xargs -n1 -I cp &#123;&#125; /data/images 复制所有图片文件到 /data/images 目录下cat url-list.txt | xargs wget -c 有一个文件包含了很多你希望下载的URL，使用xargs下载所有链接 linux-wc12345678-c 或 –bytes 只显示bytes数-l 或者 –lines 只显示行数-w 或者 –words 只显示单词数wc [-clw] [file…]wc testfile 缺省参数将输出 指定文件的 行数、单词数、字节（符）数wc -l testfile 统计指定文件的行数linux-cut","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"}]},{"title":"电脑基本操作 Windows","slug":"Tools-Win","date":"2018-09-18T07:09:12.000Z","updated":"2023-05-25T08:22:50.827Z","comments":true,"path":"2018/09/18/Tools-Win/","link":"","permalink":"http://example.com/2018/09/18/Tools-Win/","excerpt":"","text":"Win10使用小技巧 Win10任务栏居中显示 Win10好用的30个软件推荐 Win10设置合上盖子不休眠-外置显示器/远程控制 Windows快捷键大全，是指在Windows操作系统下，操作电脑的键盘快捷方式 win+E 资源管理器 // 常用文件夹 win+R 运行 win+Tab 切换桌面 // 切换任务 win+Z 打开程序 win+D 退出 win+l 锁屏 win+v 打开剪切板 win+i 打开windows win+shift+s 截图 Alt+Tab 切换上一个任务 in+Q/S 启动开始栏查询框 Ctrl+W 关闭当前窗口 WIN+R12345678910mstsc //远程桌面calc //启动计算器appwiz.cpl //程序和功能certmgr.msc //证书管理实用程序charmap //启动字符映射表chkdsk.exe //Chkdsk磁盘检查(管理员身份运行命令提示符)cleanmgr: //打开磁盘清理工具cliconfg //SQL SERVER 客户端网络实用工具cmstp： //连接管理器配置文件安装程序cmd.exe： //CMD命令提示符 自动关机命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100Shutdown -s -t 600： // 表示600秒后自动关机shutdown -a ： // 可取消定时关机Shutdown -r -t 600： // 表示600秒后自动重启rundll32 user32.dll,LockWorkStation： //表示锁定计算机colorcpl： // 颜色管理，配置显示器和打印机等中的色彩CompMgmtLauncher： // 计算机管理compmgmt.msc： // 计算机管理credwiz： // 备份或还原储存的用户名和密码comexp.msc： // 打开系统组件服务control： // 控制面版dcomcnfg： // 打开系统组件服务Dccw： // 显示颜色校准devmgmt.msc： // 设备管理器desk.cpl： // 屏幕分辨率dfrgui： // 优化驱动器 Windows 7→dfrg.msc：磁盘碎片整理程序dialer： // 电话拨号程序diskmgmt.msc： // 磁盘管理dvdplay： // DVD播放器dxdiag： // 检查DirectX信息eudcedit： // 造字程序eventvwr： // 事件查看器explorer： // 打开资源管理器Firewall.cpl： // Windows防火墙FXSCOVER： // 传真封面编辑器fsmgmt.msc： // 共享文件夹管理器gpedit.msc： // 组策略hdwwiz.cpl： // 设备管理器inetcpl.cpl： // Internet属性intl.cpl： // 区域iexpress： // 木马捆绑工具，系统自带joy.cpl： // 游戏控制器logoff： // 注销命令lusrmgr.msc： // 本地用户和组lpksetup： // 语言包安装/删除向导，安装向导会提示下载语言包lusrmgr.msc： // 本机用户和组main.cpl： // 鼠标属性mmsys.cpl： // 声音magnify： // 放大镜实用程序mem.exe： // 显示内存使用情况(如果直接运行无效，可以先管理员身份运行命令提示符在命令提示符里输入mem.exe&gt;d:a.txt // 即可打开d盘查看a.txt，里面的就是内存使用情况了。当然什么盘什么文件名可自己决定。)MdSched:Windows // 内存诊断程序mmc： // 打开控制台mobsync： // 同步命令mplayer2： // 简易widnows media playerMsconfig.exe： // 系统配置实用程序msdt： // 微软支持诊断工具msinfo32： // 系统信息mspaint： // 画图Msra： // Windows远程协助mstsc： // 远程桌面连接NAPCLCFG.MSC： // 客户端配置ncpa.cpl： // 网络连接narrator： // 屏幕“讲述人”Netplwiz： // 高级用户帐户控制面板，设置登陆安全相关的选项netstat : // an(TC)命令检查接口notepad： // 打开记事本Nslookup： // IP地址侦测器odbcad32： // ODBC数据源管理器OptionalFeatures： // 打开“打开或关闭Windows功能”对话框osk： // 打开屏幕键盘perfmon.msc： // 计算机性能监测器perfmon： // 计算机性能监测器PowerShell： // 提供强大远程处理能力printmanagement.msc： // 打印管理powercfg.cpl： // 电源选项psr： // 问题步骤记录器Rasphone： // 网络连接Recdisc： // 创建系统修复光盘Resmon： // 资源监视器Rstrui： // 系统还原regedit.exe： // 注册表regedt32： // 注册表编辑器rsop.msc： // 组策略结果集sdclt： // 备份状态与配置，就是查看系统是否已备份secpol.msc： // 本地安全策略services.msc： // 本地服务设置sfc /scannow： // 扫描错误并复原/windows文件保护sfc.exe： // 系统文件检查器shrpubw： // 创建共享文件夹sigverif： // 文件签名验证程序slui： // Windows激活，查看系统激活信息slmgr.vbs -dlv ： // 显示详细的许可证信息snippingtool： // 截图工具，支持无规则截图soundrecorder： // 录音机，没有录音时间的限制StikyNot： // 便笺 sysdm.cpl： // 系统属性sysedit： // 系统配置编辑器syskey： // 系统加密，一旦加密就不能解开，保护系统的双重密码taskmgr： // 任务管理器(旧版)TM // 任务管理器(新版)taskschd.msc： // 任务计划程序timedate.cpl： // 日期和时间UserAccountControlSettings // 用户账户控制设置utilman： // 辅助工具管理器wf.MSC： // 高级安全Windows防火墙WFS： // Windows传真和扫描wiaacmgr： // 扫描仪和照相机向导winver： // 关于Windowswmimgmt.msc： // 打开windows管理体系结构(WMI)write： // 写字板 文件扩展名对应的文件类型12345678910111213141516171819202122232425262728293031323334353637383940414243常用扩展名文本文件 .docx Microsoft Open Word XML Document .doc Microsoft Word Document .txt Plain Text File .rtf Revit Family Template File .odt OpenOffice/StarOffice File音频文件 .mp3 MP3 Audio File .wav Wave Audio File .aac MPEG-2 Advanced Audio Coding File .wma Windows Media Audio File .m4a MPEG-4 Audio File数据文件 .pdf Portable Document Format File .xls Excel Spreadsheet File .csv Comma Separated Values File .ini Initialization/Configuration File .html Hypertext Markup Language File压缩文件 .zip ZIP File .rar WinRAR Compressed Archive ..7z Compressed File .tar Consolidated Unix File Archive .gz GNU Zipped Archive File视频文件 .avi Audio Video Interleave File .mp4 MPEG-4 Video File .mov Video Clip .flv Video File .mpg MPEG 1 System Stream可执行文件 .exe Windows Executable File .msi Windows Installer File .bin Binary Disc Image .app Punch Post .dmg Disk Copy Disk Image File .sh 脚本文件 可直接執行 补充扩展名 .sh: .bak: 备份文件 .pl: perl文件 .py: python文件","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Windows","slug":"Windows","permalink":"http://example.com/tags/Windows/"}]},{"title":"面试基础 interview","slug":"Tools-Interview","date":"2018-09-18T07:09:12.000Z","updated":"2022-09-30T08:27:08.000Z","comments":true,"path":"2018/09/18/Tools-Interview/","link":"","permalink":"http://example.com/2018/09/18/Tools-Interview/","excerpt":"通往机器学习算法工程师的进阶之路是崎岖险阻的。《线性代数》 《统计学习方法》《机器学习》《模式识别》《深度学习》，以及《颈椎病康复指南》，这些书籍将长久地伴随着你的工作生涯。除了拥有全面、有条理的知识储备，想成为一名优秀的算法工程师，更重要的是对算法模型有着发自心底的热忱，对研究工作有一种匠心精神。这种匠心精神，直白来讲，可以概括为：发现问题的眼光、解决问题的探索精神，以及对问题究原竟委的执着追求","text":"通往机器学习算法工程师的进阶之路是崎岖险阻的。《线性代数》 《统计学习方法》《机器学习》《模式识别》《深度学习》，以及《颈椎病康复指南》，这些书籍将长久地伴随着你的工作生涯。除了拥有全面、有条理的知识储备，想成为一名优秀的算法工程师，更重要的是对算法模型有着发自心底的热忱，对研究工作有一种匠心精神。这种匠心精神，直白来讲，可以概括为：发现问题的眼光、解决问题的探索精神，以及对问题究原竟委的执着追求 特征工程 结构化数据结构化数据类型可以看作关系型数据库的一张表，每列都有清晰的定义，包含了数值型、类别型两种基本类型；每一行数据表示一个样本的信息 非结构化数据。非结构化数据主要包括文本、图像、音频、视频数据，其包含的信息无法用一个简单的数值表示，也没有清晰的类别定义，并且每条数据的大小各不相同特征归一化为了消除数据特征之间的量纲影响，我们需要对特征进行归一化处理，使得不同指标之间具有可比性。例如，分析一个人的身高和体重对健康的影响，如果使用米（m）和千克（kg）作为单位，那么身高特征会在1.6～1.8m的数值范围内，体重特征会在50～100kg的范围内，分析出来的结果显然会倾向于数值差别比较大的体重特征。想要得到更为准确的结果，就需要进行特征归一化（Normalization）处理，使各指标处于同一数值量级，以便进行分析 数字特征归一化 线性函数归一化（Min-Max Scaling）它对原始数据进行线性变换，使结果映射到[0, 1]的范围，实现对原始数据的等比缩放$$X_{norm} = \\frac{X-X_{min}}{X_{max}-X_{min}}$$1其中X为原始数据，X max 、X min 分别为数据最大值和最小值 零均值归一化（Z-Score Normalization）它会将原始数据映射到均值为0、标准差为1的分布上。具体来说，假设原始特征的均值为μ、标准差为σ$$z=\\frac{x-\\mu}{\\sigma}$$ 类别特征类别型特征（Categorical Feature）主要是指性别（男、女）、血型（A、B、AB、O）等只在有限选项内取值的特征。类别型特征原始输入通常是字符串形式，除了决策树等少数模型能直接处理字符串形式的输入，对于逻辑回归、支持向量机等模型来说，类别型特征必须经过处理转换成数值型特征才能正确工作 序号编码（Ordinal Encoding）序号编码通常用于处理类别间具有大小关系的数据。例如成绩，可以分为低、中、高三档，并且存在“高&gt;中&gt;低”的排序关系。序号编码会按照大小关系对类别型特征赋予一个数值ID，例如高表示为3、中表示为2、低表示为1，转换后依然保留了大小关系 独热编码（One-hot Encoding）独热编码通常用于处理类别间不具有大小关系的特征。例如血型，一共有4个取值（A型血、B型血、AB型血、O型血），独热编码会把血型变成一个4维稀疏向量，A型血表示为（1, 0, 0, 0），B型血表示为（0, 1, 0, 0），AB型表示为（0, 0,1, 0），O型血表示为（0, 0, 0, 1）。对于类别取值较多的情况下使用独热编码需要注意以下问题 使用稀疏向量来节省空间。在独热编码下，特征向量只有某一维取值为1，其他位置取值均为0。因此可以利用向量的稀疏表示有效地节省空间，并且目前大部分的算法均接受稀疏向量形式的输入 配合特征选择来降低维度。高维度特征会带来几方面的问题。一是在K近邻算法中，高维空间下两点之间的距离很难得到有效的衡量；二是在逻辑回归模型中，参数的数量会随着维度的增高而增加，容易引起过拟合问题；三是通常只有部分维度是对分类、预测有帮助，因此可以考虑配合特征选择来降低维度 二进制编码（Binary Encoding） 二进制编码主要分为两步，先用序号编码给每个类别赋予一个类别ID，然后将类别ID对应的二进制编码作为结果。 以A、B、AB、O血型为例，表1.1是二进制编码的过程。A型血的ID为1，二进制表示为001；B型血的ID为2，二进制表示为010；以此类推可以得到AB型血和O型血的二进制表示。可以看出，二进制编码本质上是利用二进制对ID进行哈希映射，最终得到0/1特征向量，且维数少于独热编码，节省了存储空间高维组合特征的处理 什么是组合特征为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征。以广告点击预估问题为例，原始数据有语言和类型两种离散特征，已知语言和类型对点击的影响 为了提高拟合能力，语言和类型可以组成二阶特征以逻辑回归为例，假设数据的特征向量为X=(x 1 ,x 2 ,…,x k )，则有$$Y=sigmoid(\\sum_i\\sum_jw_{ij}&lt;x_i,xj&gt;)$$ 其中&lt;x i , x j &gt;表示x i 和x j 的组合特征，w_ij 的维度等于|x i |·|x j |，|x i |和|x j |分别代表第i个特征和第j个特征不同取值的个数。在表1.3的广告点击预测问题中，w的维度是2×2=4（语言取值为中文或英文两种、类型的取值为电影或电视剧两种）。这种特征组合看起来是没有任何问题的，但当引入ID类型的特征时，问题就出现了。以推荐问题为例 可以由用户ID和物品ID对点击的影响得出用户ID和物品ID的组合特征对点击的影响 若用户的数量为m、物品的数量为n，那么需要学习的参数的规模为m×n。在互联网环境下，用户数量和物品数量都可以达到千万量级，几乎无法学习m×n规模的参数。在这种情况下，一种行之有效的方法是将用户和物品分别用k维的低维向量表示（k&lt;&lt;m,k&lt;&lt;n）$$Y=sigmoid(\\sum_i\\sum_jw_{ij}&lt;x_i,xj&gt;)$$ 其中$$w_{ij} = x’_i*x’_j$$x’分别表示x i 和x j 对应的低维向量。推荐问题中，需要学习的参数的规模变为m×k+n×k。熟悉推荐算法的同学很快可以看出来，这其实等价于矩阵分解。所以，这里也提供了另一个理解推荐系统中矩阵分解的思路 文本表示模型文本是一类非常重要的非结构化数据，如何表示文本数据一直是机器学习领域的一个重要研究方向 词袋模型（Bag of Words）TF - IDF（Term Frequency-Inverse Document Frequency） 最基础的文本表示模型是词袋模型。顾名思义，就是将每篇文章看成一袋子词，并忽略每个词出现的顺序。具体地说，就是将整段文本以词为单位切分开，然后每篇文章可以表示成一个长向量，向量中的每一维代表一个单词，而该维对应的权重则反映了这个词在原文章中的重要程度。常用TF-IDF来计算权重$$TF-IDF(t,d)=TF(t,d)*IDF(t)$$ 其中TF(t,d)为单词t在文档d中出现的频率，IDF(t)是逆文档频率，用来衡量单词t对表达语义所起的重要性，表示为$$IDF(t)=log\\frac{文章总数}{包含单词t的文章总数+1}$$ 直观的解释是，如果一个单词在非常多的文章里面都出现，那么它可能是一个比较通用的词汇，对于区分某篇文章特殊语义的贡献较小，因此对权重做一定惩罚 将文章进行单词级别的划分有时候并不是一种好的做法，比如英文中的natural language processing（自然语言处理）一词，如果将natural，language，processing这3个词拆分开来，所表达的含义与三个词连续出现时大相径庭。通常，可以将连续出现的n个词（n≤N）组成的词组（N-gram）也作为一个单独的特征放到向量表示中去，构成N-gram模型。另外，同一个词可能有多种词性变化，却具有相似的含义。在实际应用中，一般会对单词进行词干抽取（Word Stemming）处理，即将不同词性的单词统一成为同一词干的形式 主题模型（Topic Model） 主题模型用于从文本库中发现有代表性的主题（得到每个主题上面词的分布特性），并且能够计算出每篇文章的主题分布 词嵌入模型（Word Embedding） 词嵌入是一类将词向量化的模型的统称，核心思想是将每个词都映射成低维空间（通常K=50～300维）上的一个稠密向量（Dense Vector）。K维空间的每一维也可以看作一个隐含的主题，只不过不像主题模型中的主题那样直观。Word2Vec谷歌2013年提出的Word2Vec是目前最常用的词嵌入模型之一。Word2Vec实际是一种浅层的神经网络模型，它有两种网络结构，分别是CBOW（Continues Bag of Words）和Skip-gram Word2Vec 隐狄利克雷模型（LDA） CBOW Skip-gram 图像数据不足时的处理在机器学习中，绝大部分模型都需要大量的数据进行训练和学习（包括有监督学习和无监督学习），然而在实际应用中经常会遇到训练数据不足的问题。比如图像分类，作为计算机视觉最基本的任务之一，其目标是将每幅图像划分到指定类别集合中的一个或多个类别中。当训练一个图像分类模型时，如果训练样本比较少，该如何处理呢 迁移学习（Transfer Learning），生成对抗网络，图像处理，上采样技术，数据扩充 在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？ 一定程度内的随机旋转、平移、缩放、裁剪、填充、左右翻转等，这些变换对应着同一个目标在不同角度的观察结果 对图像中的像素添加噪声扰动，比如椒盐噪声、高斯白噪声等 颜色变换。例如，在图像的RGB颜色空间上进行主成分分析，得到3个主成分的特征向量p 1 ,p 2 ,p 3 及其对应的特征值 λ 1 ,λ 2 ,λ 3 ，然后在每个像素的RGB值上添加增量[p 1 ,p 2 ,p 3 ]•[α 1 λ 1 ,α 2 λ 2 ,α 3 λ 3 ] T ，其中 α 1 ,α 2 ,α 3 是均值为0、方差较小的高斯分布随机数 改变图像的亮度、清晰度、对比度、锐度等 模型评估评估指标的局限性在模型评估过程中，分类问题、排序问题、回归问题往往需要使用不同的指标进行评估。在诸多的评估指标中，大部分指标只能片面地反映模型的一部分性能。如果不能合理地运用评估指标，不仅不能发现模型本身的问题，而且会得出错误的结论 准确率（Accuracy） 准确率的局限性 准确率是分类问题中最简单也是最直观的评价指标，但存在明显的缺陷。比如，当负样本占99%时，分类器把所有样本都预测为负样本也可以获得99%的准确率。所以，当不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素 可以使用更为有效的平均准确率（每个类别下的样本准确率的算术平均）作为模型评估的指标 精确率（Precision） 精确率与召回率的权衡 召回率（Recall） 均方根误差（Root Mean Square Error，RMSE） ROC曲线二值分类器（Binary Classifier）是机器学习领域中最常见也是应用最广泛的分类器。评价二值分类器的指标很多，比如precision、recall、F1 score、P-R曲线等。上一小节已对这些指标做了一定的介绍，但也发现这些指标或多或少只能反映模型在某一方面的性能。相比而言，ROC曲线则有很多优点，经常作为评估二值分类器最重要的指标之一 ROC曲线 ROC曲线是Receiver Operating Characteristic Curve的简称，中文名为“受试者工作特征曲线”。ROC曲线源于军事领域，而后在医学领域应用甚广，“受试者工作特征曲线”这一名称也正是来自于医学领域。 ROC曲线的横坐标为假阳性率（False Positive Rate，FPR）；纵坐标为真阳性率（True Positive Rate，TPR）。FPR和TPR的计算方法分别为$$FPR=\\frac{FP}{N}$$ $$TPR = \\frac{TP}{P}$$ P是真实的正样本的数量 N是真实的负样本的数量 TP是P个正样本中被分类器预测为正样本的个数 FP是N个负样本中被分类器预测为正样本的个数 EG.假设有10位疑似癌症患者，其中有3位很不幸确实患了癌症（P=3），另外7位不是癌症患者（N=7）。医院对这10位疑似患者做了诊断，诊断出3位癌症患者，其中有2位确实是真正的患者（TP=2）。那么真阳性率TPR=TP/P=2/3。对于7位非癌症患者来说，有一位很不幸被误诊为癌症患者（FP=1），那么假阳性率FPR=FP/N=1/7。对于“该医院”这个分类器来说，这组分类结果就对应ROC曲线上的一个点（1/7，2/3） 曲线下的面积（Aera Under Curve，AUC） 如何计算AUC AUC指的是ROC曲线下的面积大小，该值能够量化地反映基于ROC曲线衡量出的模型性能。计算AUC值只需要沿着ROC横轴做积分就可以了。由于ROC曲线一般都处于y=x这条直线的上方（如果不是的话，只要把模型预测的概率反转成1−p就可以得到一个更好的分类器），所以AUC的取值一般在0.5～1之间。AUC越大，说明分类器越可能把真正的正样本排在前面，分类性能越好 ROC曲线相比P-R曲线有什么特点？ 同样被经常用来评估分类和排序模型的还有P-R曲线。相比P-R曲线，ROC曲线有一个特点，当正负样本的分布发生变化时，ROC曲线的形状能够基本保持不变，而P-R曲线的形状一般会发生较剧烈的变化而ROC曲线形状基本不变。这个特点让ROC曲线能够尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能。 在很多实际问题中，正负样本数量往往很不均衡。比如，计算广告领域经常涉及转化率模型，正样本的数量往往是负样本数量的1/1000甚至1/10000。若选择不同的测试集，P-R曲线的变化就会非常大，而ROC曲线则能够更加稳定地反映模型本身的好坏。所以，ROC曲线的适用场景更多，被广泛用于排序、推荐、广告等领域。但需要注意的是，选择P-R曲线还是ROC曲线是因实际问题而异的，如果研究者希望更多地看到模型在特定数据集上的表现，P-R曲线则能够更直观地反映其性能。 P-R曲线 余弦距离的应用机器学习问题中，通常将特征表示为向量的形式，所以在分析两个特征向量之间的相似性时，常使用余弦相似度来表示。余弦相似度的取值范围是[−1,1]，相同的两个向量之间的相似度为1。如果希望得到类似于距离的表示，将1减去余弦相似度即为余弦距离。因此，余弦距离的取值范围为[0,2]，相同的两个向量余弦距离为0。 余弦相似度 为什么在一些场景中要使用余弦相似度而不是欧氏距离？ 对于两个向量A和B，其余弦相似度定义为$$cos(A,B) = \\frac{A·B}{||A||_2||B||_2}$$即两个向量夹角的余弦，关注的是向量之间的角度关系，并不关心它们的绝对大小，其取值范围是[−1,1]。当一对文本相似度的长度差距很大、但内容相近时，如果使用词频或词向量作为特征，它们在特征空间中的的欧氏距离通常很大；而如果使用余弦相似度的话，它们之间的夹角可能很小，因而相似度高。此外，在文本、图像、视频等领域，研究的对象的特征维度往往很高，余弦相似度在高维情况下依然保持“相同时为1，正交时为0，相反时为−1”的性质，而欧氏距离的数值则受维度的影响，范围不固定，并且含义也比较模糊 余弦距离 欧氏距离 在一些场景，例如Word2Vec中，其向量的模长是经过归一化的，此时欧氏距离与余弦距离有着单调的关系$$||A-B||_2 = \\sqrt{2(1-cos(A,B))}$$ || A−B || 2 表示欧氏距离 cos(A,B)表示余弦相似度 (1−cos(A,B))表示余弦距离 在此场景下，如果选择距离最小（相似度最大）的近邻，那么使用余弦相似度和欧氏距离的结果是相同的 总体来说，欧氏距离体现数值上的绝对差异，而余弦距离体现方向上的相对差异。例如，统计两部剧的用户观看行为，用户A的观看向量为(0,1)，用户B为(1,0)；此时二者的余弦距离很大，而欧氏距离很小；我们分析两个用户对于不同视频的偏好，更关注相对差异，显然应当使用余弦距离。而当我们分析用户活跃度，以登陆次数(单位：次)和平均观看时长(单位：分钟)作为特征时，余弦距离会认为(1,10)、(10,100)两个用户距离很近；但显然这两个用户活跃度是有着极大差异的，此时我们更关注数值绝对差异，应当使用欧氏距离 距离的定义：在一个集合中，如果每一对元素均可唯一确定一个实数，使得三条距离公理（正定性，对称性，三角不等式）成立，则该实数可称为这对元素之间的距离 余弦距离是否是一个严格定义的距离？ 余弦距离满足正定性和对称性，但是不满足三角不等式，因此它并不是严格定义的距离 正定性根据余弦距离的定义：$$dist(A,B)=1-cos\\theta=\\frac{||A||_2||B||_2-AB}{||A||_2||B||_2}$$ $$考虑到||A||_2||B||_2\\geq0因此有dist(A,B)\\geq0恒成立 特别的 有：$$ $$dist(A,B)=0 \\leftrightarrow||A||_2||B||_2=AB\\leftrightarrow A=B$$ 因此余弦距离满足正定性 对称性 根据余弦距离的定义：$$dist(A,B)=\\frac{||A||_2||B||_2-AB}{||A||_2||B||_2}=\\frac{||B||_2||A||_2-AB}{||B||_2||A||_2}=dist(B,A)$$ 因此余弦距离满足对称性 - 三角不等式 不成立 反例： $$ dist(A,B)=1-\\frac&#123;\\sqrt&#123;2&#125;&#125;&#123;2&#125; $$ $$ dist(B,C)=1-\\frac&#123;\\sqrt&#123;2&#125;&#125;&#123;2&#125; $$ $$ dist(A,C)=1 $$ $$ dist(A,B)+dist(B,C)=2-\\sqrt&#123;2&#125;&lt;1=dist(A,C) $$ A/B测试的陷阱在互联网公司中，A/B 测试是验证新模块、新功能、新产品是否有效，新算法、新模型的效果是否有提升，新设计是否受到用户欢迎，新更改是否影响用户体验的主要测试方法。在机器学习领域中，A/B 测试是验证模型最终效果的主要手段 A/B测试 在对模型进行过充分的离线评估之后，为什么还要进行在线A/B测试？ 离线评估无法完全消除模型过拟合的影响，因此，得出的离线评估结果无法完全替代线上评估结果 离线评估无法完全还原线上的工程环境。一般来讲，离线评估往往不会考虑线上环境的延迟、数据丢失、标签数据缺失等情况。因此，离线评估的结果是理想工程环境下的结果 线上系统的某些商业指标在离线评估中无法计算。离线评估一般是针对模型本身进行评估，而与模型相关的其他指标，特别是商业指标，往往无法直接获得。比如，上线了新的推荐算法，离线评估往往关注的是ROC曲线、P-R曲线等的改进，而线上评估可以全面了解该推荐算法带来的用户点击率、留存时长、PV访问量等的变化。这些都要由A/B测试来进行全面的评估 如何进行线上A/B测试？ 进行A/B测试的主要手段是进行用户分桶，即将用户分成实验组和对照组，对实验组的用户施以新模型，对对照组的用户施以旧模型。在分桶的过程中，要注意样本的独立性和采样方式的无偏性，确保同一个用户每次只能分到同一个桶中，在分桶过程中所选取的user_id需要是一个随机数，这样才能保证桶中的样本是无偏的 实验组 对照组 模型评估的方法在机器学习中，我们通常把样本分为训练集和测试集，训练集用于训练模型，测试集用于评估模型。在样本划分和模型验证的过程中，存在着不同的抽样方法和验证方法 超参数调优 超参数有哪些调优方法 为了进行超参数调优，我们一般会采用网格搜索、随机搜索、贝叶斯优化等算法。在具体介绍算法之前，需要明确超参数搜索算法一般包括哪几个要素。一是目标函数，即算法需要最大化/最小化的目标；二是搜索范围，一般通过上限和下限来确定；三是算法的其他参数，如搜索步长 网格搜索 网格搜索可能是最简单、应用最广泛的超参数搜索算法，它通过查找搜索范围内的所有的点来确定最优值。如果采用较大的搜索范围以及较小的步长，网格搜索有很大概率找到全局最优值 然而，这种搜索方案十分消耗计算资源和时间，特别是需要调优的超参数比较多的时候 因此，在实际应用中，网格搜索法一般会先使用较广的搜索范围和较大的步长，来寻找全局最优值可能的位置；然后会逐渐缩小搜索范围和步长，来寻找更精确的最优值 这种操作方案可以降低所需的时间和计算量，但由于目标函数一般是非凸的，所以很可能会错过全局最优值 随机搜索 随机搜索的思想与网格搜索比较相似，只是不再测试上界和下界之间的所有值，而是在搜索范围中随机选取样本点 它的理论依据是，如果样本点集足够大，那么通过随机采样也能大概率地找到全局最优值，或其近似值。随机搜索一般会比网格搜索要快一些，但是和网格搜索的快速版一样，它的结果也是没法保证的 贝尔斯优化算法 贝叶斯优化算法通过对目标函数形状进行学习，找到使目标函数向全局最优值提升的参数。具体来说，它学习目标函数形状的方法是，首先根据先验分布，假设一个搜集函数 然后，每一次使用新的采样点来测试目标函数时，利用这个信息来更新目标函数的先验分布 最后，算法测试由后验分布给出的全局最值最可能出现的位置的点 一旦找到了一个局部最优值，它会在该区域不断采样，所以很容易陷入局部最优值。为了弥补这个缺陷，贝叶斯优化算法会在探索和利用之间找到一个平衡点，“探索”就是在还未取样的区域获取采样点；而“利用”则是根据后验分布在最可能出现全局最值的区域进行采样 过拟合与欠拟合在模型评估与调整的过程中，我们往往会遇到“过拟合”或“欠拟合”的情况。如何有效地识别“过拟合”和“欠拟合”现象，并有针对性地进行模型调整，是不断改进机器学习模型的关键。特别是在实际项目中，采用多种方法、从多个角度降低“过拟合”和“欠拟合”的风险是算法工程师应当具备的领域知识。 模型评估过程中，过拟合和欠拟合具体是指什么现象 过拟合是指模型对于训练数据拟合呈过当的情况，反映到评估指标上，就是模型在训练集上的表现很好，但在测试集和新数据上的表现较差 欠拟合指的是模型在训练和预测时表现都不好的情况 能否说出几种降低过拟合和欠拟合风险的方法 降低“过拟合”风险的方法 从数据入手，获得更多的训练数据。使用更多的训练数据是解决过拟合问题最有效的手段，因为更多的样本能够让模型学习到更多更有效的特征，减小噪声的影响。当然，直接增加实验数据一般是很困难的，但是可以通过一定的规则来扩充训练数据。比如，在图像分类的问题上，可以通过图像的平移、旋转、缩放等方式扩充数据；更进一步地，可以使用生成式对抗网络来合成大量的新训练数据。 降低模型复杂度。在数据较少时，模型过于复杂是产生过拟合的主要因素，适当降低模型复杂度可以避免模型拟合过多的采样噪声。例如，在神经网络模型中减少网络层数、神经元个数等；在决策树模型中降低树的深度、进行剪枝等。 正则化方法。给模型的参数加上一定的正则约束，比如将权值的大小加入到损失函数中。以L2正则化为例：$$C = C_0 +\\frac{\\lambda}{2n}*\\sum_iw_i^2$$这样，在优化原来的目标函数C 0 的同时，也能避免权值过大带来的过拟合风险 集成学习方法。集成学习是把多个模型集成在一起，来降低单一模型的过拟合风险，如Bagging方法经典算法 降低“欠拟合”风险的方法 添加新特征。当特征不足或者现有特征与样本标签的相关性不强时，模型容易出现欠拟合。通过挖掘“上下文特征”“ID类特征”“组合特征”等新的特征，往往能够取得更好的效果。在深度学习潮流中，有很多模型可以帮助完成特征工程，如因子分解机、梯度提升决策树、Deep-crossing等都可以成为丰富特征的方法。 增加模型复杂度。简单模型的学习能力较差，通过增加模型的复杂度可以使模型拥有更强的拟合能力。例如，在线性模型中添加高次项，在神经网络模型中增加网络层数或神经元个数等。 减小正则化系数。正则化是用来防止过拟合的，但当模型出现欠拟合现象时，则需要有针对性地减小正则化系数。 降维非监督学习概率图模型优化算法采样前向神经网络循环神经网络强化学习集成学习生成式对抗网络人工智能的热门应用","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Interview","slug":"Interview","permalink":"http://example.com/tags/Interview/"}]},{"title":"磨刀不误砍柴工 Tools","slug":"Tools","date":"2018-09-18T07:09:12.000Z","updated":"2023-05-25T08:22:47.931Z","comments":true,"path":"2018/09/18/Tools/","link":"","permalink":"http://example.com/2018/09/18/Tools/","excerpt":"一些些好用的工具合集","text":"一些些好用的工具合集 官方文档合集 Markdown语法官方文档 AWS服务器数据库AthenaSql官方文档 LabelStudio官方文档 Mmdetection官方文档 EXASOL官方文档 SQL SERVER官方文档 PostgreSQL官方文档 MYSQL官方文档 学习网站 古黑论 菜鸟教程 博客园 简书 CSDN 思否 码农家园 技术站点 Hacker News：非常棒的针对编程的链接聚合网站 [Programming reddit](Programming reddit)：同上MSDN：微软相关的官方技术集中地，主要是文档类infoq：企业级应用，关注软件开发领域OSChina：开源技术社区，开源方面做的不错哦cnblogs，51cto，csdn：常见的技术社区，各有专长stackoverflow：IT技术问答网站GitHub：全球最大的源代码管理平台，很多知名开源项目都在上面，如Linux内核，OpenStack等免费的it电子书：http://it-ebooks.info/DevStore:开发者服务商店 历史问题pycharmpythonPython 异常处理python-静态方法类方法属性方法python路径拼接os.path.join()Python3 try-except、raise和assert解析pandasPython之日志处理（logging模块）Python 多线程Python Jenkins APIPython 100例 crontable 定时指令服务端高并发分布式架构演进之路读取文件设置编码人工智能 小工具万能命令 //wn.run/http….迅捷助手火柴（原火萤酱） //（everthing WOX以及苹果自带的Spotlight 以及 Alfred)即书 // 一站式工作平台lconjar 2.0Pencil //基于AI智能系统来提供改造文案写作流程和故事构建提示，帮助你专注于写作。HabitLab // 戒网瘾工具-谷歌插件Writefull // 英语语法检测Alloy Timer // 番茄钟-腾讯 书籍人件人月神话代码大全2计算机程序设计艺术程序员的自我修养程序员修炼之道高效能程序员的修炼（成为一名杰出的程序员其实跟写代码没有太大关系）深入理解计算机系统软件随想录算法导论（麻省理工学院出版社）离线数学及其应用设计模式编程之美黑客与画家编程珠玑C++ PrimeEffective C++TCP/IP详解Unix 编程艺术《精神分析引论》弗洛伊德搞定：无压力工作的艺术平台工具（开源） Redmine/Trac：项目管理平台Jenkins/Jira(非开源)：持续集成系统（Apache Continuum，这个是Apache下的CI系统，还没来得及研究）Sonar：代码质量管理平台git，svn：源代码版本控制系统GitLib/Gitorious：构建自己的GitHub服务器gitbook写书的好东西，当然用来写文档也很不错的Travis-ci：开源项目持续集成必备，和GitHub相结合，https://travis-ci.org/开源测试工具、社区（Selenium、OpenQA.org）Puppet:一个自动管理引擎，可以适用于Linux、Unix以及Windows平台。所谓配置管理系统，就是管理机器里面诸如文件、用户、进程、软件包这些资源。无论是管理1台，还是上万台机器Puppet都能轻松搞定。Nagios：系统状态监控报警，还有个Icinga(完全兼容nagios所有的插件,工作原理,配置文件以及方法,几乎一模一样。配置简单,功能强大)Ganglia：分布式监控系统fleet：分布式init系统 爬虫相关(好玩的工具)PhantomjsberserkJS(基于Phantomjs的改进版本)SlimerJSCasperJSseleniumWeb 服务器性能/压力测试工具/负载均衡器http_load: 程序非常小，解压后也不到100Kwebbench: 是Linux下的一个网站压力测试工具，最多可以模拟3万个并发连接去测试网站的负载能力ab: ab是apache自带的一款功能强大的测试工具Siege: 一款开源的压力测试工具，可以根据配置对一个WEB站点进行多用户的并发访问，记录每个用户所有请求过程的相应时间，并在一定数量的并发访问下重复进行。squid（前端缓存），nginx（负载），nodejs（没错它也可以，自己写点代码就能实现高性能的负载均衡器）：常用的负载均衡器Piwik：开源网站访问量统计系统ClickHeat：开源的网站点击情况热力图HAProxy：高性能TCP /HTTP负载均衡器ElasticSearch：搜索引擎基于LucenePage Speed SDK和YSLOWHAR Viewer: HAR分析工具protractor：E2E（end to end）自动化测试工具 Web 前端相关GRUNT: js task runnerSea.js: js模块化knockout.js：MVVM开发前台，绑定技术Angular.js: 使用超动感HTML &amp; JS开发WEB应用！Highcharts.js，Flot:常用的Web图表插件Raw：非常不错的一款高级数据可视化工具Rickshaw:时序图标库，可用于构建实时图表JavaScript InfoVis Toolkit：另一款Web数据可视化插件Pdf.js，在html中展现pdfACE，CodeMirror：Html代码编辑器（ACE甚好啊）NProcess：绚丽的加载进度条impress.js：让你制作出令人眩目的内容展示效果(类似的还有reveal)Threejs：3DWeb库Hightopo：基于Html5的2D、3D可视化UI库jQuery.dataTables.js:高度灵活的表格插件Rapha?l：js，canvas绘图库，后来发现百度指数的图形就是用它绘出来的director.js：js路由模块，前端路由，Nodejs后端路由等，适合构造单页应用pace.js：页面加载进度条bower：Web包管理器jsnice：有趣的js反编译工具，猜压缩后的变量名 http://www.jsnice.org/D3.js: 是一个基于JavaScript数据展示库（类似的还有P5.js）Zepto.js：移动端替代jQuery的东东，当然也可以使用jquery-mobile.UI框架：Foundation，Boostrap，Pure，EasyUI，Polymer前端UI设计师必去的几个网站：Dribbble，awwwards，unmatchedstyle，UIMakerMozilla 开发者中心：https://developer.mozilla.org/en-US/图标资源：IcoMoon（我的最爱），Themify Icons，FreePik，GlyphiconsartDialog:非常漂亮的对话框AdminLTE：github上的一个开源项目，基于Boostrap3的后台管理页面框架Respond.js：让不懂爱的IE6-8支持响应式设计require.js: js模块加载库select2：比chosen具有更多特性的选择框替代库AngularUI：集成angular.js的UI库normalize.css: 采用了现代化标准让各浏览器渲染出的html保持一致的库CreateJS：Html5游戏引擎Less,Compass:简化CSS开发emojify.js:用于自动识别网页上的Emoji文字并将其显示为图像simditor:一个不错的开源的html编辑器，简洁高效Sencha: 基于html5的移动端开发框架SuperScrollorama+TweenMax+skrollr:打造超酷的视差滚动效果网页动画jquery-smooth-scroll:同上，平滑滚动插件Animate.css:实现了各种动画效果的css库Emmet:前端工程师必备，ZenCode的前身MagicDraw:Uml图工具大数据处理/数据分析/分布式工具Hadoop：分布式的文件系统，结合其MapReduce编程模型可以用来做海量数据的批处理（Hive，Pig，HBase啥的就不说了），值得介绍的是Cloudera的Hadoop分支CDH5，基于YARN MRv2集成了Spark可直接用于生产环境的Hadoop，对于企业快速构建数据仓库非常有用。Ceph:Linux分布式文件系统（特点：无中心）Storm：实时流数据处理，可以看下IBM的一篇介绍 （还有个Yahoo的S4，也是做流数据处理的）Spark：大规模流式数据处理（可以应付企业中常见的三种数据处理场景：复杂的批量数据处理（batch data processing）；基于历史数据的交互式查询（interactive query）；基于实时数据流的数据处理（streaming data processing）），CSND有篇文章介绍的不错Spark Streaming：基于Spark的实时计算框架Tachyon：分布式内存文件系统Mesos：计算框架一个集群管理器，提供了有效的、跨分布式应用或框架的资源隔离和共享Impala：新一代开源大数据分析引擎，提供Sql语义，比- Hive强在速度上SNAPPY：快速的数据压缩系统，适用于Hadoop生态系统中Kafka:高吞吐量的分布式消息队列系统ActiveMQ:是Apache出品，最流行的，能力强劲的开源消息总线MQTT:Message Queuing Telemetry Transport，消息队列遥测传输）是IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分RabbitMQ：记得OpenStack就是用的这个东西吧ZeroMQ：宣称是将分布式计算变得更简单，是个分布式消息队列，可以看下云风的一篇文章的介绍开源的日志收集系统：scribe、chukwa、kafka、flume。这有一篇对比文章Zookeeper：可靠的分布式协调的开源项目Databus：LinkedIn 实时低延迟数据抓取系统数据源获取：Flume、Google Refine、Needlebase、ScraperWiki、BloomReach序列化技术：JSON、BSON、Thrift、Avro、Google Protocol BuffersNoSql：Apache Hadoop、Apache Casandra、MongoDB、Apache CouchDB、Redis、BigTable、HBase、Hypertable、Voldemort、Neo4j MapReduce相关：Hive、Pig、Cascading、Cascalog、mrjob、Caffeine、S4、MapR、Acunu、Flume、Kafka、Azkaban、Oozie、Greenplum数据处理：R、Yahoo! Pipes、Mechanical Turk、Solr/ Lucene、ElasticSearch、Datameer、Bigsheets、TinkerpopNLP自然语言处理：Natural Language Toolkit、Apache OpenNLP、Boilerpipe、OpenCalais机器学习：WEKA、Mahout、scikits.learn、SkyTree可视化技术：GraphViz、Processing、Protovis、Google Fusion Tables、Tableau、Highcharts、EChats（百度的还不错）、Rapha?l.jsKettle：开源的ETL工具Pentaho：以工作流为核心的开源BI系统Mondrian：开源的Rolap服务器Oozie：开源hadoop的工作流调度引擎开源的数据分析可视化工具：Weka、Orange、KNIMECobar：阿里巴巴的MySql分布式中间件C &amp; C++ Thrift:用来进行可扩展且跨语言的服务的开发(类似的还有个Avro，Google protobuf)。libevent:是一个事件触发的网络库，适用于windows、linux、bsd等多种平台，内部使用select、epoll、kqueue等系统调用管理事件机制。（对了还有个libev呢）Boost:不多说了，准C++标准库Ptmalloc\\Valgrind\\PurifyNetworkServer架构：acceptor-&gt;dispatcher-&gt;worker(这个不算工具哦)breakpad:崩溃转储和分析模块，很多crashreport会用到 UI界面相关：MFC、BCG和QT这类的就不说了，高端一点的还有Html和DirectUI技术：libcef（基于chrome内核的，想想使用html5开发页面，还真有点小激动呢）、HtmlLayout、Duilib、Bolt，非C++的，还有node-webkit也不错，集成了node和webkit内核。 游戏开发相关MINA：使用Java开发手游和页游服务器(对了还有Netty，也很猛的，都是基于NIO的)HP-Socket：见有有些页游服务器使用这个构建的云风的技术博客：http://blog.codingnow.com/OGRE：大名鼎鼎的3D图形渲染引擎OpenVDB：梦工厂C++的特效库，开源的cocos2d：跨平台2D游戏引擎unity3d：跨平台3D游戏引擎，很火的哦Nodejs：也有不少使用它来开发手游和也有服务器（网易的Pomelo就是哦）日志聚合 分布式日志收集Scribe：Facebook的（nodejs + scribe + inotify 同步日志）logstash:强大的日志收集系统，可以基于logstash+kibana+elasticsearch+redis开发强大的日志分析平台log.io: nodejs开发的实时日志收集系统RTP,实时传输协议与音视频RTP，RTCP，RTSP-&gt; librtp，JRTPLIB(遵循了RFC1889标准)环形缓冲区，实时数据传输用SDL,ffmpeg,live555,SpeexRed5:用Java开发开源的Flash流媒体服务器。它支持：把音频（MP3）和视频（FLV）转换成播放流； 录制客户端播放流（只支持FLV）；共享对象；现场直播流发布；远程调用。 PythonEric,Eclipse+pydev,比较不错的Python IDEPyWin:Win32 api编程包numpy:科学计算包，主要用来处理大型矩阵计算等，此外还有SciPy，Matplotlib GUI相关：PyQt，PyQwtsupervisor:进程监控工具 Java相关常用的IDE：IntelliJ IDEA，Eclipse，Netbeans Web开发相关：Tomcat、Resin、Jetty、WebLogic等，常用的组件Struts，SpringHibernateNetty: 异步事件驱动网络应用编程框架，用于高并发网络编程比较好（NIO框架）MINA：简单地开发高性能和高可靠性的网络应用程序（也是个NIO框架），不少手游服务端是用它开发的jOOQ：java Orm框架Activiti:工作流引擎，类似的还有jBPM、SnakerPerfuse:是一个用户界面包用来把有结构与无结构数据以具有交互性的可视化图形展示出来.Gephi:复杂网络分析软件, 其主要用于各种网络和复杂系统，动态和分层图的交互可视化与探测开源工具Nutch:知名的爬虫项目，hadoop就是从这个项目中发展出来的web-harvest：Web数据提取工具POM工具：Maven+ArtifactoryNetflixCurator：Netflix公司开源的一个Zookeeper client library，用于简化Zookeeper客户端编程Akka:一款基于actor模型实现的 并发处理框架EclEmma：覆盖测试工具 .net相关Xilium.CefGlue:基于CEF框架的.NET封装，基于.NET开发Chrome内核浏览器CefSharp：同上，有一款WebKit的封装，C#和Js交互会更简单netz:免费的 .NET 可执行文件压缩工具SmartAssembly:变态的.net代码优化混淆工具NETDeob0：.net反混淆工具，真是魔高一尺道高一丈啊(还有个de4dot，在GitHub上，都是开源的)ILMerge：将所有引用的DLL和exe文件打成一个exe文件ILSpy:开源.net程序反编译工具Javascript.NET：很不错的js执行引擎，对v8做了封装NPOI: Excel操作DotRAS:远程访问服务的模块WinHtmlEditor: Winform下的html编辑器lSmartThreadPool:使用C#实现的，带高级特性的线程池Snoop: WPF Spy UtilityAutofac: 轻量级IoC框架HtmlAgilityPack：Html解析利器Quartz.NET：Job调度HttpLib：@CodePlex，简化http请求SuperSocket：简化Socket操作，基于他的还有个SuperWebSocket，可以开发独立的WebSocket服务器了DocX：未安装Office的情况下操作Word文件Dapper：轻量级的ORM类，性能不错HubbleDotNet：支持接入数据库的全文搜索系统fastJSON：@CodeProject，高性能的json序列化类ZXing.NET：@CodePlex，QR，条形码相关Nancy：轻量级Http服务器，做个小型的Web应用可以摆脱IIS喽(Nancy.Viewengines.Razor,可以加入Razor引擎)AntiXSS：微软的XSS防御库Microsoft Web ProtectionLibraryJint：JavaScript解释器CS-Script：将C#代码文件作为脚本执行Jexus：Linux下 高性能、易用、免费的ASP.NET服务器Clay：将dynamic发挥的更加灵活，像写js一样写C#DynamicJSON：不必定义数据模型获取json数据Antlr：开源的语法分析器（归到C#不太合适，其他语言也可以去用）SharpPcap：C#版的WinPcap调用端，牛逼的网络包分析库（自带PacketNotNet用于包协议分析）Roslyn：C#，VB编译器ImageResizer: 服务端自由控制图片大小，真乃神器也，对手机端传小图，PC端传大图，CMS用它很方便 UI相关：DevExpress, Fluent(Office 07风格), mui（Modern UI for WPF）NetSparkle：应用自动更新组件ConfuserEx: 开源.net混淆工具ServiceStack: 开源高性能Web服务框架，可用于构建高性能的REST服务ExpressionEvaluator：Eval for C#,处理字符串表达式http://nugetmusthaves.com/ 常用工具Fiddler：非常好用的Web前端调试工具，当然是针对底层http协议的，一般情况使用Chrome等自带的调试工具也足够了，特殊情况还得用它去处理wireshark：知名的网络数据包分析工具PowerCmd:替代Windows Cmd的利器RegexBuddy:强大的正则表达式测试工具Soure Insight：源代码阅读神器SublimeText：程序员最爱的编辑器Database.NET：一个通用的关系型数据库客户端，基于.NET 4.0开发的，做简单的处理还是蛮方便的Navicat Premium：支持MySql、PostgreSQL、Oracle、Sqlite和SQL Server的客户端，通用性上不如Database.NET，但性能方面比Database.NET好很多，自带备份功能也用于数据库定时备份。Synergy : 局域网内一套键盘鼠标控制多台电脑DameWare：远程协助工具集（我在公司主要控制大屏幕用）Radmin: 远程控制工具，用了一段时间的DameWare，还要破解，对Win7支持的不好，还是发现这个好用Listary：能极大幅度提高你 Windows 文件浏览与搜索速度效率的「超级神器」Clover：给资源管理器加上多标签WinLaunch：模拟Mac OS的Launch工具Fritzing：绘制电路图LICEcap：gif教程制作git，svn：版本控制系统Enigma Virtual Box（将exe，dll等封装成一个可执行程序）Open DBDiff(针对SqlServer)数据库同步SymmetricDS：数据库同步BIEE,Infomatica，SPSS，weka，R语言：数据分析CodeSmith，LightSwitch：代码生成Pandoc：Markdown转换工具，出书用的。以前玩过docbook，不过现在还是Markdown盛行啊。Window Magnet[Mac]：增强Mac窗口管理功能，想Win7一样具有窗口拖放到屏幕边缘自动调整的功能log explorer：查看SqlServer日志dependencywalker：查询Windows应用程序dll依赖项Shairport4w：将iPhone，iPad，iPod上的音频通过AirPlay协议传输到PC上ngrok：内网穿透工具Axure:快速原型制作工具，还有个在线作图的工具国内的一个创业团队做的，用着很不错 http://www.processon.comtinyproxy:（Linux）小型的代理服务器支持http和https协议EaseUS PartitionMaster：超级简单的分区调整工具，速度还是蛮快的，C盘不够用了就用它从D盘划点空间吧，不用重装系统这么折腾哦。CheatEngine：玩游戏修改内存值必备神器（记得我在玩轩辕剑6的时候就用的它，超级方便呢）ApkIDE:Android反编译神器翻、墙工具（自|由|门、天行浏览器）设计工具：Sketch、OmniGraffleMindManger：思维导图 项目管理软件Edraw ProjectExcel 难度大Mind Master 甘特图+思维导图 熟练使用后绘制效率更高瀚文进度计划软件 风格类似早期windows软件 界面不够时尚整洁亿图图示 短时间上手 模板多 适合新手使用","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"Hello World","slug":"Tools-hello-world","date":"2018-09-08T07:09:12.000Z","updated":"2022-09-30T04:33:26.000Z","comments":true,"path":"2018/09/08/Tools-hello-world/","link":"","permalink":"http://example.com/2018/09/08/Tools-hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info.If you get any problems when using Hexo, you can find the answer in troubleshootingor you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]}],"categories":[{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/categories/Introduction/"},{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"DataStructures&Algorothms","slug":"DataStructures-Algorothms","permalink":"http://example.com/tags/DataStructures-Algorothms/"},{"name":"DataFrame","slug":"DataFrame","permalink":"http://example.com/tags/DataFrame/"},{"name":"AWS","slug":"AWS","permalink":"http://example.com/tags/AWS/"},{"name":"Sagemaker","slug":"Sagemaker","permalink":"http://example.com/tags/Sagemaker/"},{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"CV","slug":"CV","permalink":"http://example.com/tags/CV/"},{"name":"Face","slug":"Face","permalink":"http://example.com/tags/Face/"},{"name":"MachineLearning","slug":"MachineLearning","permalink":"http://example.com/tags/MachineLearning/"},{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"},{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://example.com/tags/DeepLearning/"},{"name":"Yolo","slug":"Yolo","permalink":"http://example.com/tags/Yolo/"},{"name":"Recommendation","slug":"Recommendation","permalink":"http://example.com/tags/Recommendation/"},{"name":"Django","slug":"Django","permalink":"http://example.com/tags/Django/"},{"name":"Function","slug":"Function","permalink":"http://example.com/tags/Function/"},{"name":"Pandas","slug":"Pandas","permalink":"http://example.com/tags/Pandas/"},{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Shell","slug":"Shell","permalink":"http://example.com/tags/Shell/"},{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"},{"name":"Mathematics","slug":"Mathematics","permalink":"http://example.com/tags/Mathematics/"},{"name":"Athena","slug":"Athena","permalink":"http://example.com/tags/Athena/"},{"name":"EXASOL","slug":"EXASOL","permalink":"http://example.com/tags/EXASOL/"},{"name":"MySql","slug":"MySql","permalink":"http://example.com/tags/MySql/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://example.com/tags/PostgreSQL/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"Hive","slug":"Hive","permalink":"http://example.com/tags/Hive/"},{"name":"Interview","slug":"Interview","permalink":"http://example.com/tags/Interview/"},{"name":"Excel","slug":"Excel","permalink":"http://example.com/tags/Excel/"},{"name":"LabelImg","slug":"LabelImg","permalink":"http://example.com/tags/LabelImg/"},{"name":"Git","slug":"Git","permalink":"http://example.com/tags/Git/"},{"name":"Sublime","slug":"Sublime","permalink":"http://example.com/tags/Sublime/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"Windows","slug":"Windows","permalink":"http://example.com/tags/Windows/"}]}